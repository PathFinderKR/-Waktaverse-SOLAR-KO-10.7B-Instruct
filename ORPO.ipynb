{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Login to Hugging Face"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7c2f9104252a4bb"
  },
  {
   "cell_type": "code",
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from huggingface_hub import login\n",
    "\n",
    "load_dotenv()\n",
    "token = os.getenv(\"HUGGINGFACE_TOKEN\")\n",
    "login(\n",
    "    token=token,  # ADD YOUR TOKEN HERE\n",
    "    add_to_git_credential=True\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-23T08:28:06.773751Z",
     "start_time": "2024-04-23T08:28:06.227995Z"
    }
   },
   "id": "4eee58c68eb02d85",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token is valid (permission: write).\n",
      "Your token has been saved in your configured git credential helpers (store).\n",
      "Your token has been saved to /home/pathfinder/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "source": [
    "model_name = \"Waktaverse-Llama-3-KO-8B-Instruct-ORPO\"  # ADD YOUR MODEL NAME HERE\n",
    "username = \"PathFinderKR\"  # ADD YOUR USERNAME HERE\n",
    "repo_id = f\"{username}/{model_name}\"  # repository id"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-23T08:28:06.777558Z",
     "start_time": "2024-04-23T08:28:06.775076Z"
    }
   },
   "id": "cd4c26069d51a597",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Login to Weights & Biases",
   "id": "45b93503027bc62"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T08:28:08.527322Z",
     "start_time": "2024-04-23T08:28:06.778532Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import wandb\n",
    "\n",
    "api_key = os.getenv(\"WANDB_API_KEY\")\n",
    "wandb.login(\n",
    "    key=api_key  # ADD YOUR API KEY HERE\n",
    ")\n",
    "wandb.init(project=model_name)"
   ],
   "id": "bd9885bdc6270f76",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33mpathfinderkr\u001B[0m (\u001B[33mwaktaverse\u001B[0m). Use \u001B[1m`wandb login --relogin`\u001B[0m to force relogin\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \u001B[33mWARNING\u001B[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \u001B[33mWARNING\u001B[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Appending key for api.wandb.ai to your netrc file: /home/pathfinder/.netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Downloads"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "78114e8f78ee19ec"
  },
  {
   "cell_type": "code",
   "source": [
    "#!pip install huggingface_hub\n",
    "#!pip install wandb\n",
    "#!pip install transformers\n",
    "#!pip install bitsandbytes\n",
    "#!pip install peft\n",
    "#!pip install trl\n",
    "#!pip install accelerate\n",
    "#!pip install datasets\n",
    "#!pip install scikit-learn\n",
    "#!pip install packaging\n",
    "#!pip install ninja\n",
    "#!pip install flash-attn --no-build-isolation"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-23T08:28:08.531058Z",
     "start_time": "2024-04-23T08:28:08.528892Z"
    }
   },
   "id": "ce6454f84604b9e4",
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Imports"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "685ac8c0e05ac872"
  },
  {
   "cell_type": "code",
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "# pytorch\n",
    "import torch\n",
    "\n",
    "# huggingface\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    BitsAndBytesConfig\n",
    ")\n",
    "from peft import LoraConfig, PeftModel\n",
    "from trl import ORPOConfig, ORPOTrainer\n",
    "\n",
    "# datasets\n",
    "from datasets import load_dataset"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-23T08:28:10.799544Z",
     "start_time": "2024-04-23T08:28:08.532114Z"
    }
   },
   "id": "f8c108abcd576306",
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Device"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e512d30c21d105c2"
  },
  {
   "cell_type": "code",
   "source": [
    "# Device setup\n",
    "device = (\n",
    "    \"cuda:0\" if torch.cuda.is_available() else # Nvidia GPU\n",
    "    \"mps\" if torch.backends.mps.is_available() else # Apple Silicon GPU\n",
    "    \"cpu\"\n",
    ")\n",
    "print(f\"Device = {device}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-23T08:28:10.803549Z",
     "start_time": "2024-04-23T08:28:10.800489Z"
    }
   },
   "id": "fdf3a2a4e0e31554",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device = cuda:0\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T08:28:10.810441Z",
     "start_time": "2024-04-23T08:28:10.804585Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Flash Attention Implementation\n",
    "if device == \"cuda:0\":\n",
    "    if torch.cuda.get_device_capability()[0] >= 8: # Ampere, Ada, or Hopper GPUs\n",
    "        attn_implementation = \"flash_attention_2\"\n",
    "        torch_dtype = torch.bfloat16\n",
    "    else:\n",
    "        attn_implementation = \"eager\"\n",
    "        torch_dtype = torch.float16\n",
    "else:\n",
    "    attn_implementation = \"eager\"\n",
    "    torch_dtype = torch.float32\n",
    "print(f\"Attention Implementation = {attn_implementation}\")"
   ],
   "id": "d96a4ad9abc2d0ed",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention Implementation = flash_attention_2\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Hyperparameters"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "84ce31a12e172a64"
  },
  {
   "cell_type": "code",
   "source": [
    "################################################################################\n",
    "# seed\n",
    "################################################################################\n",
    "seed=42\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "################################################################################\n",
    "# Tokenizer parameters\n",
    "################################################################################\n",
    "max_tokens=1024\n",
    "padding=\"do_not_pad\" # \"max_length\", \"longest\", \"do_not_pad\"\n",
    "truncation=True\n",
    "\n",
    "################################################################################\n",
    "# Generation parameters\n",
    "################################################################################\n",
    "num_return_sequences=1\n",
    "min_new_tokens=1\n",
    "max_new_tokens=1024\n",
    "do_sample=True\n",
    "temperature=0.6\n",
    "top_k=40\n",
    "top_p=0.9\n",
    "repetition_penalty=1.1\n",
    "\n",
    "################################################################################\n",
    "# Dataset parameters\n",
    "################################################################################\n",
    "validation_size=0.1\n",
    "\n",
    "################################################################################\n",
    "# bitsandbytes parameters\n",
    "################################################################################\n",
    "load_in_4bit=True\n",
    "bnb_4bit_compute_dtype=torch_dtype\n",
    "bnb_4bit_quant_type=\"nf4\" # \"nf4\", #fp4\"\n",
    "bnb_4bit_use_double_quant=True\n",
    "\n",
    "################################################################################\n",
    "# LoRA parameters\n",
    "################################################################################\n",
    "task_type=\"CAUSAL_LM\"\n",
    "target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"]\n",
    "r=8\n",
    "lora_alpha=16\n",
    "lora_dropout=0.05\n",
    "bias=\"none\"\n",
    "\n",
    "################################################################################\n",
    "# ORPO parameters\n",
    "################################################################################\n",
    "output_dir=\"./results\"\n",
    "logging_dir=\"./logs\"\n",
    "save_strategy=\"epoch\" # \"steps\", \"epoch\"\n",
    "logging_strategy=\"steps\" # \"steps\", \"epoch\"\n",
    "if logging_strategy == \"steps\":\n",
    "    logging_steps=10\n",
    "else:\n",
    "    logging_steps=None\n",
    "evaluation_strategy=\"steps\" # \"steps\", \"epoch\"\n",
    "if evaluation_strategy == \"steps\":\n",
    "    eval_steps=10\n",
    "else:\n",
    "    eval_steps=None\n",
    "save_total_limit=1\n",
    "report_to=\"wandb\"\n",
    "\n",
    "learning_rate=8e-6\n",
    "beta=0.1\n",
    "max_length=1024\n",
    "max_prompt_length=512\n",
    "num_train_epochs=1\n",
    "per_device_train_batch_size=1\n",
    "per_device_eval_batch_size=1\n",
    "gradient_accumulation_steps=1\n",
    "optim=\"adamw_torch\" # \"sgd\", \"adamw_torch\"\n",
    "weight_decay=0.1\n",
    "lr_scheduler_type=\"cosine\" # \"constant\", \"linear\", \"cosine\"\n",
    "warmup_steps=10\n",
    "warmup_ratio=0.1"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-23T08:28:10.817744Z",
     "start_time": "2024-04-23T08:28:10.811481Z"
    }
   },
   "id": "dc1a272a1c0b7ce4",
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f5d3b7c47ea29a3d"
  },
  {
   "cell_type": "code",
   "source": [
    "# Model List\n",
    "\n",
    "# gemma variants\n",
    "# \"google/gemma-1.1-7b-it\"\n",
    "# \"google/codegemma-7b-it\"\n",
    "\n",
    "# llama2 variants\n",
    "# \"meta-llama/Meta-Llama-3-8B-Instruct\" // downloaded\n",
    "# \"codellama/CodeLlama-7b-Instruct-hf\"\n",
    "# \"PathFinderKR/Waktaverse-Llama-3-KO-8B-Instruct\"\n",
    "\n",
    "# mistral variants\n",
    "# \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "\n",
    "# solar variants\n",
    "# \"upstage/SOLAR-10.7B-Instruct-v1.0\" // downloaded\n",
    "# \"PathFinderKR/Waktaverse-SOLAR-KO-10.7B-Instruct\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-23T08:28:10.826307Z",
     "start_time": "2024-04-23T08:28:10.818732Z"
    }
   },
   "id": "70d2fbe5c0980a54",
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "source": [
    "# Model ID for base model\n",
    "model_id = \"meta-llama/Meta-Llama-3-8B-Instruct\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-23T08:28:10.832913Z",
     "start_time": "2024-04-23T08:28:10.827946Z"
    }
   },
   "id": "eb8160d8919cdaeb",
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "source": [
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "tokenizer.add_special_tokens({'pad_token': '[PAD]'}) # add padding token\n",
    "tokenizer.padding_side = \"right\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-23T08:28:11.236702Z",
     "start_time": "2024-04-23T08:28:10.833901Z"
    }
   },
   "id": "4ebbf883fce9aa8",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T08:28:11.241420Z",
     "start_time": "2024-04-23T08:28:11.237891Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Quantization\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=load_in_4bit,\n",
    "    bnb_4bit_compute_dtype=bnb_4bit_compute_dtype,\n",
    "    bnb_4bit_quant_type=bnb_4bit_quant_type,\n",
    "    bnb_4bit_use_double_quant=bnb_4bit_use_double_quant\n",
    ")"
   ],
   "id": "69d30da42bd6cf7b",
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "source": [
    "# Load model\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    device_map=device,\n",
    "    attn_implementation=attn_implementation,\n",
    "    torch_dtype=torch_dtype,\n",
    "    quantization_config=quantization_config\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-23T08:28:31.191220Z",
     "start_time": "2024-04-23T08:28:11.242258Z"
    }
   },
   "id": "978055543828a014",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "072df15a4c5a4723a9f07f572d1317ca"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T08:28:31.211579Z",
     "start_time": "2024-04-23T08:28:31.200099Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# display the model architecture\n",
    "display(Markdown(f'```{model}```'))"
   ],
   "id": "e224c50f423698e1",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "```LlamaForCausalLM(\n  (model): LlamaModel(\n    (embed_tokens): Embedding(128256, 4096)\n    (layers): ModuleList(\n      (0-31): 32 x LlamaDecoderLayer(\n        (self_attn): LlamaFlashAttention2(\n          (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n          (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n          (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n          (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n          (rotary_emb): LlamaRotaryEmbedding()\n        )\n        (mlp): LlamaMLP(\n          (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n          (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n          (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n          (act_fn): SiLU()\n        )\n        (input_layernorm): LlamaRMSNorm()\n        (post_attention_layernorm): LlamaRMSNorm()\n      )\n    )\n    (norm): LlamaRMSNorm()\n  )\n  (lm_head): Linear(in_features=4096, out_features=128256, bias=False)\n)```"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a4042d4b7cd2d0fd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T08:28:31.232791Z",
     "start_time": "2024-04-23T08:28:31.213142Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Dataset ID\n",
    "dataset_id = \"orpo-explorers/OpenHermesPreferences-10k\""
   ],
   "id": "bfb9b3344154880f",
   "outputs": [],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "source": [
    "# Load dataset\n",
    "dataset = load_dataset(dataset_id)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-23T08:28:35.328967Z",
     "start_time": "2024-04-23T08:28:31.236167Z"
    }
   },
   "id": "4373ef1c6a85e5e2",
   "outputs": [],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "source": [
    "# Dataset information\n",
    "dataset"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-23T08:28:35.333096Z",
     "start_time": "2024-04-23T08:28:35.330055Z"
    }
   },
   "id": "aabd9487c235d581",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['source', 'category', 'prompt', 'candidates_completions', 'candidate_policies', 'ranks', 'rank_str', 'chosen_policy', 'chosen', 'rejected_policy', 'rejected'],\n",
       "        num_rows: 10000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "source": [
    "# Dataset example\n",
    "dataset[\"train\"][0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-23T08:28:35.340725Z",
     "start_time": "2024-04-23T08:28:35.334802Z"
    }
   },
   "id": "760399232efac9ea",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': None,\n",
       " 'category': None,\n",
       " 'prompt': 'You are a helpful assistant, who always provide explanation. Think like you are answering to a five year old. Read this: Southeast Tucson continues to experience rapid residential development. The area includes Davis-Monthan Air Force Base. The area is considered to be south of Golf Links Road. It is the home of Santa Rita High School, Chuck Ford Park (Lakeside Park), Lakeside Lake, Lincoln Park (upper and lower), The Lakecrest Neighborhoods, and Pima Community College East Campus. The Atterbury Wash with its access to excellent bird watching is also located in the Southeast Tucson area. The suburban community of Rita Ranch houses many of the military families from Davis-Monthan, and is near the southeastern-most expansion of the current city limits. Close by Rita Ranch and also within the city limits lies Civano, a planned development meant to showcase ecologically sound building practices and lifestyles.\\n\\nWhat is the name of the High School in the area of Southeast Tuscon?\\nWhat is the answer? (If it cannot be answered, return \"unanswerable\")',\n",
       " 'candidates_completions': [' The name of the high school in the area of Southeast Tucson is Santa Rita High School. So, the answer is Santa Rita High School.',\n",
       "  'The name of the High School in the area of Southeast Tucson is Santa Rita High School.',\n",
       "  'The name of the high school in the area of Southeast Tucson is Santa Rita High School.'],\n",
       " 'candidate_policies': ['mistralai/Mixtral-8x7B-Instruct-v0.1',\n",
       "  'teknium/OpenHermes-2.5',\n",
       "  'NousResearch/Nous-Hermes-2-Yi-34B'],\n",
       " 'ranks': [2, 1, 0],\n",
       " 'rank_str': 'NousResearch/Nous-Hermes-2-Yi-34B > teknium/OpenHermes-2.5 > mistralai/Mixtral-8x7B-Instruct-v0.1',\n",
       " 'chosen_policy': 'NousResearch/Nous-Hermes-2-Yi-34B',\n",
       " 'chosen': [{'content': 'You are a helpful assistant, who always provide explanation. Think like you are answering to a five year old. Read this: Southeast Tucson continues to experience rapid residential development. The area includes Davis-Monthan Air Force Base. The area is considered to be south of Golf Links Road. It is the home of Santa Rita High School, Chuck Ford Park (Lakeside Park), Lakeside Lake, Lincoln Park (upper and lower), The Lakecrest Neighborhoods, and Pima Community College East Campus. The Atterbury Wash with its access to excellent bird watching is also located in the Southeast Tucson area. The suburban community of Rita Ranch houses many of the military families from Davis-Monthan, and is near the southeastern-most expansion of the current city limits. Close by Rita Ranch and also within the city limits lies Civano, a planned development meant to showcase ecologically sound building practices and lifestyles.\\n\\nWhat is the name of the High School in the area of Southeast Tuscon?\\nWhat is the answer? (If it cannot be answered, return \"unanswerable\")',\n",
       "   'role': 'user'},\n",
       "  {'content': 'The name of the high school in the area of Southeast Tucson is Santa Rita High School.',\n",
       "   'role': 'assistant'}],\n",
       " 'rejected_policy': 'mistralai/Mixtral-8x7B-Instruct-v0.1',\n",
       " 'rejected': [{'content': 'You are a helpful assistant, who always provide explanation. Think like you are answering to a five year old. Read this: Southeast Tucson continues to experience rapid residential development. The area includes Davis-Monthan Air Force Base. The area is considered to be south of Golf Links Road. It is the home of Santa Rita High School, Chuck Ford Park (Lakeside Park), Lakeside Lake, Lincoln Park (upper and lower), The Lakecrest Neighborhoods, and Pima Community College East Campus. The Atterbury Wash with its access to excellent bird watching is also located in the Southeast Tucson area. The suburban community of Rita Ranch houses many of the military families from Davis-Monthan, and is near the southeastern-most expansion of the current city limits. Close by Rita Ranch and also within the city limits lies Civano, a planned development meant to showcase ecologically sound building practices and lifestyles.\\n\\nWhat is the name of the High School in the area of Southeast Tuscon?\\nWhat is the answer? (If it cannot be answered, return \"unanswerable\")',\n",
       "   'role': 'user'},\n",
       "  {'content': ' The name of the high school in the area of Southeast Tucson is Santa Rita High School. So, the answer is Santa Rita High School.',\n",
       "   'role': 'assistant'}]}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Preprocessing",
   "id": "6e54c42138a256a8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T08:28:35.857460Z",
     "start_time": "2024-04-23T08:28:35.341664Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ORPO dataset format: \n",
    "# {\"prompt\": [str], \"chosen\": [str], \"rejected\": [str]} in chat template\n",
    "def preprocess_function(example):\n",
    "    example[\"chosen\"] = tokenizer.apply_chat_template(example[\"chosen\"], tokenize=False)\n",
    "    example[\"rejected\"] = tokenizer.apply_chat_template(example[\"rejected\"], tokenize=False)\n",
    "    return example\n",
    "\n",
    "dataset = dataset.map(preprocess_function, batched=True)"
   ],
   "id": "94e5625353430024",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "64194f55c72d4e2b9f2502be30219800"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T08:28:35.873232Z",
     "start_time": "2024-04-23T08:28:35.858894Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Split the dataset into a training and a validation dataset\n",
    "dataset = dataset[\"train\"].train_test_split(test_size=validation_size, seed=seed)\n",
    "\n",
    "# Number of questions in the train, validation dataset\n",
    "print(f\"Number of questions in the train dataset: {len(dataset['train'])}\")\n",
    "print(f\"Number of questions in the validation dataset: {len(dataset['test'])}\")"
   ],
   "id": "af828c6aa70c7412",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of questions in the train dataset: 9000\n",
      "Number of questions in the validation dataset: 1000\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T08:28:35.877528Z",
     "start_time": "2024-04-23T08:28:35.874216Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Display the first example\n",
    "dataset[\"train\"][0]"
   ],
   "id": "84e41321b0c5161e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': None,\n",
       " 'category': None,\n",
       " 'prompt': \"User will you give you a task with some instruction. Your job is follow the instructions as faithfully as you can. While answering think step-by-step and justify your answer. Given the task definition and input, reply with output. In this task, you're given four sentences of a story written in natural language, and one last sentence (Sentence5). Your job is to classify whether the last sentence completes the rest of the story coherently or not by providing 'Yes' or 'No'.\\n\\nSentence1: Ann and Tim loved astrology. Sentence2: In fact, the met while they were both in astronomy class in college! Sentence3: When they married and became pregnant, they had a dilemma. Sentence4: They couldn't decide on a meaningful name for their baby daughter. \\n Sentence5: Tim and Anna decided they would ask their veterinarian.\",\n",
       " 'candidates_completions': [' No, the last sentence does not complete the rest of the story coherently. The story is about the main characters, Ann and Tim, who love astrology and are trying to decide on a meaningful name for their baby daughter. The suggested Sentence 5 has them asking their veterinarian, which is unrelated to the topic of the previous sentences and seems incongruous in the context of the story.',\n",
       "  \"Step 1: Understanding the context of the story\\nAnn and Tim both love astrology and met in astronomy class. They got married and are expecting a baby. They are struggling to choose a meaningful name for their baby daughter.\\n\\nStep 2: Analyzing the last sentence\\nSentence5: Tim and Anna decided they would ask their veterinarian.\\n\\nStep 3: Determining coherence\\nIn sentence5, they seek advice from a veterinarian who isn't related to astrology. So, it doesn't show a coherent connection to the context of the story based on their mutual interest in astrology. \\n\\nStep 4: Providing the answer\\nBased on the lack of coherence with the rest of the story, my answer is:\\nNo\",\n",
       "  'Output: No'],\n",
       " 'candidate_policies': ['mistralai/Mixtral-8x7B-Instruct-v0.1',\n",
       "  'teknium/OpenHermes-2.5',\n",
       "  'NousResearch/Nous-Hermes-2-Yi-34B'],\n",
       " 'ranks': [0, 1, 2],\n",
       " 'rank_str': 'mistralai/Mixtral-8x7B-Instruct-v0.1 > teknium/OpenHermes-2.5 > NousResearch/Nous-Hermes-2-Yi-34B',\n",
       " 'chosen_policy': 'mistralai/Mixtral-8x7B-Instruct-v0.1',\n",
       " 'chosen': \"<|begin_of_text|><|start_header_id|>user<|end_header_id|>\\n\\nUser will you give you a task with some instruction. Your job is follow the instructions as faithfully as you can. While answering think step-by-step and justify your answer. Given the task definition and input, reply with output. In this task, you're given four sentences of a story written in natural language, and one last sentence (Sentence5). Your job is to classify whether the last sentence completes the rest of the story coherently or not by providing 'Yes' or 'No'.\\n\\nSentence1: Ann and Tim loved astrology. Sentence2: In fact, the met while they were both in astronomy class in college! Sentence3: When they married and became pregnant, they had a dilemma. Sentence4: They couldn't decide on a meaningful name for their baby daughter. \\n Sentence5: Tim and Anna decided they would ask their veterinarian.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nNo, the last sentence does not complete the rest of the story coherently. The story is about the main characters, Ann and Tim, who love astrology and are trying to decide on a meaningful name for their baby daughter. The suggested Sentence 5 has them asking their veterinarian, which is unrelated to the topic of the previous sentences and seems incongruous in the context of the story.<|eot_id|>\",\n",
       " 'rejected_policy': 'NousResearch/Nous-Hermes-2-Yi-34B',\n",
       " 'rejected': \"<|begin_of_text|><|start_header_id|>user<|end_header_id|>\\n\\nUser will you give you a task with some instruction. Your job is follow the instructions as faithfully as you can. While answering think step-by-step and justify your answer. Given the task definition and input, reply with output. In this task, you're given four sentences of a story written in natural language, and one last sentence (Sentence5). Your job is to classify whether the last sentence completes the rest of the story coherently or not by providing 'Yes' or 'No'.\\n\\nSentence1: Ann and Tim loved astrology. Sentence2: In fact, the met while they were both in astronomy class in college! Sentence3: When they married and became pregnant, they had a dilemma. Sentence4: They couldn't decide on a meaningful name for their baby daughter. \\n Sentence5: Tim and Anna decided they would ask their veterinarian.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nOutput: No<|eot_id|>\"}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T08:28:35.884475Z",
     "start_time": "2024-04-23T08:28:35.879337Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Dataset example\n",
    "print(f\"Chosen: {dataset['train'][0]['chosen']}\")\n",
    "print(f\"Rejected: {dataset['train'][0]['rejected']}\")"
   ],
   "id": "853e5ffda289871f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chosen: <|begin_of_text|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "User will you give you a task with some instruction. Your job is follow the instructions as faithfully as you can. While answering think step-by-step and justify your answer. Given the task definition and input, reply with output. In this task, you're given four sentences of a story written in natural language, and one last sentence (Sentence5). Your job is to classify whether the last sentence completes the rest of the story coherently or not by providing 'Yes' or 'No'.\n",
      "\n",
      "Sentence1: Ann and Tim loved astrology. Sentence2: In fact, the met while they were both in astronomy class in college! Sentence3: When they married and became pregnant, they had a dilemma. Sentence4: They couldn't decide on a meaningful name for their baby daughter. \n",
      " Sentence5: Tim and Anna decided they would ask their veterinarian.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "No, the last sentence does not complete the rest of the story coherently. The story is about the main characters, Ann and Tim, who love astrology and are trying to decide on a meaningful name for their baby daughter. The suggested Sentence 5 has them asking their veterinarian, which is unrelated to the topic of the previous sentences and seems incongruous in the context of the story.<|eot_id|>\n",
      "Rejected: <|begin_of_text|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "User will you give you a task with some instruction. Your job is follow the instructions as faithfully as you can. While answering think step-by-step and justify your answer. Given the task definition and input, reply with output. In this task, you're given four sentences of a story written in natural language, and one last sentence (Sentence5). Your job is to classify whether the last sentence completes the rest of the story coherently or not by providing 'Yes' or 'No'.\n",
      "\n",
      "Sentence1: Ann and Tim loved astrology. Sentence2: In fact, the met while they were both in astronomy class in college! Sentence3: When they married and became pregnant, they had a dilemma. Sentence4: They couldn't decide on a meaningful name for their baby daughter. \n",
      " Sentence5: Tim and Anna decided they would ask their veterinarian.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Output: No<|eot_id|>\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T08:28:35.891461Z",
     "start_time": "2024-04-23T08:28:35.886349Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(f\"Chosen: {dataset['test'][0]['chosen']}\")\n",
    "print(f\"Rejected: {dataset['test'][0]['rejected']}\")"
   ],
   "id": "aaadec88a007f9f0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chosen: <|begin_of_text|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "How can I create a two-dimensional array of size 5 by 5 in C language?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "You can create a two-dimensional array of size 5 by 5 in C language using the following code:\n",
      "\n",
      "```C\n",
      "#include<stdio.h>\n",
      "\n",
      "int main() {\n",
      "    int arr[5][5];\n",
      "\n",
      "    for(int i = 0; i < 5; i++) {\n",
      "        for (int j = 0; j < 5; j++) {\n",
      "            arr[i][j] = 0;\n",
      "        }\n",
      "    }\n",
      "\n",
      "    return 0;\n",
      "}\n",
      "```\n",
      "\n",
      "In this code, we declare a two-dimensional array `arr` of size 5 by 5 using the syntax `int arr[5][5];`. This creates a 5x5 matrix with 25 elements.\n",
      "\n",
      "To initialize all the elements of the array to 0, we use nested `for` loops. The outer loop iterates over the rows, and the inner loop iterates over the columns. Inside the nested loops, we assign the value 0 to each element of the array using the statement `arr[i][j] = 0;`.\n",
      "\n",
      "After executing this code, you will have a two-dimensional array `arr` of size 5 by 5, with all elements initialized to 0.<|eot_id|>\n",
      "Rejected: <|begin_of_text|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "How can I create a two-dimensional array of size 5 by 5 in C language?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "In C language, you can create a two-dimensional array of size 5 by 5 using the following syntax:\n",
      "\n",
      "```c\n",
      "int array_name[5][5];\n",
      "```\n",
      "\n",
      "Here, `array_name` is the name you want to give to the array. The first `5` indicates the number of rows, and the second `5` indicates the number of columns in the array.\n",
      "\n",
      "You can then access individual elements of the array using the row and column indices. For example, to access the element at the first row and third column, you would use:\n",
      "\n",
      "```c\n",
      "int element = array_name[0][2];\n",
      "```\n",
      "\n",
      "Note that array indices in C start at 0, so the first row is index 0, and the first column is also index 0.<|eot_id|>\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T08:28:35.900450Z",
     "start_time": "2024-04-23T08:28:35.892686Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Train on only a subset of the dataset for demonstration purposes\n",
    "dataset[\"train\"] = dataset[\"train\"].select(range(100))\n",
    "dataset[\"test\"] = dataset[\"test\"].select(range(10))"
   ],
   "id": "560b596e621189c7",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Inference before Training",
   "id": "7e1cc5548c03cc80"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T08:28:35.908361Z",
     "start_time": "2024-04-23T08:28:35.901927Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def generate_response(system ,user):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system},\n",
    "        {\"role\": \"user\", \"content\": user}\n",
    "    ]\n",
    "    prompt = tokenizer.apply_chat_template(\n",
    "        messages, \n",
    "        tokenize=False, \n",
    "        add_generation_prompt=False\n",
    "    )\n",
    "    \n",
    "    input_ids = tokenizer.encode(\n",
    "        prompt,\n",
    "        max_length=max_tokens,\n",
    "        padding=padding,\n",
    "        truncation=truncation,\n",
    "        add_special_tokens=True,\n",
    "        return_tensors=\"pt\"\n",
    "    ).to(device)\n",
    "    \n",
    "    outputs = model.generate(\n",
    "        input_ids=input_ids,\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "        num_return_sequences=num_return_sequences,\n",
    "        min_new_tokens=min_new_tokens,\n",
    "        max_new_tokens=max_new_tokens,\n",
    "        do_sample=do_sample,\n",
    "        temperature=temperature,\n",
    "        top_k=top_k,\n",
    "        top_p=top_p,\n",
    "        repetition_penalty=repetition_penalty\n",
    "    )\n",
    "    \n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=False)"
   ],
   "id": "926796ff0f85510b",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T08:28:35.915763Z",
     "start_time": "2024-04-23T08:28:35.909472Z"
    }
   },
   "cell_type": "code",
   "source": "system_prompt = \"You are a helpful assistant. Respond to the following user prompt. Use Korean only. 한국어만 사용하세요.\"",
   "id": "6296a3ab5e72f67b",
   "outputs": [],
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "source": [
    "#user_prompt = \"Write me a poem about Machine Learning.\"\n",
    "user_prompt = \"머신러닝에 대한 시를 써주세요.\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-23T08:28:35.922666Z",
     "start_time": "2024-04-23T08:28:35.916886Z"
    }
   },
   "id": "99e67d0533bf0f91",
   "outputs": [],
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "source": [
    "response = generate_response(system_prompt, user_prompt)\n",
    "print(response)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-23T08:28:44.537138Z",
     "start_time": "2024-04-23T08:28:35.929258Z"
    }
   },
   "id": "acf71f317ede56b2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "You are a helpful assistant. Respond to the following user prompt. Use Korean only. 한국어만 사용하세요.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "머신러닝에 대한 시를 써주세요.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "머신 러닝의 노래\n",
      "\n",
      "머신 러닝의 꿈은 하늘 높이\n",
      "데이터를 모으면 새로운 세상\n",
      "알고리즘의 춤을 추는 밤\n",
      "인공지능의 새벽을 맞이할 것\n",
      "\n",
      "자료의 흐름 속에서 우리는 찾는다\n",
      "패턴과 상관관계를 파악하여\n",
      "새로운 지식을 얻는 데 성공하라\n",
      "인간의 삶을 더 잘 이해할 수 있게\n",
      "\n",
      "머신 러닝의 노래는 끝나지 않아\n",
      "계속적으로 발전하고 있는 그릇\n",
      "인류의 미래를 예측하는 데 도움이 되리\n",
      "새로운 세상을 창조하는 데 일조하게\n",
      "\n",
      "(Note: This is a poem written in Korean about machine learning.)<|eot_id|>\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "cell_type": "markdown",
   "source": "##  Odds Ratio Preference Optimization ",
   "metadata": {
    "collapsed": false
   },
   "id": "b43eba6780d2e557"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T08:28:44.540317Z",
     "start_time": "2024-04-23T08:28:44.538116Z"
    }
   },
   "cell_type": "code",
   "source": [
    "lora_config = LoraConfig(\n",
    "    task_type=task_type,\n",
    "    target_modules=target_modules,\n",
    "    r=r,\n",
    "    lora_alpha=lora_alpha,\n",
    "    lora_dropout=lora_dropout,\n",
    "    bias=bias\n",
    ")"
   ],
   "id": "75ef555547f56ebf",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T08:28:44.578635Z",
     "start_time": "2024-04-23T08:28:44.541167Z"
    }
   },
   "cell_type": "code",
   "source": [
    "orpo_args = ORPOConfig(\n",
    "    output_dir=output_dir,\n",
    "    logging_dir=logging_dir,\n",
    "    save_strategy=save_strategy,\n",
    "    logging_strategy=logging_strategy,\n",
    "    evaluation_strategy=evaluation_strategy,\n",
    "    save_total_limit=save_total_limit,\n",
    "    report_to=report_to,\n",
    "    \n",
    "    learning_rate=learning_rate,\n",
    "    beta=beta,\n",
    "    max_length=max_length,\n",
    "    max_prompt_length=max_prompt_length,\n",
    "    num_train_epochs=num_train_epochs,\n",
    "    per_device_train_batch_size=per_device_train_batch_size,\n",
    "    per_device_eval_batch_size=per_device_eval_batch_size,\n",
    "    gradient_accumulation_steps=gradient_accumulation_steps,\n",
    "    optim=optim,\n",
    "    weight_decay=weight_decay,\n",
    "    lr_scheduler_type=lr_scheduler_type,\n",
    "    warmup_steps=warmup_steps,\n",
    "    warmup_ratio=warmup_ratio,\n",
    "    seed=seed\n",
    ")"
   ],
   "id": "2e29a9a3ca3b96b1",
   "outputs": [],
   "execution_count": 30
  },
  {
   "cell_type": "code",
   "source": [
    "trainer = ORPOTrainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    args=orpo_args,\n",
    "    peft_config=lora_config,\n",
    "    train_dataset=dataset[\"train\"],\n",
    "    eval_dataset=dataset[\"test\"]\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-23T08:28:45.311961Z",
     "start_time": "2024-04-23T08:28:44.579710Z"
    }
   },
   "id": "c60c5aa9a7d970b3",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pathfinder/anaconda3/envs/torch-env/lib/python3.11/site-packages/trl/trainer/orpo_trainer.py:247: UserWarning: When using DPODataCollatorWithPadding, you should set `remove_unused_columns=False` in your TrainingArguments we have set it for you, but you should do it yourself in the future.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "42434cdfaff34a3fbd4b1a2cabcf3f02"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/10 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "64083d708b8349ba931d62f411d4107a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 31
  },
  {
   "cell_type": "code",
   "source": [
    "trainer.train()"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "end_time": "2024-04-23T08:28:49.665912Z",
     "start_time": "2024-04-23T08:28:45.313227Z"
    }
   },
   "id": "5d9ba03835392e2a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011112820344447352, max=1.0…"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "55e26cd2822543c2b98940025b674f09"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Run data is saved locally in <code>/mnt/c/Users/cheir/GitHub/Waktaverse-LLM/wandb/run-20240423_172845-icdzgt51</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/waktaverse/huggingface/runs/icdzgt51' target=\"_blank\">fanciful-shape-22</a></strong> to <a href='https://wandb.ai/waktaverse/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View project at <a href='https://wandb.ai/waktaverse/huggingface' target=\"_blank\">https://wandb.ai/waktaverse/huggingface</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run at <a href='https://wandb.ai/waktaverse/huggingface/runs/icdzgt51' target=\"_blank\">https://wandb.ai/waktaverse/huggingface/runs/icdzgt51</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../aten/src/ATen/native/cuda/Indexing.cu:1290: indexSelectLargeIndex: block: [132,0,0], thread: [32,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1290: indexSelectLargeIndex: block: [132,0,0], thread: [33,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1290: indexSelectLargeIndex: block: [132,0,0], thread: [34,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1290: indexSelectLargeIndex: block: [132,0,0], thread: [35,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1290: indexSelectLargeIndex: block: [132,0,0], thread: [36,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1290: indexSelectLargeIndex: block: [132,0,0], thread: [37,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1290: indexSelectLargeIndex: block: [132,0,0], thread: [38,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1290: indexSelectLargeIndex: block: [132,0,0], thread: [39,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1290: indexSelectLargeIndex: block: [132,0,0], thread: [40,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1290: indexSelectLargeIndex: block: [132,0,0], thread: [41,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1290: indexSelectLargeIndex: block: [132,0,0], thread: [42,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1290: indexSelectLargeIndex: block: [132,0,0], thread: [43,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1290: indexSelectLargeIndex: block: [132,0,0], thread: [44,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1290: indexSelectLargeIndex: block: [132,0,0], thread: [45,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1290: indexSelectLargeIndex: block: [132,0,0], thread: [46,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1290: indexSelectLargeIndex: block: [132,0,0], thread: [47,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1290: indexSelectLargeIndex: block: [132,0,0], thread: [48,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1290: indexSelectLargeIndex: block: [132,0,0], thread: [49,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1290: indexSelectLargeIndex: block: [132,0,0], thread: [50,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1290: indexSelectLargeIndex: block: [132,0,0], thread: [51,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1290: indexSelectLargeIndex: block: [132,0,0], thread: [52,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1290: indexSelectLargeIndex: block: [132,0,0], thread: [53,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1290: indexSelectLargeIndex: block: [132,0,0], thread: [54,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1290: indexSelectLargeIndex: block: [132,0,0], thread: [55,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1290: indexSelectLargeIndex: block: [132,0,0], thread: [56,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1290: indexSelectLargeIndex: block: [132,0,0], thread: [57,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1290: indexSelectLargeIndex: block: [132,0,0], thread: [58,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1290: indexSelectLargeIndex: block: [132,0,0], thread: [59,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1290: indexSelectLargeIndex: block: [132,0,0], thread: [60,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1290: indexSelectLargeIndex: block: [132,0,0], thread: [61,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1290: indexSelectLargeIndex: block: [132,0,0], thread: [62,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1290: indexSelectLargeIndex: block: [132,0,0], thread: [63,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1290: indexSelectLargeIndex: block: [123,0,0], thread: [96,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1290: indexSelectLargeIndex: block: [123,0,0], thread: [97,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1290: indexSelectLargeIndex: block: [123,0,0], thread: [98,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1290: indexSelectLargeIndex: block: [123,0,0], thread: [99,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1290: indexSelectLargeIndex: block: [123,0,0], thread: [100,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1290: indexSelectLargeIndex: block: [123,0,0], thread: [101,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1290: indexSelectLargeIndex: block: [123,0,0], thread: [102,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1290: indexSelectLargeIndex: block: [123,0,0], thread: [103,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1290: indexSelectLargeIndex: block: [123,0,0], thread: [104,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1290: indexSelectLargeIndex: block: [123,0,0], thread: [105,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1290: indexSelectLargeIndex: block: [123,0,0], thread: [106,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1290: indexSelectLargeIndex: block: [123,0,0], thread: [107,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1290: indexSelectLargeIndex: block: [123,0,0], thread: [108,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1290: indexSelectLargeIndex: block: [123,0,0], thread: [109,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1290: indexSelectLargeIndex: block: [123,0,0], thread: [110,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1290: indexSelectLargeIndex: block: [123,0,0], thread: [111,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1290: indexSelectLargeIndex: block: [123,0,0], thread: [112,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1290: indexSelectLargeIndex: block: [123,0,0], thread: [113,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1290: indexSelectLargeIndex: block: [123,0,0], thread: [114,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1290: indexSelectLargeIndex: block: [123,0,0], thread: [115,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1290: indexSelectLargeIndex: block: [123,0,0], thread: [116,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1290: indexSelectLargeIndex: block: [123,0,0], thread: [117,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1290: indexSelectLargeIndex: block: [123,0,0], thread: [118,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1290: indexSelectLargeIndex: block: [123,0,0], thread: [119,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1290: indexSelectLargeIndex: block: [123,0,0], thread: [120,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1290: indexSelectLargeIndex: block: [123,0,0], thread: [121,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1290: indexSelectLargeIndex: block: [123,0,0], thread: [122,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1290: indexSelectLargeIndex: block: [123,0,0], thread: [123,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1290: indexSelectLargeIndex: block: [123,0,0], thread: [124,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1290: indexSelectLargeIndex: block: [123,0,0], thread: [125,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1290: indexSelectLargeIndex: block: [123,0,0], thread: [126,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1290: indexSelectLargeIndex: block: [123,0,0], thread: [127,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[32], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/torch-env/lib/python3.11/site-packages/transformers/trainer.py:1859\u001B[0m, in \u001B[0;36mTrainer.train\u001B[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001B[0m\n\u001B[1;32m   1857\u001B[0m         hf_hub_utils\u001B[38;5;241m.\u001B[39menable_progress_bars()\n\u001B[1;32m   1858\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1859\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43minner_training_loop\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1860\u001B[0m \u001B[43m        \u001B[49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1861\u001B[0m \u001B[43m        \u001B[49m\u001B[43mresume_from_checkpoint\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mresume_from_checkpoint\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1862\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtrial\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrial\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1863\u001B[0m \u001B[43m        \u001B[49m\u001B[43mignore_keys_for_eval\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mignore_keys_for_eval\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1864\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/torch-env/lib/python3.11/site-packages/transformers/trainer.py:2203\u001B[0m, in \u001B[0;36mTrainer._inner_training_loop\u001B[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001B[0m\n\u001B[1;32m   2200\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcontrol \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcallback_handler\u001B[38;5;241m.\u001B[39mon_step_begin(args, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcontrol)\n\u001B[1;32m   2202\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39maccelerator\u001B[38;5;241m.\u001B[39maccumulate(model):\n\u001B[0;32m-> 2203\u001B[0m     tr_loss_step \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtraining_step\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2205\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[1;32m   2206\u001B[0m     args\u001B[38;5;241m.\u001B[39mlogging_nan_inf_filter\n\u001B[1;32m   2207\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_torch_xla_available()\n\u001B[1;32m   2208\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m (torch\u001B[38;5;241m.\u001B[39misnan(tr_loss_step) \u001B[38;5;129;01mor\u001B[39;00m torch\u001B[38;5;241m.\u001B[39misinf(tr_loss_step))\n\u001B[1;32m   2209\u001B[0m ):\n\u001B[1;32m   2210\u001B[0m     \u001B[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001B[39;00m\n\u001B[1;32m   2211\u001B[0m     tr_loss \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m tr_loss \u001B[38;5;241m/\u001B[39m (\u001B[38;5;241m1\u001B[39m \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mglobal_step \u001B[38;5;241m-\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_globalstep_last_logged)\n",
      "File \u001B[0;32m~/anaconda3/envs/torch-env/lib/python3.11/site-packages/transformers/trainer.py:3138\u001B[0m, in \u001B[0;36mTrainer.training_step\u001B[0;34m(self, model, inputs)\u001B[0m\n\u001B[1;32m   3135\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m loss_mb\u001B[38;5;241m.\u001B[39mreduce_mean()\u001B[38;5;241m.\u001B[39mdetach()\u001B[38;5;241m.\u001B[39mto(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs\u001B[38;5;241m.\u001B[39mdevice)\n\u001B[1;32m   3137\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcompute_loss_context_manager():\n\u001B[0;32m-> 3138\u001B[0m     loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcompute_loss\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   3140\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs\u001B[38;5;241m.\u001B[39mn_gpu \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m   3141\u001B[0m     loss \u001B[38;5;241m=\u001B[39m loss\u001B[38;5;241m.\u001B[39mmean()  \u001B[38;5;66;03m# mean() to average on multi-gpu parallel training\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/envs/torch-env/lib/python3.11/site-packages/trl/trainer/orpo_trainer.py:786\u001B[0m, in \u001B[0;36mORPOTrainer.compute_loss\u001B[0;34m(self, model, inputs, return_outputs)\u001B[0m\n\u001B[1;32m    783\u001B[0m compute_loss_context_manager \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mcuda\u001B[38;5;241m.\u001B[39mamp\u001B[38;5;241m.\u001B[39mautocast \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_peft_has_been_casted_to_bf16 \u001B[38;5;28;01melse\u001B[39;00m nullcontext\n\u001B[1;32m    785\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m compute_loss_context_manager():\n\u001B[0;32m--> 786\u001B[0m     loss, metrics \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_batch_loss_metrics\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_eval\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtrain\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m    788\u001B[0m \u001B[38;5;66;03m# force log the metrics\u001B[39;00m\n\u001B[1;32m    789\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstore_metrics(metrics, train_eval\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/anaconda3/envs/torch-env/lib/python3.11/site-packages/trl/trainer/orpo_trainer.py:746\u001B[0m, in \u001B[0;36mORPOTrainer.get_batch_loss_metrics\u001B[0;34m(self, model, batch, train_eval)\u001B[0m\n\u001B[1;32m    737\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Compute the ORPO loss and other metrics for the given batch of inputs for train or test.\"\"\"\u001B[39;00m\n\u001B[1;32m    738\u001B[0m metrics \u001B[38;5;241m=\u001B[39m {}\n\u001B[1;32m    740\u001B[0m (\n\u001B[1;32m    741\u001B[0m     policy_chosen_logps,\n\u001B[1;32m    742\u001B[0m     policy_rejected_logps,\n\u001B[1;32m    743\u001B[0m     policy_chosen_logits,\n\u001B[1;32m    744\u001B[0m     policy_rejected_logits,\n\u001B[1;32m    745\u001B[0m     policy_nll_loss,\n\u001B[0;32m--> 746\u001B[0m ) \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconcatenated_forward\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    748\u001B[0m losses, chosen_rewards, rejected_rewards, log_odds_ratio, log_odds_chosen \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39modds_ratio_loss(\n\u001B[1;32m    749\u001B[0m     policy_chosen_logps, policy_rejected_logps\n\u001B[1;32m    750\u001B[0m )\n\u001B[1;32m    751\u001B[0m \u001B[38;5;66;03m# full ORPO loss\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/envs/torch-env/lib/python3.11/site-packages/trl/trainer/orpo_trainer.py:686\u001B[0m, in \u001B[0;36mORPOTrainer.concatenated_forward\u001B[0;34m(self, model, batch)\u001B[0m\n\u001B[1;32m    676\u001B[0m len_chosen \u001B[38;5;241m=\u001B[39m batch[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mchosen_labels\u001B[39m\u001B[38;5;124m\"\u001B[39m]\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m    678\u001B[0m model_kwargs \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m    679\u001B[0m     {\n\u001B[1;32m    680\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdecoder_input_ids\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_shift_right(concatenated_batch[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mconcatenated_labels\u001B[39m\u001B[38;5;124m\"\u001B[39m]),\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    683\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m {}\n\u001B[1;32m    684\u001B[0m )\n\u001B[0;32m--> 686\u001B[0m outputs \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    687\u001B[0m \u001B[43m    \u001B[49m\u001B[43mconcatenated_batch\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mconcatenated_input_ids\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    688\u001B[0m \u001B[43m    \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconcatenated_batch\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mconcatenated_attention_mask\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    689\u001B[0m \u001B[43m    \u001B[49m\u001B[43muse_cache\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    690\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mmodel_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    691\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    692\u001B[0m all_logits \u001B[38;5;241m=\u001B[39m outputs\u001B[38;5;241m.\u001B[39mlogits\n\u001B[1;32m    694\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcross_entropy_loss\u001B[39m(logits, labels):\n",
      "File \u001B[0;32m~/anaconda3/envs/torch-env/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1509\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1510\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1511\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/torch-env/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1515\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1516\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1518\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1519\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1520\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1523\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/envs/torch-env/lib/python3.11/site-packages/peft/peft_model.py:1129\u001B[0m, in \u001B[0;36mPeftModelForCausalLM.forward\u001B[0;34m(self, input_ids, attention_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict, task_ids, **kwargs)\u001B[0m\n\u001B[1;32m   1127\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_enable_peft_forward_hooks(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m   1128\u001B[0m         kwargs \u001B[38;5;241m=\u001B[39m {k: v \u001B[38;5;28;01mfor\u001B[39;00m k, v \u001B[38;5;129;01min\u001B[39;00m kwargs\u001B[38;5;241m.\u001B[39mitems() \u001B[38;5;28;01mif\u001B[39;00m k \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mspecial_peft_forward_args}\n\u001B[0;32m-> 1129\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbase_model\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1130\u001B[0m \u001B[43m            \u001B[49m\u001B[43minput_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minput_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1131\u001B[0m \u001B[43m            \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1132\u001B[0m \u001B[43m            \u001B[49m\u001B[43minputs_embeds\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs_embeds\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1133\u001B[0m \u001B[43m            \u001B[49m\u001B[43mlabels\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlabels\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1134\u001B[0m \u001B[43m            \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1135\u001B[0m \u001B[43m            \u001B[49m\u001B[43moutput_hidden_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1136\u001B[0m \u001B[43m            \u001B[49m\u001B[43mreturn_dict\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_dict\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1137\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1138\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1140\u001B[0m batch_size \u001B[38;5;241m=\u001B[39m _get_batch_size(input_ids, inputs_embeds)\n\u001B[1;32m   1141\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m attention_mask \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m   1142\u001B[0m     \u001B[38;5;66;03m# concat prompt attention mask\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/envs/torch-env/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1509\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1510\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1511\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/torch-env/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1515\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1516\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1518\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1519\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1520\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1523\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/envs/torch-env/lib/python3.11/site-packages/peft/tuners/tuners_utils.py:161\u001B[0m, in \u001B[0;36mBaseTuner.forward\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    160\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs: Any, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: Any):\n\u001B[0;32m--> 161\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mforward\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/torch-env/lib/python3.11/site-packages/accelerate/hooks.py:166\u001B[0m, in \u001B[0;36madd_hook_to_module.<locals>.new_forward\u001B[0;34m(module, *args, **kwargs)\u001B[0m\n\u001B[1;32m    164\u001B[0m         output \u001B[38;5;241m=\u001B[39m module\u001B[38;5;241m.\u001B[39m_old_forward(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    165\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 166\u001B[0m     output \u001B[38;5;241m=\u001B[39m \u001B[43mmodule\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_old_forward\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    167\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m module\u001B[38;5;241m.\u001B[39m_hf_hook\u001B[38;5;241m.\u001B[39mpost_forward(module, output)\n",
      "File \u001B[0;32m~/anaconda3/envs/torch-env/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:1208\u001B[0m, in \u001B[0;36mLlamaForCausalLM.forward\u001B[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001B[0m\n\u001B[1;32m   1205\u001B[0m return_dict \u001B[38;5;241m=\u001B[39m return_dict \u001B[38;5;28;01mif\u001B[39;00m return_dict \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39muse_return_dict\n\u001B[1;32m   1207\u001B[0m \u001B[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001B[39;00m\n\u001B[0;32m-> 1208\u001B[0m outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1209\u001B[0m \u001B[43m    \u001B[49m\u001B[43minput_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minput_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1210\u001B[0m \u001B[43m    \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1211\u001B[0m \u001B[43m    \u001B[49m\u001B[43mposition_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mposition_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1212\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpast_key_values\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpast_key_values\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1213\u001B[0m \u001B[43m    \u001B[49m\u001B[43minputs_embeds\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs_embeds\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1214\u001B[0m \u001B[43m    \u001B[49m\u001B[43muse_cache\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_cache\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1215\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1216\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_hidden_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1217\u001B[0m \u001B[43m    \u001B[49m\u001B[43mreturn_dict\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_dict\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1218\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcache_position\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcache_position\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1219\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1221\u001B[0m hidden_states \u001B[38;5;241m=\u001B[39m outputs[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m   1222\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mpretraining_tp \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n",
      "File \u001B[0;32m~/anaconda3/envs/torch-env/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1509\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1510\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1511\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/torch-env/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1515\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1516\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1518\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1519\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1520\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1523\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/envs/torch-env/lib/python3.11/site-packages/accelerate/hooks.py:166\u001B[0m, in \u001B[0;36madd_hook_to_module.<locals>.new_forward\u001B[0;34m(module, *args, **kwargs)\u001B[0m\n\u001B[1;32m    164\u001B[0m         output \u001B[38;5;241m=\u001B[39m module\u001B[38;5;241m.\u001B[39m_old_forward(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    165\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 166\u001B[0m     output \u001B[38;5;241m=\u001B[39m \u001B[43mmodule\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_old_forward\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    167\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m module\u001B[38;5;241m.\u001B[39m_hf_hook\u001B[38;5;241m.\u001B[39mpost_forward(module, output)\n",
      "File \u001B[0;32m~/anaconda3/envs/torch-env/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:992\u001B[0m, in \u001B[0;36mLlamaModel.forward\u001B[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001B[0m\n\u001B[1;32m    989\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m position_ids \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    990\u001B[0m     position_ids \u001B[38;5;241m=\u001B[39m cache_position\u001B[38;5;241m.\u001B[39munsqueeze(\u001B[38;5;241m0\u001B[39m)\n\u001B[0;32m--> 992\u001B[0m causal_mask \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_update_causal_mask\u001B[49m\u001B[43m(\u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs_embeds\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcache_position\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpast_seen_tokens\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    994\u001B[0m \u001B[38;5;66;03m# embed positions\u001B[39;00m\n\u001B[1;32m    995\u001B[0m hidden_states \u001B[38;5;241m=\u001B[39m inputs_embeds\n",
      "File \u001B[0;32m~/anaconda3/envs/torch-env/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:1069\u001B[0m, in \u001B[0;36mLlamaModel._update_causal_mask\u001B[0;34m(self, attention_mask, input_tensor, cache_position, past_seen_tokens)\u001B[0m\n\u001B[1;32m   1056\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_update_causal_mask\u001B[39m(\n\u001B[1;32m   1057\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m   1058\u001B[0m     attention_mask: torch\u001B[38;5;241m.\u001B[39mTensor,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1065\u001B[0m     \u001B[38;5;66;03m# (`recording cudagraph tree for symint key 13`, etc.), which is VERY slow. A workaround is `@torch.compiler.disable`, but this prevents using\u001B[39;00m\n\u001B[1;32m   1066\u001B[0m     \u001B[38;5;66;03m# `fullgraph=True`. See more context in https://github.com/huggingface/transformers/pull/29114\u001B[39;00m\n\u001B[1;32m   1068\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39m_attn_implementation \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mflash_attention_2\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m-> 1069\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m attention_mask \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;241;43m0.0\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mattention_mask\u001B[49m:\n\u001B[1;32m   1070\u001B[0m             \u001B[38;5;28;01mreturn\u001B[39;00m attention_mask\n\u001B[1;32m   1071\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/envs/torch-env/lib/python3.11/site-packages/torch/_tensor.py:1091\u001B[0m, in \u001B[0;36mTensor.__contains__\u001B[0;34m(self, element)\u001B[0m\n\u001B[1;32m   1086\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(Tensor\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__contains__\u001B[39m, (\u001B[38;5;28mself\u001B[39m,), \u001B[38;5;28mself\u001B[39m, element)\n\u001B[1;32m   1087\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(\n\u001B[1;32m   1088\u001B[0m     element, (torch\u001B[38;5;241m.\u001B[39mTensor, Number, torch\u001B[38;5;241m.\u001B[39mSymInt, torch\u001B[38;5;241m.\u001B[39mSymFloat, torch\u001B[38;5;241m.\u001B[39mSymBool)\n\u001B[1;32m   1089\u001B[0m ):\n\u001B[1;32m   1090\u001B[0m     \u001B[38;5;66;03m# type hint doesn't understand the __contains__ result array\u001B[39;00m\n\u001B[0;32m-> 1091\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m(\u001B[49m\u001B[43melement\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m==\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43many\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mitem\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# type: ignore[union-attr]\u001B[39;00m\n\u001B[1;32m   1093\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[1;32m   1094\u001B[0m     \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTensor.__contains__ only supports Tensor or scalar, but you passed in a \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mtype\u001B[39m(element)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1095\u001B[0m )\n",
      "\u001B[0;31mRuntimeError\u001B[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "cell_type": "code",
   "source": [
    "wandb.finish()\n",
    "trainer.save_model(model_name)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "f4b2fdcf617359a4",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "## Inference after Training",
   "metadata": {
    "collapsed": false
   },
   "id": "4ec24bf55b44834d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "system_prompt = \"You are a helpful assistant. Respond to the following user prompt. Use Korean only. 한국어만 사용하세요.\"",
   "id": "d35aa851e8176d2d",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "#user_prompt = \"Write me a poem about Machine Learning.\"\n",
    "user_prompt = \"머신러닝에 대한 시를 써주세요.\""
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "bcba8c32d5f5469f",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "response = generate_response(system_prompt, user_prompt)\n",
    "print(response)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "1219dfd08fc2facd",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Upload Model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ae7bc882cc302767"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Flush memory\n",
    "import gc\n",
    "\n",
    "del trainer, model\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ],
   "id": "5328afb28569c151",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# Reload model in FP16 and merge it with LoRA weights\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    device_map=device,\n",
    "    torch_dtype=torch.float16\n",
    ")\n",
    "model = PeftModel.from_pretrained(base_model, model_name)\n",
    "model = model.merge_and_unload()"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "57bcdb4c1c233116",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# Reload tokenizer to save it\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\""
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "db819b259928e006",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# Push model and tokenizer to Hugging Face Hub\n",
    "model.push_to_hub(\n",
    "    repo_id=repo_id,\n",
    "    use_temp_dir=False\n",
    ")\n",
    "tokenizer.push_to_hub(\n",
    "    repo_id=repo_id,\n",
    "    use_temp_dir=False\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "43aa8d6999c41016",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
