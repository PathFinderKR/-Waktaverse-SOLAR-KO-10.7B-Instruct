{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Importing Libraries",
   "id": "ac75bbafc649a044"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-17T05:12:07.579873Z",
     "start_time": "2024-05-17T05:12:05.022306Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "# pytorch\n",
    "import torch\n",
    "\n",
    "# huggingface\n",
    "from huggingface_hub import login\n",
    "from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "import evaluate\n",
    "from datasets import Audio, load_dataset, DatasetDict\n",
    "\n",
    "# wandb\n",
    "import wandb"
   ],
   "id": "fbbf7dc485d2e81d",
   "execution_count": 4,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Login to Hugging Face",
   "id": "ba734f4553b55bde"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": 1,
   "source": [
    "load_dotenv()\n",
    "token = os.getenv(\"HUGGINGFACE_TOKEN\")\n",
    "login(\n",
    "    token=token,  # ADD YOUR TOKEN HERE\n",
    "    add_to_git_credential=True\n",
    ")"
   ],
   "id": "initial_id"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "74f9c395dc73b9ed"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": 2,
   "source": [
    "model_name = \"Waktaverse-whisper-KO-large-v3\"  # ADD YOUR MODEL NAME HERE\n",
    "username = \"PathFinderKR\"  # ADD YOUR USERNAME HERE\n",
    "repo_id = f\"{username}/{model_name}\"  # repository id"
   ],
   "id": "10278940e0efdeef"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Login to Weights & Biases",
   "id": "bda17620db56f7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": 3,
   "source": [
    "api_key = os.getenv(\"WANDB_API_KEY\")\n",
    "wandb.login(\n",
    "    key=api_key  # ADD YOUR API KEY HERE\n",
    ")\n",
    "wandb.init(project=model_name)"
   ],
   "id": "4bd928034393af5c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Device",
   "id": "64b0506e05ceda89"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-17T05:12:07.755054Z",
     "start_time": "2024-05-17T05:12:07.580978Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Device setup\n",
    "device = (\n",
    "    \"cuda:0\" if torch.cuda.is_available() else # Nvidia GPU\n",
    "    #\"mps\" if torch.backends.mps.is_available() else # Apple Silicon GPU\n",
    "    \"cpu\"\n",
    ")\n",
    "print(f\"Device = {device}\")"
   ],
   "id": "d9854d2cc03800ce",
   "execution_count": 5,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-17T05:12:07.763401Z",
     "start_time": "2024-05-17T05:12:07.756191Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Flash Attention Implementation\n",
    "if device == \"cuda:0\":\n",
    "    if torch.cuda.get_device_capability()[0] >= 8: # Ampere, Ada, or Hopper GPUs\n",
    "        attn_implementation = \"flash_attention_2\"\n",
    "        torch_dtype = torch.float16\n",
    "    else:\n",
    "        attn_implementation = \"eager\"\n",
    "        torch_dtype = torch.float16\n",
    "else:\n",
    "    attn_implementation = \"eager\"\n",
    "    torch_dtype = torch.float32\n",
    "print(f\"Attention Implementation = {attn_implementation}\")"
   ],
   "id": "71e388c237d897cb",
   "execution_count": 6,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Hyperparameters",
   "id": "e5738bbdd3f5609a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-17T05:12:07.769870Z",
     "start_time": "2024-05-17T05:12:07.764547Z"
    }
   },
   "cell_type": "code",
   "source": [
    "################################################################################\n",
    "# Language\n",
    "################################################################################\n",
    "language = \"Korean\"\n",
    "language_code = \"ko\"\n",
    "\n",
    "################################################################################\n",
    "# Generation parameters\n",
    "################################################################################\n",
    "max_new_tokens=100\n",
    "chunk_length_s=30\n",
    "batch_size=4\n",
    "sampling_rate=16000\n",
    "\n",
    "################################################################################\n",
    "# Training parameters\n",
    "################################################################################\n",
    "output_dir=\"./results\"\n",
    "logging_dir=\"./logs\"\n",
    "save_strategy=\"epoch\"\n",
    "logging_strategy=\"steps\" # \"steps\", \"epoch\"\n",
    "if logging_strategy == \"steps\":\n",
    "    logging_steps=10\n",
    "else:\n",
    "    logging_steps=None\n",
    "evaluation_strategy=\"epoch\" # \"steps\", \"epoch\"\n",
    "load_best_model_at_end=True\n",
    "metric_for_best_model=\"wer\"\n",
    "greater_is_better=False\n",
    "save_total_limit=1\n",
    "report_to=\"wandb\"\n",
    "\n",
    "num_train_epochs=2\n",
    "per_device_train_batch_size=4\n",
    "gradient_accumulation_steps=4\n",
    "gradient_checkpointing=True\n",
    "learning_rate=2e-5\n",
    "lr_scheduler_type=\"cosine\" # \"constant\", \"linear\", \"cosine\"\n",
    "warmup_ratio=0.1\n",
    "optim = \"adamw_torch\"\n",
    "weight_decay=0.01"
   ],
   "id": "61fc426f76f3fb64",
   "execution_count": 7,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Model",
   "id": "35917c1f0e8f3b30"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-17T05:12:07.778573Z",
     "start_time": "2024-05-17T05:12:07.771052Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Model ID for base model\n",
    "model_id = \"openai/whisper-large-v3\""
   ],
   "id": "375bedeb9583aa27",
   "execution_count": 8,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-17T05:12:11.183241Z",
     "start_time": "2024-05-17T05:12:07.779757Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# load model and processor\n",
    "processor = AutoProcessor.from_pretrained(model_id)\n",
    "model = AutoModelForSpeechSeq2Seq.from_pretrained(\n",
    "    model_id,\n",
    "    device_map=device,\n",
    "    #attn_implementation=attn_implementation,\n",
    "    torch_dtype=torch_dtype,\n",
    "    low_cpu_mem_usage=True,\n",
    "    use_safetensors=True\n",
    ")"
   ],
   "id": "71aa4496f9217519",
   "execution_count": 9,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-17T05:12:11.191605Z",
     "start_time": "2024-05-17T05:12:11.185492Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Display the model architecture\n",
    "display(Markdown(f'```{model}```'))"
   ],
   "id": "8ed2c02ce4f9caf5",
   "execution_count": 10,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Dataset",
   "id": "10bdc2fc57dfc32a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-17T05:12:11.202724Z",
     "start_time": "2024-05-17T05:12:11.192680Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Dataset ID\n",
    "dataset_id = \"mozilla-foundation/common_voice_17_0\""
   ],
   "id": "20e707e9f8a94299",
   "execution_count": 11,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-17T05:12:20.633793Z",
     "start_time": "2024-05-17T05:12:11.203846Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load dataset\n",
    "dataset = DatasetDict()\n",
    "dataset[\"train\"] = load_dataset(dataset_id, language_code, split=\"train\", trust_remote_code=True)\n",
    "dataset[\"validation\"] = load_dataset(dataset_id, language_code, split=\"validation\", trust_remote_code=True)\n",
    "dataset[\"test\"] = load_dataset(dataset_id, language_code, split=\"test\", trust_remote_code=True)"
   ],
   "id": "a36a3cbea836d472",
   "execution_count": 12,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-17T05:12:20.638409Z",
     "start_time": "2024-05-17T05:12:20.634833Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Dataset information\n",
    "dataset"
   ],
   "id": "5f0b998f9d148e0c",
   "execution_count": 13,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-17T05:12:21.128905Z",
     "start_time": "2024-05-17T05:12:20.639312Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Dataset sample\n",
    "dataset[\"train\"][0]"
   ],
   "id": "e7fb9919f52c2e85",
   "execution_count": 14,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-17T05:12:21.151264Z",
     "start_time": "2024-05-17T05:12:21.129983Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Tokenization sample\n",
    "tokenized_sentence = processor.tokenizer(dataset[\"train\"][0][\"sentence\"])\n",
    "decoded_sentence = processor.tokenizer.decode(tokenized_sentence[\"input_ids\"])\n",
    "\n",
    "print(f\"Tokenized Sentence: {tokenized_sentence}\")\n",
    "print(f\"Decoded Sentence: {decoded_sentence}\")"
   ],
   "id": "f705e5fc7a9114aa",
   "execution_count": 15,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Preprocessing",
   "id": "2118b20fdd3597c2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-17T05:12:22.634443Z",
     "start_time": "2024-05-17T05:12:21.152350Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Down sample audio\n",
    "def preprocess_function(examples):\n",
    "    audio = examples[\"audio\"]\n",
    "    \n",
    "    examples[\"input_features\"] = processor.feature_extractor(audio[\"array\"], sampling_rate=sampling_rate).input_features[0]\n",
    "    examples[\"labels\"] = processor.tokenizer(examples[\"sentence\"], return_tensors=\"pt\").input_ids\n",
    "    \n",
    "    return examples\n",
    "\n",
    "# Preprocess dataset\n",
    "dataset = dataset.map(preprocess_function, remove_columns=dataset.column_names[\"train\"], num_proc=4)"
   ],
   "id": "f9a90db19293a62c",
   "execution_count": 16,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-17T05:12:22.639722Z",
     "start_time": "2024-05-17T05:12:22.635454Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from typing import Any, Dict, List, Union\n",
    "\n",
    "@dataclass\n",
    "class DataCollatorSpeechSeq2SeqWithPadding:\n",
    "    processor: Any\n",
    "    decoder_start_token_id: int\n",
    "\n",
    "    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n",
    "        # split inputs and labels since they have to be of different lengths and need different padding methods\n",
    "        # first treat the audio inputs by simply returning torch tensors\n",
    "        input_features = [{\"input_features\": feature[\"input_features\"]} for feature in features]\n",
    "        batch = self.processor.feature_extractor.pad(input_features, return_tensors=\"pt\")\n",
    "\n",
    "        # get the tokenized label sequences\n",
    "        label_features = [{\"input_ids\": feature[\"labels\"]} for feature in features]\n",
    "        # pad the labels to max length\n",
    "        labels_batch = self.processor.tokenizer.pad(label_features, return_tensors=\"pt\")\n",
    "\n",
    "        # replace padding with -100 to ignore loss correctly\n",
    "        labels = labels_batch[\"input_ids\"].masked_fill(labels_batch.attention_mask.ne(1), -100)\n",
    "\n",
    "        # if bos token is appended in previous tokenization step,\n",
    "        # cut bos token here as it's append later anyways\n",
    "        if (labels[:, 0] == self.decoder_start_token_id).all().cpu().item():\n",
    "            labels = labels[:, 1:]\n",
    "\n",
    "        batch[\"labels\"] = labels\n",
    "\n",
    "        return batch\n"
   ],
   "id": "27f8990f04dbb239",
   "execution_count": 17,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Inference",
   "id": "61930d88aaf1efaa"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-17T05:12:22.650548Z",
     "start_time": "2024-05-17T05:12:22.640684Z"
    }
   },
   "cell_type": "code",
   "source": [
    "pipe = pipeline(\n",
    "    \"automatic-speech-recognition\",\n",
    "    model=model,\n",
    "    tokenizer=processor.tokenizer,\n",
    "    feature_extractor=processor.feature_extractor,\n",
    "    torch_dtype=torch_dtype,\n",
    "    return_timestamps=True,\n",
    "\n",
    "    max_new_tokens=max_new_tokens,\n",
    "    chunk_length_s=chunk_length_s,\n",
    "    batch_size=batch_size\n",
    ")"
   ],
   "id": "53dae8b4956d9ba3",
   "execution_count": 18,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-17T05:12:22.657258Z",
     "start_time": "2024-05-17T05:12:22.651841Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def speech_recognition(audio):\n",
    "    text = pipe(audio)[\"text\"]\n",
    "    return text"
   ],
   "id": "a126faa15071f557",
   "execution_count": 19,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-17T05:12:23.288494Z",
     "start_time": "2024-05-17T05:12:22.658358Z"
    }
   },
   "cell_type": "code",
   "source": "result = speech_recognition(dataset[\"train\"][0])",
   "id": "44f5df47d8de171f",
   "execution_count": 20,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "result",
   "id": "43c0e16d084c136e",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Training",
   "id": "f42358f2f99e5e28"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-17T05:12:31.225059Z",
     "start_time": "2024-05-17T05:12:31.221016Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def compute_metrics(pred):\n",
    "    metric = evaluate.load(\"wer\")\n",
    "    \n",
    "    pred_ids = pred.predictions\n",
    "    label_ids = pred.label_ids\n",
    "    \n",
    "    label_ids[label_ids == -100] = processor.tokenizer.pad_token_id\n",
    "    \n",
    "    pred_str = processor.tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n",
    "    label_str = processor.tokenizer.batch_decode(label_ids, skip_special_tokens=True)\n",
    "    \n",
    "    wer = 100 * metric.compute(predictions=pred_str, references=label_str)\n",
    "    \n",
    "    return {\"wer\": wer}"
   ],
   "id": "3ffcda9748086a84",
   "execution_count": 21,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-17T05:12:31.848089Z",
     "start_time": "2024-05-17T05:12:31.771251Z"
    }
   },
   "cell_type": "code",
   "source": [
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    logging_dir=logging_dir,\n",
    "    save_strategy=save_strategy,\n",
    "    logging_strategy=logging_strategy,\n",
    "    logging_steps=logging_steps,\n",
    "    evaluation_strategy=evaluation_strategy,\n",
    "    load_best_model_at_end=load_best_model_at_end,\n",
    "    metric_for_best_model=metric_for_best_model,\n",
    "    greater_is_better=greater_is_better,\n",
    "    save_total_limit=save_total_limit,\n",
    "    report_to=report_to,\n",
    "    \n",
    "    num_train_epochs=num_train_epochs,\n",
    "    per_device_train_batch_size=per_device_train_batch_size,\n",
    "    gradient_accumulation_steps=gradient_accumulation_steps,\n",
    "    gradient_checkpointing=gradient_checkpointing,\n",
    "    learning_rate=learning_rate,\n",
    "    lr_scheduler_type=lr_scheduler_type,\n",
    "    warmup_ratio=warmup_ratio,\n",
    "    optim=optim,\n",
    "    weight_decay=weight_decay\n",
    ")"
   ],
   "id": "5629ae0c796e3ccb",
   "execution_count": 22,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-17T05:13:39.518899Z",
     "start_time": "2024-05-17T05:13:39.499348Z"
    }
   },
   "cell_type": "code",
   "source": [
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    tokenizer=processor.feature_extractor,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset[\"train\"],\n",
    "    eval_dataset=dataset[\"validation\"],\n",
    "   #data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ],
   "id": "6fa46f2dc9990141",
   "execution_count": 27,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-17T05:13:19.615063Z",
     "start_time": "2024-05-17T05:13:18.904740Z"
    }
   },
   "cell_type": "code",
   "source": "trainer.train()",
   "id": "f50d13a926cb24ee",
   "execution_count": 26,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "79b5e7a906ad306d",
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
