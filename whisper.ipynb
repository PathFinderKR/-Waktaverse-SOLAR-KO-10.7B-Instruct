{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Login to Hugging Face",
   "id": "ba734f4553b55bde"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-16T02:33:17.401743Z",
     "start_time": "2024-05-16T02:33:16.878171Z"
    }
   },
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from huggingface_hub import login\n",
    "\n",
    "load_dotenv()\n",
    "token = os.getenv(\"HUGGINGFACE_TOKEN\")\n",
    "login(\n",
    "    token=token,  # ADD YOUR TOKEN HERE\n",
    "    add_to_git_credential=True\n",
    ")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token is valid (permission: write).\n",
      "Your token has been saved in your configured git credential helpers (store).\n",
      "Your token has been saved to /home/pathfinder/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "74f9c395dc73b9ed"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-16T02:33:17.405468Z",
     "start_time": "2024-05-16T02:33:17.403178Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_name = \"Waktaverse-whisper-KO-large-v3\"  # ADD YOUR MODEL NAME HERE\n",
    "username = \"PathFinderKR\"  # ADD YOUR USERNAME HERE\n",
    "repo_id = f\"{username}/{model_name}\"  # repository id"
   ],
   "id": "10278940e0efdeef",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Login to Weights & Biases",
   "id": "bda17620db56f7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-16T02:33:22.170726Z",
     "start_time": "2024-05-16T02:33:17.406423Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import wandb\n",
    "\n",
    "api_key = os.getenv(\"WANDB_API_KEY\")\n",
    "wandb.login(\n",
    "    key=api_key  # ADD YOUR API KEY HERE\n",
    ")\n",
    "wandb.init(project=model_name)"
   ],
   "id": "4bd928034393af5c",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33mpathfinderkr\u001B[0m (\u001B[33mwaktaverse\u001B[0m). Use \u001B[1m`wandb login --relogin`\u001B[0m to force relogin\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \u001B[33mWARNING\u001B[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \u001B[33mWARNING\u001B[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Appending key for api.wandb.ai to your netrc file: /home/pathfinder/.netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Tracking run with wandb version 0.17.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Run data is saved locally in <code>/mnt/c/Users/cheir/GitHub/Waktaverse-LLM/wandb/run-20240516_113319-7xsfdsmy</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/waktaverse/Waktaverse-whisper-KO-large-v3/runs/7xsfdsmy' target=\"_blank\">eager-shape-1</a></strong> to <a href='https://wandb.ai/waktaverse/Waktaverse-whisper-KO-large-v3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View project at <a href='https://wandb.ai/waktaverse/Waktaverse-whisper-KO-large-v3' target=\"_blank\">https://wandb.ai/waktaverse/Waktaverse-whisper-KO-large-v3</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run at <a href='https://wandb.ai/waktaverse/Waktaverse-whisper-KO-large-v3/runs/7xsfdsmy' target=\"_blank\">https://wandb.ai/waktaverse/Waktaverse-whisper-KO-large-v3/runs/7xsfdsmy</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/waktaverse/Waktaverse-whisper-KO-large-v3/runs/7xsfdsmy?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7fc25863a050>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Imports",
   "id": "ac75bbafc649a044"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-16T02:33:24.922895Z",
     "start_time": "2024-05-16T02:33:22.172118Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "# pytorch\n",
    "import torch\n",
    "\n",
    "# huggingface\n",
    "from transformers import (\n",
    "    AutoModelForSpeechSeq2Seq,\n",
    "    AutoProcessor,\n",
    "    pipeline,\n",
    "    Seq2SeqTrainingArguments,\n",
    "    Seq2SeqTrainer\n",
    ")\n",
    "\n",
    "# datasets\n",
    "from datasets import Audio, load_dataset, DatasetDict"
   ],
   "id": "fbbf7dc485d2e81d",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Device",
   "id": "64b0506e05ceda89"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-16T02:33:24.928491Z",
     "start_time": "2024-05-16T02:33:24.924216Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Device setup\n",
    "device = (\n",
    "    \"cuda:0\" if torch.cuda.is_available() else # Nvidia GPU\n",
    "    \"mps\" if torch.backends.mps.is_available() else # Apple Silicon GPU\n",
    "    \"cpu\"\n",
    ")\n",
    "print(f\"Device = {device}\")"
   ],
   "id": "d9854d2cc03800ce",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device = cuda:0\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-16T02:33:24.937050Z",
     "start_time": "2024-05-16T02:33:24.929620Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Flash Attention Implementation\n",
    "if device == \"cuda:0\":\n",
    "    if torch.cuda.get_device_capability()[0] >= 8: # Ampere, Ada, or Hopper GPUs\n",
    "        attn_implementation = \"flash_attention_2\"\n",
    "        torch_dtype = torch.float16\n",
    "    else:\n",
    "        attn_implementation = \"eager\"\n",
    "        torch_dtype = torch.float16\n",
    "else:\n",
    "    attn_implementation = \"eager\"\n",
    "    torch_dtype = torch.float32\n",
    "print(f\"Attention Implementation = {attn_implementation}\")"
   ],
   "id": "71e388c237d897cb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention Implementation = flash_attention_2\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Hyperparameters",
   "id": "e5738bbdd3f5609a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-16T02:33:24.944384Z",
     "start_time": "2024-05-16T02:33:24.938573Z"
    }
   },
   "cell_type": "code",
   "source": [
    "################################################################################\n",
    "# Language\n",
    "################################################################################\n",
    "language = \"Korean\"\n",
    "language_code = \"ko\"\n",
    "\n",
    "################################################################################\n",
    "# seed\n",
    "################################################################################\n",
    "seed=42\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "################################################################################\n",
    "# Generation parameters\n",
    "################################################################################\n",
    "max_new_tokens=100\n",
    "chunk_length_s=30\n",
    "batch_size=4\n",
    "\n",
    "################################################################################\n",
    "# Training parameters\n",
    "################################################################################\n",
    "output_dir=\"./results\"\n",
    "logging_dir=\"./logs\"\n",
    "save_strategy=\"epoch\"\n",
    "logging_strategy=\"steps\" # \"steps\", \"epoch\"\n",
    "if logging_strategy == \"steps\":\n",
    "    logging_steps=10\n",
    "else:\n",
    "    logging_steps=None\n",
    "save_total_limit=1\n",
    "report_to=\"wandb\"\n",
    "\n",
    "num_train_epochs=2\n",
    "per_device_train_batch_size=4\n",
    "gradient_accumulation_steps=4\n",
    "gradient_checkpointing=True\n",
    "learning_rate=2e-5\n",
    "lr_scheduler_type=\"cosine\" # \"constant\", \"linear\", \"cosine\"\n",
    "warmup_ratio=0.1\n",
    "optim = \"adamw_torch\"\n",
    "weight_decay=0.01"
   ],
   "id": "61fc426f76f3fb64",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Model",
   "id": "35917c1f0e8f3b30"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-16T02:33:24.953857Z",
     "start_time": "2024-05-16T02:33:24.945655Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Model ID for base model\n",
    "model_id = \"openai/whisper-large-v3\""
   ],
   "id": "375bedeb9583aa27",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-16T02:33:39.323763Z",
     "start_time": "2024-05-16T02:33:24.955128Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# load model and processor\n",
    "processor = AutoProcessor.from_pretrained(model_id)\n",
    "model = AutoModelForSpeechSeq2Seq.from_pretrained(\n",
    "    model_id,\n",
    "    device_map=device,\n",
    "    attn_implementation=attn_implementation,\n",
    "    torch_dtype=torch_dtype,\n",
    "    low_cpu_mem_usage=True,\n",
    "    use_safetensors=True\n",
    ")"
   ],
   "id": "71aa4496f9217519",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-16T02:34:07.278092Z",
     "start_time": "2024-05-16T02:34:07.272112Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Display the model architecture\n",
    "display(Markdown(f'```{model}```'))"
   ],
   "id": "8ed2c02ce4f9caf5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "```WhisperForConditionalGeneration(\n  (model): WhisperModel(\n    (encoder): WhisperEncoder(\n      (conv1): Conv1d(128, 1280, kernel_size=(3,), stride=(1,), padding=(1,))\n      (conv2): Conv1d(1280, 1280, kernel_size=(3,), stride=(2,), padding=(1,))\n      (embed_positions): Embedding(1500, 1280)\n      (layers): ModuleList(\n        (0-31): 32 x WhisperEncoderLayer(\n          (self_attn): WhisperFlashAttention2(\n            (k_proj): Linear(in_features=1280, out_features=1280, bias=False)\n            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n          )\n          (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n          (activation_fn): GELUActivation()\n          (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n          (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n          (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n        )\n      )\n      (layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n    )\n    (decoder): WhisperDecoder(\n      (embed_tokens): Embedding(51866, 1280, padding_idx=50256)\n      (embed_positions): WhisperPositionalEmbedding(448, 1280)\n      (layers): ModuleList(\n        (0-31): 32 x WhisperDecoderLayer(\n          (self_attn): WhisperFlashAttention2(\n            (k_proj): Linear(in_features=1280, out_features=1280, bias=False)\n            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n          )\n          (activation_fn): GELUActivation()\n          (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n          (encoder_attn): WhisperFlashAttention2(\n            (k_proj): Linear(in_features=1280, out_features=1280, bias=False)\n            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n          )\n          (encoder_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n          (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n          (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n          (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n        )\n      )\n      (layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n    )\n  )\n  (proj_out): Linear(in_features=1280, out_features=51866, bias=False)\n)```"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Dataset",
   "id": "10bdc2fc57dfc32a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": 10,
   "source": [
    "# Dataset ID\n",
    "dataset_id = \"mozilla-foundation/common_voice_17_0\""
   ],
   "id": "20e707e9f8a94299"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pathfinder/anaconda3/envs/torch-env/lib/python3.11/site-packages/datasets/load.py:1486: FutureWarning: The repository for mozilla-foundation/common_voice_17_0 contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/mozilla-foundation/common_voice_17_0\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 11,
   "source": [
    "# Load dataset\n",
    "dataset = DatasetDict()\n",
    "dataset[\"train\"] = load_dataset(dataset_id, language_code, split=\"train\", streaming=True)\n",
    "dataset[\"validation\"] = load_dataset(dataset_id, language_code, split=\"validation\", streaming=True)\n",
    "dataset[\"test\"] = load_dataset(dataset_id, language_code, split=\"test\", streaming=True)"
   ],
   "id": "a36a3cbea836d472"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: IterableDataset({\n",
       "        features: ['client_id', 'path', 'audio', 'sentence', 'up_votes', 'down_votes', 'age', 'gender', 'accent', 'locale', 'segment', 'variant'],\n",
       "        n_shards: 1\n",
       "    })\n",
       "    validation: IterableDataset({\n",
       "        features: ['client_id', 'path', 'audio', 'sentence', 'up_votes', 'down_votes', 'age', 'gender', 'accent', 'locale', 'segment', 'variant'],\n",
       "        n_shards: 1\n",
       "    })\n",
       "    test: IterableDataset({\n",
       "        features: ['client_id', 'path', 'audio', 'sentence', 'up_votes', 'down_votes', 'age', 'gender', 'accent', 'locale', 'segment', 'variant'],\n",
       "        n_shards: 1\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12,
   "source": [
    "# Dataset information\n",
    "dataset"
   ],
   "id": "5f0b998f9d148e0c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Inference",
   "id": "61930d88aaf1efaa"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "input_str = common_voice[\"train\"][0][\"sentence\"]\n",
    "labels = tokenizer(input_str).input_ids\n",
    "decoded_with_special = tokenizer.decode(labels, skip_special_tokens=False)\n",
    "decoded_str = tokenizer.decode(labels, skip_special_tokens=True)\n",
    "\n",
    "print(f\"Input:                 {input_str}\")\n",
    "print(f\"Decoded w/ special:    {decoded_with_special}\")\n",
    "print(f\"Decoded w/out special: {decoded_str}\")\n",
    "print(f\"Are equal:             {input_str == decoded_str}\")\n"
   ],
   "id": "e66e093278495832"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-16T02:34:29.701554Z",
     "start_time": "2024-05-16T02:34:29.698430Z"
    }
   },
   "cell_type": "code",
   "source": [
    "pipe = pipeline(\n",
    "    \"automatic-speech-recognition\",\n",
    "    model=model,\n",
    "    tokenizer=processor.tokenizer,\n",
    "    feature_extractor=processor.feature_extractor,\n",
    "    torch_dtype=torch_dtype,\n",
    "    return_timestamps=True,\n",
    "\n",
    "    max_new_tokens=max_new_tokens,\n",
    "    chunk_length_s=chunk_length_s,\n",
    "    batch_size=batch_size\n",
    ")"
   ],
   "id": "53dae8b4956d9ba3",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-16T02:34:42.508233Z",
     "start_time": "2024-05-16T02:34:42.489178Z"
    }
   },
   "cell_type": "code",
   "source": "sample = dataset[\"test\"][0][\"audio\"]",
   "id": "87a9b7f3abdd502b",
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "Subclasses of Dataset should implement __getitem__.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNotImplementedError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[19], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m sample \u001B[38;5;241m=\u001B[39m \u001B[43mdataset\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtest\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124maudio\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n",
      "File \u001B[0;32m~/anaconda3/envs/torch-env/lib/python3.11/site-packages/torch/utils/data/dataset.py:60\u001B[0m, in \u001B[0;36mDataset.__getitem__\u001B[0;34m(self, index)\u001B[0m\n\u001B[1;32m     59\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__getitem__\u001B[39m(\u001B[38;5;28mself\u001B[39m, index) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m T_co:\n\u001B[0;32m---> 60\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mNotImplementedError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSubclasses of Dataset should implement __getitem__.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[0;31mNotImplementedError\u001B[0m: Subclasses of Dataset should implement __getitem__."
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "result = pipe(sample)\n",
    "print(result)"
   ],
   "id": "3f8a1fc8d6dffb96",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Training",
   "id": "f42358f2f99e5e28"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    logging_dir=logging_dir,\n",
    "    save_strategy=save_strategy,\n",
    "    logging_strategy=logging_strategy,\n",
    "    logging_steps=logging_steps,\n",
    "    save_total_limit=save_total_limit,\n",
    "    report_to=report_to,\n",
    "    \n",
    "    \n",
    "    num_train_epochs=num_train_epochs,\n",
    "    per_device_train_batch_size=per_device_train_batch_size,\n",
    "    gradient_accumulation_steps=gradient_accumulation_steps,\n",
    "    gradient_checkpointing=gradient_checkpointing,\n",
    "    learning_rate=learning_rate,\n",
    "    lr_scheduler_type=lr_scheduler_type,\n",
    "    warmup_ratio=warmup_ratio,\n",
    "    optim=optim,\n",
    "    weight_decay=weight_decay,\n",
    "    seed=seed\n",
    ")"
   ],
   "id": "5629ae0c796e3ccb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=ds,\n",
    "    tokenizer=processor,\n",
    "    data_collator=processor.data_collator,\n",
    "    compute_metrics=None\n",
    ")"
   ],
   "id": "6fa46f2dc9990141",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "trainer.train()",
   "id": "f50d13a926cb24ee",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
