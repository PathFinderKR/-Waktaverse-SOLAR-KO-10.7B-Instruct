{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Login to Hugging Face",
   "id": "ba734f4553b55bde"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-16T20:24:58.954077Z",
     "start_time": "2024-05-16T20:24:58.524331Z"
    }
   },
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from huggingface_hub import login\n",
    "\n",
    "load_dotenv()\n",
    "token = os.getenv(\"HUGGINGFACE_TOKEN\")\n",
    "login(\n",
    "    token=token,  # ADD YOUR TOKEN HERE\n",
    "    add_to_git_credential=True\n",
    ")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token is valid (permission: write).\n",
      "\u001B[1m\u001B[31mCannot authenticate through git-credential as no helper is defined on your machine.\n",
      "You might have to re-authenticate when pushing to the Hugging Face Hub.\n",
      "Run the following command in your terminal in case you want to set the 'store' credential helper as default.\n",
      "\n",
      "git config --global credential.helper store\n",
      "\n",
      "Read https://git-scm.com/book/en/v2/Git-Tools-Credential-Storage for more details.\u001B[0m\n",
      "Token has not been saved to git credential helper.\n",
      "Your token has been saved to /home/pathfinder/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "74f9c395dc73b9ed"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-16T20:24:58.958495Z",
     "start_time": "2024-05-16T20:24:58.955820Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_name = \"Waktaverse-whisper-KO-large-v3\"  # ADD YOUR MODEL NAME HERE\n",
    "username = \"PathFinderKR\"  # ADD YOUR USERNAME HERE\n",
    "repo_id = f\"{username}/{model_name}\"  # repository id"
   ],
   "id": "10278940e0efdeef",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Login to Weights & Biases",
   "id": "bda17620db56f7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-16T20:25:03.729037Z",
     "start_time": "2024-05-16T20:24:58.959558Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import wandb\n",
    "\n",
    "api_key = os.getenv(\"WANDB_API_KEY\")\n",
    "wandb.login(\n",
    "    key=api_key  # ADD YOUR API KEY HERE\n",
    ")\n",
    "wandb.init(project=model_name)"
   ],
   "id": "4bd928034393af5c",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33mpathfinderkr\u001B[0m (\u001B[33mwaktaverse\u001B[0m). Use \u001B[1m`wandb login --relogin`\u001B[0m to force relogin\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \u001B[33mWARNING\u001B[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \u001B[33mWARNING\u001B[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Appending key for api.wandb.ai to your netrc file: /home/pathfinder/.netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Tracking run with wandb version 0.17.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Run data is saved locally in <code>/mnt/c/Users/cheir/GitHub/Waktaverse-LLM/wandb/run-20240517_052500-95w9b0ya</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/waktaverse/Waktaverse-whisper-KO-large-v3/runs/95w9b0ya' target=\"_blank\">copper-donkey-13</a></strong> to <a href='https://wandb.ai/waktaverse/Waktaverse-whisper-KO-large-v3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View project at <a href='https://wandb.ai/waktaverse/Waktaverse-whisper-KO-large-v3' target=\"_blank\">https://wandb.ai/waktaverse/Waktaverse-whisper-KO-large-v3</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run at <a href='https://wandb.ai/waktaverse/Waktaverse-whisper-KO-large-v3/runs/95w9b0ya' target=\"_blank\">https://wandb.ai/waktaverse/Waktaverse-whisper-KO-large-v3/runs/95w9b0ya</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/waktaverse/Waktaverse-whisper-KO-large-v3/runs/95w9b0ya?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7ffa14939950>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Imports",
   "id": "ac75bbafc649a044"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-16T20:25:06.221920Z",
     "start_time": "2024-05-16T20:25:03.730581Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "# pytorch\n",
    "import torch\n",
    "\n",
    "# huggingface\n",
    "from transformers import (\n",
    "    AutoModelForSpeechSeq2Seq,\n",
    "    AutoProcessor,\n",
    "    pipeline,\n",
    "    Seq2SeqTrainingArguments,\n",
    "    Seq2SeqTrainer,\n",
    "    WhisperFeatureExtractor,\n",
    "    WhisperTokenizer\n",
    ")\n",
    "\n",
    "# datasets\n",
    "from datasets import Audio, load_dataset, DatasetDict"
   ],
   "id": "fbbf7dc485d2e81d",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Device",
   "id": "64b0506e05ceda89"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-16T20:25:06.392486Z",
     "start_time": "2024-05-16T20:25:06.223504Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Device setup\n",
    "device = (\n",
    "    \"cuda:0\" if torch.cuda.is_available() else # Nvidia GPU\n",
    "    \"mps\" if torch.backends.mps.is_available() else # Apple Silicon GPU\n",
    "    \"cpu\"\n",
    ")\n",
    "print(f\"Device = {device}\")"
   ],
   "id": "d9854d2cc03800ce",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device = cuda:0\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-16T20:25:06.405569Z",
     "start_time": "2024-05-16T20:25:06.393512Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Flash Attention Implementation\n",
    "if device == \"cuda:0\":\n",
    "    if torch.cuda.get_device_capability()[0] >= 8: # Ampere, Ada, or Hopper GPUs\n",
    "        attn_implementation = \"flash_attention_2\"\n",
    "        torch_dtype = torch.float16\n",
    "    else:\n",
    "        attn_implementation = \"eager\"\n",
    "        torch_dtype = torch.float16\n",
    "else:\n",
    "    attn_implementation = \"eager\"\n",
    "    torch_dtype = torch.float32\n",
    "print(f\"Attention Implementation = {attn_implementation}\")"
   ],
   "id": "71e388c237d897cb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention Implementation = flash_attention_2\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Hyperparameters",
   "id": "e5738bbdd3f5609a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-16T20:25:06.419653Z",
     "start_time": "2024-05-16T20:25:06.406765Z"
    }
   },
   "cell_type": "code",
   "source": [
    "################################################################################\n",
    "# Language\n",
    "################################################################################\n",
    "language = \"Korean\"\n",
    "language_code = \"ko\"\n",
    "\n",
    "################################################################################\n",
    "# seed\n",
    "################################################################################\n",
    "seed=42\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "################################################################################\n",
    "# Generation parameters\n",
    "################################################################################\n",
    "max_new_tokens=100\n",
    "chunk_length_s=30\n",
    "batch_size=4\n",
    "sampling_rate=16000\n",
    "\n",
    "################################################################################\n",
    "# Training parameters\n",
    "################################################################################\n",
    "output_dir=\"./results\"\n",
    "logging_dir=\"./logs\"\n",
    "save_strategy=\"epoch\"\n",
    "logging_strategy=\"steps\" # \"steps\", \"epoch\"\n",
    "if logging_strategy == \"steps\":\n",
    "    logging_steps=10\n",
    "else:\n",
    "    logging_steps=None\n",
    "save_total_limit=1\n",
    "report_to=\"wandb\"\n",
    "\n",
    "num_train_epochs=2\n",
    "per_device_train_batch_size=4\n",
    "gradient_accumulation_steps=4\n",
    "gradient_checkpointing=True\n",
    "learning_rate=2e-5\n",
    "lr_scheduler_type=\"cosine\" # \"constant\", \"linear\", \"cosine\"\n",
    "warmup_ratio=0.1\n",
    "optim = \"adamw_torch\"\n",
    "weight_decay=0.01"
   ],
   "id": "61fc426f76f3fb64",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Model",
   "id": "35917c1f0e8f3b30"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-16T20:25:06.430131Z",
     "start_time": "2024-05-16T20:25:06.420703Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Model ID for base model\n",
    "model_id = \"openai/whisper-large-v3\""
   ],
   "id": "375bedeb9583aa27",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-16T20:25:06.440481Z",
     "start_time": "2024-05-16T20:25:06.431205Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load feature extractor and tokenizer\n",
    "#feature_extractor = WhisperFeatureExtractor.from_pretrained(model_id)\n",
    "#tokenizer = WhisperTokenizer.from_pretrained(model_id, language=language, task=\"automatic-speech-recognition\")"
   ],
   "id": "78b881225883e975",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-16T20:25:09.498609Z",
     "start_time": "2024-05-16T20:25:06.441583Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# load model and processor\n",
    "processor = AutoProcessor.from_pretrained(model_id)\n",
    "model = AutoModelForSpeechSeq2Seq.from_pretrained(\n",
    "    model_id,\n",
    "    device_map=device,\n",
    "    #attn_implementation=attn_implementation,\n",
    "    torch_dtype=torch_dtype,\n",
    "    low_cpu_mem_usage=True,\n",
    "    use_safetensors=True\n",
    ")"
   ],
   "id": "71aa4496f9217519",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pathfinder/anaconda3/envs/torch-env/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-16T20:25:09.505431Z",
     "start_time": "2024-05-16T20:25:09.499786Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Display the model architecture\n",
    "display(Markdown(f'```{model}```'))"
   ],
   "id": "8ed2c02ce4f9caf5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "```WhisperForConditionalGeneration(\n  (model): WhisperModel(\n    (encoder): WhisperEncoder(\n      (conv1): Conv1d(128, 1280, kernel_size=(3,), stride=(1,), padding=(1,))\n      (conv2): Conv1d(1280, 1280, kernel_size=(3,), stride=(2,), padding=(1,))\n      (embed_positions): Embedding(1500, 1280)\n      (layers): ModuleList(\n        (0-31): 32 x WhisperEncoderLayer(\n          (self_attn): WhisperSdpaAttention(\n            (k_proj): Linear(in_features=1280, out_features=1280, bias=False)\n            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n          )\n          (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n          (activation_fn): GELUActivation()\n          (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n          (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n          (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n        )\n      )\n      (layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n    )\n    (decoder): WhisperDecoder(\n      (embed_tokens): Embedding(51866, 1280, padding_idx=50256)\n      (embed_positions): WhisperPositionalEmbedding(448, 1280)\n      (layers): ModuleList(\n        (0-31): 32 x WhisperDecoderLayer(\n          (self_attn): WhisperSdpaAttention(\n            (k_proj): Linear(in_features=1280, out_features=1280, bias=False)\n            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n          )\n          (activation_fn): GELUActivation()\n          (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n          (encoder_attn): WhisperSdpaAttention(\n            (k_proj): Linear(in_features=1280, out_features=1280, bias=False)\n            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n          )\n          (encoder_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n          (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n          (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n          (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n        )\n      )\n      (layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n    )\n  )\n  (proj_out): Linear(in_features=1280, out_features=51866, bias=False)\n)```"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Dataset",
   "id": "10bdc2fc57dfc32a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-16T20:25:09.512065Z",
     "start_time": "2024-05-16T20:25:09.506798Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Dataset ID\n",
    "dataset_id = \"mozilla-foundation/common_voice_17_0\""
   ],
   "id": "20e707e9f8a94299",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-16T20:25:20.145807Z",
     "start_time": "2024-05-16T20:25:09.513082Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load dataset\n",
    "dataset = DatasetDict()\n",
    "dataset[\"train\"] = load_dataset(dataset_id, language_code, split=\"train\", trust_remote_code=True)\n",
    "dataset[\"validation\"] = load_dataset(dataset_id, language_code, split=\"validation\", trust_remote_code=True)\n",
    "dataset[\"test\"] = load_dataset(dataset_id, language_code, split=\"test\", trust_remote_code=True)"
   ],
   "id": "a36a3cbea836d472",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-16T20:25:20.150913Z",
     "start_time": "2024-05-16T20:25:20.147396Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Dataset information\n",
    "dataset"
   ],
   "id": "5f0b998f9d148e0c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['client_id', 'path', 'audio', 'sentence', 'up_votes', 'down_votes', 'age', 'gender', 'accent', 'locale', 'segment', 'variant'],\n",
       "        num_rows: 376\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['client_id', 'path', 'audio', 'sentence', 'up_votes', 'down_votes', 'age', 'gender', 'accent', 'locale', 'segment', 'variant'],\n",
       "        num_rows: 330\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['client_id', 'path', 'audio', 'sentence', 'up_votes', 'down_votes', 'age', 'gender', 'accent', 'locale', 'segment', 'variant'],\n",
       "        num_rows: 339\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-16T20:25:20.644962Z",
     "start_time": "2024-05-16T20:25:20.152101Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Dataset sample\n",
    "dataset[\"train\"][0]"
   ],
   "id": "e7fb9919f52c2e85",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'client_id': 'c6ea915bc1573d5253873335a07670c60dfe75546918f591b700e4a992ab7e44ab084bd752b3e69e197900cfa2e45e1f094af17209d83b5065456069e71aa84e',\n",
       " 'path': '/home/pathfinder/.cache/huggingface/datasets/downloads/extracted/7a0463f732267b69160aee0e58bd2957b341ae0b656ec6f0e6bff7fa99840bbe/ko_train_0/common_voice_ko_36880067.mp3',\n",
       " 'audio': {'path': '/home/pathfinder/.cache/huggingface/datasets/downloads/extracted/7a0463f732267b69160aee0e58bd2957b341ae0b656ec6f0e6bff7fa99840bbe/ko_train_0/common_voice_ko_36880067.mp3',\n",
       "  'array': array([ 1.42108547e-13,  8.24229573e-13,  1.16529009e-12, ...,\n",
       "         -2.78210791e-06,  1.59777846e-06,  3.08523158e-06]),\n",
       "  'sampling_rate': 48000},\n",
       " 'sentence': '그 이웃을 쳐서 거짓 증거하는 사람은 방망이요 칼이요 뾰족한 살이니라',\n",
       " 'up_votes': 4,\n",
       " 'down_votes': 0,\n",
       " 'age': 'twenties',\n",
       " 'gender': 'female_feminine',\n",
       " 'accent': '서울',\n",
       " 'locale': 'ko',\n",
       " 'segment': '',\n",
       " 'variant': ''}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Preprocessing",
   "id": "2118b20fdd3597c2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-16T20:25:20.648071Z",
     "start_time": "2024-05-16T20:25:20.645982Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "f9a90db19293a62c",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Inference",
   "id": "61930d88aaf1efaa"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-16T20:25:20.675383Z",
     "start_time": "2024-05-16T20:25:20.671649Z"
    }
   },
   "cell_type": "code",
   "source": [
    "pipe = pipeline(\n",
    "    \"automatic-speech-recognition\",\n",
    "    model=model,\n",
    "    tokenizer=processor.tokenizer,\n",
    "    feature_extractor=processor.feature_extractor,\n",
    "    torch_dtype=torch_dtype,\n",
    "    return_timestamps=True,\n",
    "\n",
    "    max_new_tokens=max_new_tokens,\n",
    "    chunk_length_s=chunk_length_s,\n",
    "    batch_size=batch_size\n",
    ")"
   ],
   "id": "53dae8b4956d9ba3",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-16T20:25:20.686879Z",
     "start_time": "2024-05-16T20:25:20.676417Z"
    }
   },
   "cell_type": "code",
   "source": "sample = dataset[\"test\"][0][\"audio\"]",
   "id": "87a9b7f3abdd502b",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-16T20:34:47.113296Z",
     "start_time": "2024-05-16T20:34:46.929725Z"
    }
   },
   "cell_type": "code",
   "source": "result = pipe(sample)",
   "id": "44f5df47d8de171f",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pipe' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m result \u001B[38;5;241m=\u001B[39m pipe(sample)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'pipe' is not defined"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "result",
   "id": "43c0e16d084c136e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Training",
   "id": "f42358f2f99e5e28"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-16T20:25:22.273585Z",
     "start_time": "2024-05-16T20:25:22.242233Z"
    }
   },
   "cell_type": "code",
   "source": [
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    logging_dir=logging_dir,\n",
    "    save_strategy=save_strategy,\n",
    "    logging_strategy=logging_strategy,\n",
    "    logging_steps=logging_steps,\n",
    "    save_total_limit=save_total_limit,\n",
    "    report_to=report_to,\n",
    "    \n",
    "    num_train_epochs=num_train_epochs,\n",
    "    per_device_train_batch_size=per_device_train_batch_size,\n",
    "    gradient_accumulation_steps=gradient_accumulation_steps,\n",
    "    gradient_checkpointing=gradient_checkpointing,\n",
    "    learning_rate=learning_rate,\n",
    "    lr_scheduler_type=lr_scheduler_type,\n",
    "    warmup_ratio=warmup_ratio,\n",
    "    optim=optim,\n",
    "    weight_decay=weight_decay,\n",
    "    seed=seed\n",
    ")"
   ],
   "id": "5629ae0c796e3ccb",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-16T20:25:22.431419Z",
     "start_time": "2024-05-16T20:25:22.274664Z"
    }
   },
   "cell_type": "code",
   "source": [
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=ds,\n",
    "    tokenizer=processor,\n",
    "    data_collator=processor.data_collator,\n",
    "    compute_metrics=None\n",
    ")"
   ],
   "id": "6fa46f2dc9990141",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[22], line 4\u001B[0m\n\u001B[1;32m      1\u001B[0m trainer \u001B[38;5;241m=\u001B[39m Seq2SeqTrainer(\n\u001B[1;32m      2\u001B[0m     model\u001B[38;5;241m=\u001B[39mmodel,\n\u001B[1;32m      3\u001B[0m     args\u001B[38;5;241m=\u001B[39mtraining_args,\n\u001B[0;32m----> 4\u001B[0m     train_dataset\u001B[38;5;241m=\u001B[39mds,\n\u001B[1;32m      5\u001B[0m     tokenizer\u001B[38;5;241m=\u001B[39mprocessor,\n\u001B[1;32m      6\u001B[0m     data_collator\u001B[38;5;241m=\u001B[39mprocessor\u001B[38;5;241m.\u001B[39mdata_collator,\n\u001B[1;32m      7\u001B[0m     compute_metrics\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m      8\u001B[0m )\n",
      "\u001B[0;31mNameError\u001B[0m: name 'ds' is not defined"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "trainer.train()",
   "id": "f50d13a926cb24ee",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
