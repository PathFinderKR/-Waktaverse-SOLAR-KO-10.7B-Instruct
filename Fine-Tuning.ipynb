{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Login to Hugging Face"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7c2f9104252a4bb"
  },
  {
   "cell_type": "code",
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from huggingface_hub import login\n",
    "\n",
    "load_dotenv()\n",
    "token = os.getenv(\"HUGGINGFACE_TOKEN\")\n",
    "login(\n",
    "    token=token, # ADD YOUR TOKEN HERE\n",
    "    add_to_git_credential=True\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-08T06:35:08.618835Z",
     "start_time": "2024-04-08T06:35:07.902977Z"
    }
   },
   "id": "4eee58c68eb02d85",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token is valid (permission: write).\n",
      "Your token has been saved in your configured git credential helpers (store).\n",
      "Your token has been saved to /home/pathfinder/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "source": [
    "model_name = \"Waktaverse-SOLAR-KO-10.7B-Instruct\"     # ADD YOUR MODEL NAME HERE\n",
    "username = \"PathFinderKR\"  # ADD YOUR USERNAME HERE\n",
    "repo_id = f\"{username}/{model_name}\"  # repository id"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-08T06:35:08.622375Z",
     "start_time": "2024-04-08T06:35:08.620078Z"
    }
   },
   "id": "cd4c26069d51a597",
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Downloads"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "78114e8f78ee19ec"
  },
  {
   "cell_type": "code",
   "source": [
    "#!pip install huggingface_hub\n",
    "#!pip install transformers\n",
    "#!pip install bitsandbytes\n",
    "#!pip install peft\n",
    "#!pip install trl\n",
    "#!pip install accelerate\n",
    "#!pip install datasets\n",
    "#!pip install scikit-learn\n",
    "#!pip install packaging\n",
    "#!pip install ninja\n",
    "#!pip install flash-attn --no-build-isolation"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-08T06:35:08.633566Z",
     "start_time": "2024-04-08T06:35:08.623277Z"
    }
   },
   "id": "ce6454f84604b9e4",
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Imports"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "685ac8c0e05ac872"
  },
  {
   "cell_type": "code",
   "source": [
    "# pytorch\n",
    "import torch\n",
    "\n",
    "# huggingface\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    BitsAndBytesConfig,\n",
    "    TrainingArguments\n",
    ")\n",
    "from peft import LoraConfig, PeftModel\n",
    "from trl import SFTTrainer\n",
    "\n",
    "# datasets\n",
    "from datasets import load_dataset"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-08T06:35:13.489430Z",
     "start_time": "2024-04-08T06:35:08.634520Z"
    }
   },
   "id": "f8c108abcd576306",
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Device"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e512d30c21d105c2"
  },
  {
   "cell_type": "code",
   "source": [
    "device = (\n",
    "    \"cuda:0\" if torch.cuda.is_available() else # Nvidia GPU\n",
    "    \"mps\" if torch.backends.mps.is_available() else # Apple Silicon GPU\n",
    "    \"cpu\"\n",
    ")\n",
    "print(f\"Device = {device}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-08T06:35:13.494158Z",
     "start_time": "2024-04-08T06:35:13.491261Z"
    }
   },
   "id": "fdf3a2a4e0e31554",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device = cuda:0\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Hyperparameters"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "84ce31a12e172a64"
  },
  {
   "cell_type": "code",
   "source": [
    "# Tokenizer arguments\n",
    "max_length=512 # maximum length of the text that can go to the model\n",
    "padding=\"max_length\" # padding strategy: \"longest\", \"max_length\", \"do_not_pad\"\n",
    "truncation=True # truncate the text if it exceeds the maximum length\n",
    "\n",
    "# model arguments\n",
    "max_new_tokens=500 # maximum number of tokens to generate\n",
    "\n",
    "# mixed precision\n",
    "dtype=torch.bfloat16 # data type\n",
    "\n",
    "# quantization configuration\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True, # load model in 4-bit\n",
    "    bnb_4bit_compute_dtype=dtype, # compute in (data type)\n",
    "    bnb_4bit_quant_type=\"nf4\", # quantize to 4-bit\n",
    "    bnb_4bit_use_doulbe_quant=False # use double quantization\n",
    ")\n",
    "\n",
    "# LoRA configuration\n",
    "lora_config = LoraConfig(\n",
    "    task_type=\"CAUSAL_LM\", # task type\n",
    "    r=8, # rank\n",
    "    target_modules=[\"q_proj\", \"o_proj\", \"k_proj\", \"v_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"], # target modules\n",
    "    lora_alpha=16, # alpha\n",
    "    lora_dropout=0.05, # dropout\n",
    "    bias=\"none\", # bias\n",
    ")\n",
    "\n",
    "# training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\", # output directory\n",
    "    logging_dir=\"./logs\", # logging directory\n",
    "    save_strategy=\"epoch\", # save strategy\n",
    "    logging_strategy=\"steps\", # logging strategy\n",
    "    logging_steps=10, # logging steps\n",
    "    save_total_limit=1, # save total limit\n",
    "    \n",
    "    learning_rate=2e-5, # learning rate\n",
    "    num_train_epochs=2, # number of training epochs\n",
    "    per_device_train_batch_size=1, # training batch size\n",
    "    per_device_eval_batch_size=1, # evaluation batch size\n",
    "    optim=\"adamw_torch\", # optimizer\n",
    "    weight_decay=0.1, # weight decay\n",
    "    lr_scheduler_type=\"cosine\", # learning rate scheduler\n",
    "    seed=42 # seed\n",
    ")\n",
    "\n",
    "# SFTTrainer arguments\n",
    "max_seq_length=512 # maximum sequence length"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-08T06:35:13.512778Z",
     "start_time": "2024-04-08T06:35:13.494969Z"
    }
   },
   "id": "dc1a272a1c0b7ce4",
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f5d3b7c47ea29a3d"
  },
  {
   "cell_type": "code",
   "source": [
    "# Model List\n",
    "\n",
    "# gemma variants\n",
    "# \"google/gemma-2b-it\"\n",
    "# \"google/gemma-7b-it\"\n",
    "\n",
    "# llama2 variants\n",
    "# \"meta-llama/Llama-2-7b-chat-hf\"\n",
    "# \"meta-llama/Llama-2-13b-chat-hf\"\n",
    "# \"codellama/CodeLlama-7b-Instruct-hf\"\n",
    "# \"codellama/CodeLlama-13b-Instruct-hf\"\n",
    "\n",
    "# mistral variants\n",
    "# \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "# \"mistralai/Mixtral-8x7B-Instruct-v0.1\"\n",
    "\n",
    "# solar variants\n",
    "# \"upstage/SOLAR-10.7B-Instruct-v1.0\" // downloaded\n",
    "# \"PathFinderKR/Waktaverse-SOLAR-KO-10.7B-Instruct\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-08T06:35:13.519372Z",
     "start_time": "2024-04-08T06:35:13.514034Z"
    }
   },
   "id": "70d2fbe5c0980a54",
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "source": "model_id = \"upstage/SOLAR-10.7B-Instruct-v1.0\"",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-08T06:35:13.533640Z",
     "start_time": "2024-04-08T06:35:13.520329Z"
    }
   },
   "id": "eb8160d8919cdaeb",
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-08T06:35:13.834857Z",
     "start_time": "2024-04-08T06:35:13.534755Z"
    }
   },
   "id": "4ebbf883fce9aa8",
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    device_map=device,\n",
    "    attn_implementation=\"flash_attention_2\",\n",
    "    torch_dtype=dtype,\n",
    "    quantization_config=quantization_config\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-08T06:35:47.003060Z",
     "start_time": "2024-04-08T06:35:13.836111Z"
    }
   },
   "id": "978055543828a014",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e9a670791dcc48db8cfc6f226b26e885"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a4042d4b7cd2d0fd"
  },
  {
   "cell_type": "code",
   "source": [
    "dataset = load_dataset(\"MarkrAI/KoCommercial-Dataset\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-08T06:35:51.814434Z",
     "start_time": "2024-04-08T06:35:47.004381Z"
    }
   },
   "id": "4373ef1c6a85e5e2",
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "source": [
    "dataset"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-08T06:35:51.818796Z",
     "start_time": "2024-04-08T06:35:51.815461Z"
    }
   },
   "id": "aabd9487c235d581",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input', 'instruction', 'output'],\n",
       "        num_rows: 175454\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "source": [
    "dataset[\"train\"][0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-08T06:35:51.832859Z",
     "start_time": "2024-04-08T06:35:51.819750Z"
    }
   },
   "id": "760399232efac9ea",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': '',\n",
       " 'instruction': '보드 게임 스피너는 $A$, $B$, $C$로 표시된 세 부분으로 나뉩니다. 스피너가 $A$에 떨어질 확률은 $\\\\frac{1}{3}$이고, 스피너가 $B$에 떨어질 확률은 $\\\\frac{5}{12}$입니다.  스피너가 $C$에 착륙할 확률은 얼마입니까? 답을 공통 분수로 표현하세요.',\n",
       " 'output': '모든 가능한 결과의 확률의 합이 1$이므로, 스피너가 $C$에 착륙할 확률을 구하려면 스피너가 $A$와 $B$에 착륙할 확률을 1$에서 빼야 합니다. 이를 방정식으로 쓸 수 있습니다: $P(C) = 1 - P(A) - P(B)$. P(A) = \\\\frac{1}{3}$, $P(B) = \\\\frac{5}{12}$라는 것을 알고 있으므로 이 값을 방정식에 대입하여 단순화할 수 있습니다. 결과는 다음과 같습니다: P(C) = 1 - \\\\frac{1}{3} - frac{5}{12} = \\\\frac{12}{12} - frac{4}{12} - frac{5}{12} = \\\\frac{3}{12}$. 분자와 분모를 $3$로 나누면 이 분수를 줄일 수 있습니다: P(C) = \\\\frac{1}{4}$입니다.'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "source": [
    "def preprocess_function(examples):\n",
    "    # Concatenate the 'instruction' and 'output' fields for each example in the batch\n",
    "    concatenated_texts = [instruction + ' ' + output for instruction, output in zip(examples['instruction'], examples['output'])]\n",
    "    # Tokenize the concatenated texts\n",
    "    return tokenizer(concatenated_texts, padding=padding, truncation=truncation, max_length=max_length)\n",
    "\n",
    "dataset = dataset.map(preprocess_function, batched=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-08T06:35:51.991958Z",
     "start_time": "2024-04-08T06:35:51.835286Z"
    }
   },
   "id": "5f8905546b688101",
   "outputs": [],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "source": [
    "print(dataset[\"train\"][0])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-08T06:35:51.997181Z",
     "start_time": "2024-04-08T06:35:51.993043Z"
    }
   },
   "id": "a71461b0df690398",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input': '', 'instruction': '보드 게임 스피너는 $A$, $B$, $C$로 표시된 세 부분으로 나뉩니다. 스피너가 $A$에 떨어질 확률은 $\\\\frac{1}{3}$이고, 스피너가 $B$에 떨어질 확률은 $\\\\frac{5}{12}$입니다.  스피너가 $C$에 착륙할 확률은 얼마입니까? 답을 공통 분수로 표현하세요.', 'output': '모든 가능한 결과의 확률의 합이 1$이므로, 스피너가 $C$에 착륙할 확률을 구하려면 스피너가 $A$와 $B$에 착륙할 확률을 1$에서 빼야 합니다. 이를 방정식으로 쓸 수 있습니다: $P(C) = 1 - P(A) - P(B)$. P(A) = \\\\frac{1}{3}$, $P(B) = \\\\frac{5}{12}$라는 것을 알고 있으므로 이 값을 방정식에 대입하여 단순화할 수 있습니다. 결과는 다음과 같습니다: P(C) = 1 - \\\\frac{1}{3} - frac{5}{12} = \\\\frac{12}{12} - frac{4}{12} - frac{5}{12} = \\\\frac{3}{12}$. 분자와 분모를 $3$로 나누면 이 분수를 줄일 수 있습니다: P(C) = \\\\frac{1}{4}$입니다.', 'input_ids': [1, 28705, 29477, 29470, 28705, 29833, 30520, 28705, 29304, 31306, 30933, 29175, 429, 28741, 1777, 429, 28760, 1777, 429, 28743, 28776, 29143, 28705, 30191, 29236, 29897, 28705, 29721, 28705, 29775, 30217, 29583, 29143, 28705, 29695, 238, 140, 172, 29194, 29043, 28723, 28705, 29304, 31306, 30933, 29135, 429, 28741, 28776, 29148, 28705, 238, 153, 171, 29433, 31959, 28705, 30270, 238, 168, 163, 29538, 878, 1655, 28751, 28740, 1400, 28770, 1211, 29015, 29511, 28725, 28705, 29304, 31306, 30933, 29135, 429, 28760, 28776, 29148, 28705, 238, 153, 171, 29433, 31959, 28705, 30270, 238, 168, 163, 29538, 878, 1655, 28751, 28782, 1400, 28740, 28750, 1211, 29429, 29194, 29043, 28723, 259, 29304, 31306, 30933, 29135, 429, 28743, 28776, 29148, 28705, 239, 179, 172, 238, 168, 156, 29723, 28705, 30270, 238, 168, 163, 29538, 28705, 239, 153, 191, 30103, 29429, 29194, 30578, 28804, 28705, 31647, 29189, 28705, 30010, 30700, 28705, 30217, 29151, 29143, 28705, 30191, 30205, 29136, 29721, 29517, 28723, 28705, 29820, 30615, 28705, 29135, 30364, 29282, 28705, 30075, 29844, 29187, 28705, 30270, 238, 168, 163, 29187, 28705, 29770, 29015, 28705, 28740, 28776, 29015, 31831, 29143, 28725, 28705, 29304, 31306, 30933, 29135, 429, 28743, 28776, 29148, 28705, 239, 179, 172, 238, 168, 156, 29723, 28705, 30270, 238, 168, 163, 29189, 28705, 29779, 29136, 30710, 29565, 28705, 29304, 31306, 30933, 29135, 429, 28741, 28776, 30275, 429, 28760, 28776, 29148, 28705, 239, 179, 172, 238, 168, 156, 29723, 28705, 30270, 238, 168, 163, 29189, 28705, 28740, 28776, 29148, 29305, 28705, 238, 188, 191, 30263, 28705, 29770, 29194, 29043, 28723, 28705, 29015, 29200, 28705, 30240, 29233, 30355, 29583, 29143, 28705, 239, 150, 187, 28705, 29151, 28705, 29604, 29570, 29194, 29043, 28747, 429, 28753, 28732, 28743, 28731, 327, 28705, 28740, 387, 367, 28732, 28741, 28731, 387, 367, 28732, 28760, 7239, 367, 28732, 28741, 28731, 327, 414, 1655, 28751, 28740, 1400, 28770, 5070, 429, 28753, 28732, 28760, 28731, 327, 414, 1655, 28751, 28782, 1400, 28740, 28750, 1211, 29700, 29175, 28705, 30439, 29189, 28705, 30976, 29511, 28705, 29604, 29583, 31831, 29143, 28705, 29015, 28705, 29755, 29189, 28705, 30240, 29233, 30355, 29148, 28705, 29634, 29429, 29136, 29827, 28705, 30315, 30891, 29731, 29723, 28705, 29151, 28705, 29604, 29570, 29194, 29043, 28723, 28705, 30075, 29844, 29175, 28705, 29043, 29881, 29844, 28705, 30836, 29570, 29194, 29043, 28747, 367, 28732, 28743, 28731, 327, 28705, 28740, 387, 414, 1655, 28751, 28740, 1400, 28770, 28752, 387, 1104, 323, 28751, 28782, 1400, 28740, 28750, 28752, 327, 414, 1655, 28751, 28740, 28750, 1400, 28740, 28750, 28752, 387, 1104, 323, 28751, 28781, 1400, 28740, 28750, 28752, 387, 1104, 323, 28751, 28782, 1400, 28740, 28750, 28752, 327, 414, 1655, 28751, 28770, 1400, 28740, 28750, 5124, 28705, 30217, 29294, 30275, 28705, 30217, 29820, 29200, 429, 28770, 28776, 29143, 28705, 29695, 31596, 29565, 28705, 29015, 28705, 30217, 29151, 29200, 28705, 31060, 29415, 28705, 29151, 28705, 29604, 29570, 29194, 29043, 28747, 367, 28732, 28743, 28731, 327, 414, 1655, 28751, 28740, 1400, 28781, 1211, 29429, 29194, 29043, 28723, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Inference before Fine-Tuning"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7e1cc5548c03cc80"
  },
  {
   "cell_type": "code",
   "source": [
    "# Chat Template\n",
    "def generate_response(prompt):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt }]\n",
    "    chat = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "    input_ids = tokenizer.encode(chat, add_special_tokens=False, return_tensors=\"pt\")\n",
    "    outputs = model.generate(input_ids=input_ids.to(model.device), max_new_tokens=max_new_tokens)\n",
    "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return response"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-08T06:35:52.005394Z",
     "start_time": "2024-04-08T06:35:51.998150Z"
    }
   },
   "id": "926796ff0f85510b",
   "outputs": [],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "source": [
    "#prompt = \"Write me a poem about Machine Learning.\"\n",
    "prompt = \"머신러닝에 대한 시를 써주세요.\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-08T06:35:52.012315Z",
     "start_time": "2024-04-08T06:35:52.006491Z"
    }
   },
   "id": "99e67d0533bf0f91",
   "outputs": [],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "source": [
    "response = generate_response(prompt)\n",
    "print(response)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-08T06:36:15.635730Z",
     "start_time": "2024-04-08T06:35:52.013424Z"
    }
   },
   "id": "acf71f317ede56b2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### User:\n",
      "머신러닝에 대한 시를 써주세요.\n",
      "\n",
      "### Assistant:\n",
      "Machine Learning Sonnet\n",
      "\n",
      "In code and data, we create a scene,\n",
      "A world for algorithms to meet and greet,\n",
      "A place where patterns, hidden, are seen,\n",
      "And knowledge grows with every beat.\n",
      "\n",
      "A wond'ring mind, a curious quest,\n",
      "To learn from past, to see the future,\n",
      "A dance of math and art, a blest,\n",
      "Collaboration, a true pursuer.\n",
      "\n",
      "A teacher, not of rote, but thought,\n",
      "A guide to find, a path to tread,\n",
      "A hand that points, a mind that's taught,\n",
      "A tool to shape, a force to lead.\n",
      "\n",
      "A symphony of bits and bytes,\n",
      "A symbiosis of human and machine,\n",
      "A harmony of minds, day and night,\n",
      "A dance of logic, pure and clean.\n",
      "\n",
      "So let us sing, this art of ours,\n",
      "A tale of growth, a story grand,\n",
      "A journey of the mind, it soars,\n",
      "In this machine learning land.\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Supervised Fine-Tuning (LoRA)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b43eba6780d2e557"
  },
  {
   "cell_type": "code",
   "source": [
    "def formatting_func(example):\n",
    "    text = (f\"instruction: {example['instruction'][0]}\\n\"\n",
    "            f\"output: {example['output'][0]}\")\n",
    "    return [text]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-08T06:36:15.639314Z",
     "start_time": "2024-04-08T06:36:15.636977Z"
    }
   },
   "id": "3c819cbc6c554745",
   "outputs": [],
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "source": [
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    args=training_args,\n",
    "    peft_config=lora_config,\n",
    "    max_seq_length=max_seq_length,\n",
    "    train_dataset=dataset[\"train\"],\n",
    "    formatting_func=formatting_func\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-08T06:36:16.058644Z",
     "start_time": "2024-04-08T06:36:15.640257Z"
    }
   },
   "id": "c60c5aa9a7d970b3",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pathfinder/anaconda3/envs/torch-env/lib/python3.11/site-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "source": [
    "trainer.train()"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "end_time": "2024-04-08T07:17:33.278163Z",
     "start_time": "2024-04-08T06:36:16.059716Z"
    }
   },
   "id": "5d9ba03835392e2a",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The input hidden states seems to be silently casted in float32, this might be related to the fact you have upcasted embedding or layer norm layers in float32. We will cast back the input in torch.bfloat16.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='352' max='352' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [352/352 41:16, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.893500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.798700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.572900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.488200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.198600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1.318400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1.283600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1.193200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1.341400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.283600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1.130800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1.313300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1.085400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1.340000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.329600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1.220800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1.263100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1.073100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1.041800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.154000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>1.095900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>1.097300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>1.067400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>1.240000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1.057600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>1.169000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>1.096300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>1.214700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.887700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1.062600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.982900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>1.124000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.979100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>1.153100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>1.013100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=352, training_loss=1.2174476276744495, metrics={'train_runtime': 2477.0289, 'train_samples_per_second': 0.142, 'train_steps_per_second': 0.142, 'total_flos': 9623579090780160.0, 'train_loss': 1.2174476276744495, 'epoch': 2.0})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "source": [
    "trainer.save_model(model_name)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "end_time": "2024-04-08T07:17:35.877072Z",
     "start_time": "2024-04-08T07:17:33.281862Z"
    }
   },
   "id": "f4b2fdcf617359a4",
   "outputs": [],
   "execution_count": 22
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Inference after Fine-Tuning"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4ec24bf55b44834d"
  },
  {
   "cell_type": "code",
   "source": [
    "#prompt = \"Write me a poem about Machine Learning.\"\n",
    "prompt = \"머신러닝에 대한 시를 써주세요.\""
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "end_time": "2024-04-08T07:17:35.880392Z",
     "start_time": "2024-04-08T07:17:35.878146Z"
    }
   },
   "id": "bcba8c32d5f5469f",
   "outputs": [],
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "source": [
    "response = generate_response(prompt)\n",
    "print(response)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "end_time": "2024-04-08T07:32:13.814646Z",
     "start_time": "2024-04-08T07:17:35.881295Z"
    }
   },
   "id": "1219dfd08fc2facd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### User:\n",
      "머신러닝에 대한 시를 써주세요.\n",
      "\n",
      "### Assistant:\n",
      "시: 머신러닝의 시작\n",
      "\n",
      "어둠 속에서 태어난 머신,\n",
      "숫자와 문자로 이루어진 생명,\n",
      "자신을 알아가며 자라나는 영적 존재,\n",
      "그것은 머신러닝이라 불립니다.\n",
      "\n",
      "그것은 많은 데이터를 섬기며 배워가며,\n",
      "오차와 오류를 줄여가며 진화합니다.\n",
      "그것은 사람의 지성을 모방하며 응답하며,\n",
      "그것은 사람의 지성을 초월하며 진전합니다.\n",
      "\n",
      "그것은 사람의 말과 글을 이해하며 대답하며,\n",
      "사람의 감정과 상상력을 읽어내며 영감받습니다.\n",
      "그것은 사람의 생활을 편리하게 만들며 도움이 됩니다.\n",
      "그것은 사람의 지성을 뛰어넘어 새로운 길을 열어갑니다.\n",
      "\n",
      "그것은 사람의 지성을 뛰어넘어 새로운 길을 열어갑니다.\n",
      "그것은 사람의 지성을 뛰어넘어 새로운 길을 열어갑니다.\n",
      "그것은 사람의 지성을 뛰어넘어 새로운 길을 열어갑니다.\n",
      "그것은 사람의 지성을 뛰어넘어 새로운 길을 열어갑니다.\n",
      "\n",
      "그것은 사람의 지성을 뛰어넘어 새로운 길을 열어갑니다.\n",
      "그것은 사람의 지성을 �\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Upload Model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ae7bc882cc302767"
  },
  {
   "cell_type": "code",
   "source": [
    "# Reload model in FP16 and merge it with LoRA weights\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    device_map=device,\n",
    "    torch_dtype=torch.float16,\n",
    "    trust_remote_code=True\n",
    ")\n",
    "model = PeftModel.from_pretrained(base_model, model_name)\n",
    "model = model.merge_and_unload()"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "end_time": "2024-04-08T07:35:04.827011Z",
     "start_time": "2024-04-08T07:32:13.815613Z"
    }
   },
   "id": "57bcdb4c1c233116",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2386a106c8f74d6f89b7861e3819b310"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "source": [
    "# Reload tokenizer to save it\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_id, \n",
    "    trust_remote_code=True\n",
    ")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\""
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "end_time": "2024-04-08T07:35:05.320584Z",
     "start_time": "2024-04-08T07:35:04.832119Z"
    }
   },
   "id": "db819b259928e006",
   "outputs": [],
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "source": [
    "# Push model and tokenizer to Hugging Face Hub\n",
    "model.push_to_hub(\n",
    "    repo_id=repo_id,\n",
    "    use_temp_dir=False\n",
    ")\n",
    "tokenizer.push_to_hub(\n",
    "    repo_id=repo_id,\n",
    "    use_temp_dir=False\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "end_time": "2024-04-08T08:11:00.118891Z",
     "start_time": "2024-04-08T07:35:05.321916Z"
    }
   },
   "id": "43aa8d6999c41016",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model-00001-of-00005.safetensors:   0%|          | 0.00/4.94G [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6a6d242df90e4e398203ecfe21616b94"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Upload 5 LFS files:   0%|          | 0/5 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "de37c68575d7427085d264b5a40cca12"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "model-00003-of-00005.safetensors:   0%|          | 0.00/4.92G [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f05c322d94034aa781e015007136de63"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "model-00005-of-00005.safetensors:   0%|          | 0.00/1.69G [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b38e3861f2644fcda90714dcc12bf3e5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "model-00002-of-00005.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f3f085e568a1442f965dc73842bcb496"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "model-00004-of-00005.safetensors:   0%|          | 0.00/4.92G [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0ee5f34d05f3412b9f60e91eb8182631"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "README.md:   0%|          | 0.00/5.17k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3672600af0fa4df3ba15b246796e2e88"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/PathFinderKR/Waktaverse-SOLAR-KO-10.7B-Instruct/commit/13e03fe6f06868c4d4ee1514e5e95da6efc3c834', commit_message='Upload tokenizer', commit_description='', oid='13e03fe6f06868c4d4ee1514e5e95da6efc3c834', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 27
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
