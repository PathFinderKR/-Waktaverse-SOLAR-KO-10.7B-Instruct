{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Login to Hugging Face"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7c2f9104252a4bb"
  },
  {
   "cell_type": "code",
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from huggingface_hub import login\n",
    "\n",
    "load_dotenv()\n",
    "token = os.getenv(\"HUGGINGFACE_TOKEN\")\n",
    "login(\n",
    "    token=token, # ADD YOUR TOKEN HERE\n",
    "    add_to_git_credential=True\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-05T23:38:53.204166Z",
     "start_time": "2024-04-05T23:38:52.430929Z"
    }
   },
   "id": "4eee58c68eb02d85",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token is valid (permission: write).\n",
      "Your token has been saved in your configured git credential helpers (store).\n",
      "Your token has been saved to /home/pathfinder/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "source": [
    "model_name = \"waktaverse-SOLAR-KO-10.7B-Instruct-v1.0\"     # ADD YOUR MODEL NAME HERE\n",
    "username = \"PathFinderKR\"  # ADD YOUR USERNAME HERE\n",
    "repo_id = f\"{username}/{model_name}\"  # repository id"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-05T23:38:53.208422Z",
     "start_time": "2024-04-05T23:38:53.205436Z"
    }
   },
   "id": "cd4c26069d51a597",
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Downloads"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "78114e8f78ee19ec"
  },
  {
   "cell_type": "code",
   "source": [
    "#!pip install huggingface_hub\n",
    "#!pip install transformers\n",
    "#!pip install bitsandbytes\n",
    "#!pip install peft\n",
    "#!pip install trl\n",
    "#!pip install accelerate\n",
    "#!pip install datasets\n",
    "#!pip install scikit-learn\n",
    "#!pip install packaging\n",
    "#!pip install ninja\n",
    "#!pip install flash-attn --no-build-isolation"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-05T23:38:53.219528Z",
     "start_time": "2024-04-05T23:38:53.209309Z"
    }
   },
   "id": "ce6454f84604b9e4",
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Imports"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "685ac8c0e05ac872"
  },
  {
   "cell_type": "code",
   "source": [
    "# pytorch\n",
    "import torch\n",
    "\n",
    "# huggingface\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    BitsAndBytesConfig,\n",
    "    TrainingArguments\n",
    ")\n",
    "from peft import LoraConfig, PeftModel\n",
    "from trl import SFTTrainer\n",
    "\n",
    "# datasets\n",
    "from datasets import load_dataset"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-05T23:38:59.033632Z",
     "start_time": "2024-04-05T23:38:53.221123Z"
    }
   },
   "id": "f8c108abcd576306",
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Device"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e512d30c21d105c2"
  },
  {
   "cell_type": "code",
   "source": [
    "device = (\n",
    "    \"cuda:0\" if torch.cuda.is_available() else # Nvidia GPU\n",
    "    \"mps\" if torch.backends.mps.is_available() else # Apple Silicon GPU\n",
    "    \"cpu\"\n",
    ")\n",
    "print(f\"Device = {device}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-05T23:38:59.037762Z",
     "start_time": "2024-04-05T23:38:59.034759Z"
    }
   },
   "id": "fdf3a2a4e0e31554",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device = cuda:0\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Hyperparameters"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "84ce31a12e172a64"
  },
  {
   "cell_type": "code",
   "source": [
    "# Tokenizer arguments\n",
    "max_length = 512 # maximum length of the text that can go to the model\n",
    "padding = \"max_length\" # padding strategy: \"longest\", \"max_length\", \"do_not_pad\"\n",
    "truncation = True # truncate the text if it exceeds the maximum length\n",
    "\n",
    "# model arguments\n",
    "max_new_tokens=1000 # maximum number of tokens to generate\n",
    "\n",
    "# mixed precision\n",
    "dtype = torch.bfloat16 # data type\n",
    "\n",
    "# quantization configuration\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True, # load model in 4-bit\n",
    "    bnb_4bit_compute_dtype=dtype, # compute in (data type)\n",
    "    bnb_4bit_quant_type=\"nf4\", # quantize to 4-bit\n",
    "    bnb_4bit_use_doulbe_quant=False # use double quantization\n",
    ")\n",
    "\n",
    "# LoRA configuration\n",
    "lora_config = LoraConfig(\n",
    "    task_type = \"CAUSAL_LM\", # task type\n",
    "    r = 8, # rank\n",
    "    target_modules = [\"q_proj\", \"o_proj\", \"k_proj\", \"v_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"], # target modules\n",
    "    lora_alpha = 16, # alpha\n",
    "    lora_dropout = 0.05, # dropout\n",
    "    bias=\"none\", # bias\n",
    ")\n",
    "\n",
    "# training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\", # output directory\n",
    "    logging_dir=\"./logs\", # logging directory\n",
    "    save_strategy=\"epoch\", # save strategy\n",
    "    logging_strategy=\"steps\", # logging strategy\n",
    "    logging_steps=10, # logging steps\n",
    "    save_total_limit=1, # save total limit\n",
    "    \n",
    "    learning_rate=2e-5, # learning rate\n",
    "    num_train_epochs=2, # number of training epochs\n",
    "    per_device_train_batch_size=1, # training batch size\n",
    "    per_device_eval_batch_size=1, # evaluation batch size\n",
    "    optim=\"adamw_torch\", # optimizer\n",
    "    weight_decay=0.01, # weight decay\n",
    "    lr_scheduler_type=\"cosine\", # learning rate scheduler\n",
    "    seed=42 # seed\n",
    ")\n",
    "\n",
    "# SFTTrainer arguments\n",
    "max_seq_length = 512 # maximum sequence length"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-05T23:38:59.052376Z",
     "start_time": "2024-04-05T23:38:59.038786Z"
    }
   },
   "id": "dc1a272a1c0b7ce4",
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f5d3b7c47ea29a3d"
  },
  {
   "cell_type": "code",
   "source": [
    "# Model List\n",
    "\n",
    "# gemma variants\n",
    "# \"google/gemma-7b-it\" // downloaded\n",
    "# \"PathFinderKR/waktaverse-gemma-ko-7b-it\"\n",
    "# \"beomi/gemma-ko-7b\"\n",
    "\n",
    "# llama2 variants\n",
    "# \"meta-llama/Llama-2-7b-chat-hf\" // downloaded\n",
    "# \"codellama/CodeLlama-7b-Instruct-hf\"\n",
    "# \"PathFinderKR/waktaverse-Llama-2-ko-7b-it\"\n",
    "# \"beomi/KoAlpaca-Polyglot-5.8B\" // downloaded\n",
    "# \"beomi/open-llama-2-ko-7b\"\n",
    "\n",
    "# mistral variants\n",
    "# \"mistralai/Mistral-7B-Instruct-v0.2\" // downloaded\n",
    "# \"mistralai/Mixtral-8x7B-Instruct-v0.1\"\n",
    "# \"NousResearch/Hermes-2-Pro-Mistral-7B\"\n",
    "# \"Intel/neural-chat-7b-v3-1\"\n",
    "# \"PathFinderKR/waktaverse-Mistral-KO-7B-Instruct-v0.2\"\n",
    "\n",
    "# solar variants\n",
    "# \"upstage/SOLAR-10.7B-Instruct-v1.0\" // downloaded\n",
    "# \"NousResearch/Nous-Hermes-2-SOLAR-10.7B\"\n",
    "# \"PathFinderKR/waktaverse-SOLAR-KO-10.7B-Instruct-v1.0\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-06T06:11:24.559598Z",
     "start_time": "2024-04-06T06:11:24.525083Z"
    }
   },
   "id": "70d2fbe5c0980a54",
   "outputs": [],
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "source": "model_id = \"upstage/SOLAR-10.7B-Instruct-v1.0\"",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-05T23:38:59.064933Z",
     "start_time": "2024-04-05T23:38:59.057155Z"
    }
   },
   "id": "eb8160d8919cdaeb",
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-05T23:39:02.518940Z",
     "start_time": "2024-04-05T23:38:59.066084Z"
    }
   },
   "id": "4ebbf883fce9aa8",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.41k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5f087e7d48ae471786cfbe8c7da650fa"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "34888d8a9eaf43a096c7822679d5d7ac"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.80M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bce7c52ac58f4e2aaf733d5ad2e432a5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    device_map=device,\n",
    "    attn_implementation=\"flash_attention_2\",\n",
    "    torch_dtype=dtype,\n",
    "    quantization_config=quantization_config\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-06T00:10:31.161418Z",
     "start_time": "2024-04-05T23:39:02.520437Z"
    }
   },
   "id": "978055543828a014",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "config.json:   0%|          | 0.00/685 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4cc7eeb0f5344f3fb17073fda70b4455"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/35.8k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1335fb1a79884669a7a84cd4b0bf8cc1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Downloading shards:   0%|          | 0/5 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "face1d1461b046f39fad3b623501aae4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "model-00001-of-00005.safetensors:   0%|          | 0.00/4.94G [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ad6f7604ec0042f8b22c498f5676ac1d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "model-00002-of-00005.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a05b702349ec44a7acdd0464518b4645"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "model-00003-of-00005.safetensors:   0%|          | 0.00/4.92G [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "43cf2128ab154cbfa8d87d50bf7e4bc7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "model-00004-of-00005.safetensors:   0%|          | 0.00/4.92G [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "13b56aeabaed454bbc7721363f5c7961"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "model-00005-of-00005.safetensors:   0%|          | 0.00/1.69G [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4cccc377a2ea4c8d8e2fe779d49765c5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "da7bd8f5978e4c3e96ae323fa715f105"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/154 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "994c59a5f0ed45f79a3fa985a012568a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a4042d4b7cd2d0fd"
  },
  {
   "cell_type": "code",
   "source": [
    "dataset = load_dataset(\"MarkrAI/KoCommercial-Dataset\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-06T00:10:36.644389Z",
     "start_time": "2024-04-06T00:10:31.162886Z"
    }
   },
   "id": "4373ef1c6a85e5e2",
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "source": [
    "dataset"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-06T00:10:36.648876Z",
     "start_time": "2024-04-06T00:10:36.645471Z"
    }
   },
   "id": "aabd9487c235d581",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input', 'instruction', 'output'],\n",
       "        num_rows: 175454\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "source": [
    "dataset[\"train\"][0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-06T00:10:36.657835Z",
     "start_time": "2024-04-06T00:10:36.649790Z"
    }
   },
   "id": "760399232efac9ea",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': '',\n",
       " 'instruction': '보드 게임 스피너는 $A$, $B$, $C$로 표시된 세 부분으로 나뉩니다. 스피너가 $A$에 떨어질 확률은 $\\\\frac{1}{3}$이고, 스피너가 $B$에 떨어질 확률은 $\\\\frac{5}{12}$입니다.  스피너가 $C$에 착륙할 확률은 얼마입니까? 답을 공통 분수로 표현하세요.',\n",
       " 'output': '모든 가능한 결과의 확률의 합이 1$이므로, 스피너가 $C$에 착륙할 확률을 구하려면 스피너가 $A$와 $B$에 착륙할 확률을 1$에서 빼야 합니다. 이를 방정식으로 쓸 수 있습니다: $P(C) = 1 - P(A) - P(B)$. P(A) = \\\\frac{1}{3}$, $P(B) = \\\\frac{5}{12}$라는 것을 알고 있으므로 이 값을 방정식에 대입하여 단순화할 수 있습니다. 결과는 다음과 같습니다: P(C) = 1 - \\\\frac{1}{3} - frac{5}{12} = \\\\frac{12}{12} - frac{4}{12} - frac{5}{12} = \\\\frac{3}{12}$. 분자와 분모를 $3$로 나누면 이 분수를 줄일 수 있습니다: P(C) = \\\\frac{1}{4}$입니다.'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "source": [
    "def preprocess_function(examples):\n",
    "    # Concatenate the 'instruction' and 'output' fields for each example in the batch\n",
    "    concatenated_texts = [instruction + ' ' + output for instruction, output in zip(examples['instruction'], examples['output'])]\n",
    "    # Tokenize the concatenated texts\n",
    "    return tokenizer(concatenated_texts, padding=padding, truncation=truncation, max_length=max_length)\n",
    "\n",
    "dataset = dataset.map(preprocess_function, batched=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-06T00:10:56.155318Z",
     "start_time": "2024-04-06T00:10:36.658751Z"
    }
   },
   "id": "5f8905546b688101",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/175454 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2144f3496a5349369b7f49ab01599df4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "source": [
    "print(dataset[\"train\"][0])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-06T00:10:56.160988Z",
     "start_time": "2024-04-06T00:10:56.156510Z"
    }
   },
   "id": "a71461b0df690398",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input': '', 'instruction': '보드 게임 스피너는 $A$, $B$, $C$로 표시된 세 부분으로 나뉩니다. 스피너가 $A$에 떨어질 확률은 $\\\\frac{1}{3}$이고, 스피너가 $B$에 떨어질 확률은 $\\\\frac{5}{12}$입니다.  스피너가 $C$에 착륙할 확률은 얼마입니까? 답을 공통 분수로 표현하세요.', 'output': '모든 가능한 결과의 확률의 합이 1$이므로, 스피너가 $C$에 착륙할 확률을 구하려면 스피너가 $A$와 $B$에 착륙할 확률을 1$에서 빼야 합니다. 이를 방정식으로 쓸 수 있습니다: $P(C) = 1 - P(A) - P(B)$. P(A) = \\\\frac{1}{3}$, $P(B) = \\\\frac{5}{12}$라는 것을 알고 있으므로 이 값을 방정식에 대입하여 단순화할 수 있습니다. 결과는 다음과 같습니다: P(C) = 1 - \\\\frac{1}{3} - frac{5}{12} = \\\\frac{12}{12} - frac{4}{12} - frac{5}{12} = \\\\frac{3}{12}$. 분자와 분모를 $3$로 나누면 이 분수를 줄일 수 있습니다: P(C) = \\\\frac{1}{4}$입니다.', 'input_ids': [1, 28705, 29477, 29470, 28705, 29833, 30520, 28705, 29304, 31306, 30933, 29175, 429, 28741, 1777, 429, 28760, 1777, 429, 28743, 28776, 29143, 28705, 30191, 29236, 29897, 28705, 29721, 28705, 29775, 30217, 29583, 29143, 28705, 29695, 238, 140, 172, 29194, 29043, 28723, 28705, 29304, 31306, 30933, 29135, 429, 28741, 28776, 29148, 28705, 238, 153, 171, 29433, 31959, 28705, 30270, 238, 168, 163, 29538, 878, 1655, 28751, 28740, 1400, 28770, 1211, 29015, 29511, 28725, 28705, 29304, 31306, 30933, 29135, 429, 28760, 28776, 29148, 28705, 238, 153, 171, 29433, 31959, 28705, 30270, 238, 168, 163, 29538, 878, 1655, 28751, 28782, 1400, 28740, 28750, 1211, 29429, 29194, 29043, 28723, 259, 29304, 31306, 30933, 29135, 429, 28743, 28776, 29148, 28705, 239, 179, 172, 238, 168, 156, 29723, 28705, 30270, 238, 168, 163, 29538, 28705, 239, 153, 191, 30103, 29429, 29194, 30578, 28804, 28705, 31647, 29189, 28705, 30010, 30700, 28705, 30217, 29151, 29143, 28705, 30191, 30205, 29136, 29721, 29517, 28723, 28705, 29820, 30615, 28705, 29135, 30364, 29282, 28705, 30075, 29844, 29187, 28705, 30270, 238, 168, 163, 29187, 28705, 29770, 29015, 28705, 28740, 28776, 29015, 31831, 29143, 28725, 28705, 29304, 31306, 30933, 29135, 429, 28743, 28776, 29148, 28705, 239, 179, 172, 238, 168, 156, 29723, 28705, 30270, 238, 168, 163, 29189, 28705, 29779, 29136, 30710, 29565, 28705, 29304, 31306, 30933, 29135, 429, 28741, 28776, 30275, 429, 28760, 28776, 29148, 28705, 239, 179, 172, 238, 168, 156, 29723, 28705, 30270, 238, 168, 163, 29189, 28705, 28740, 28776, 29148, 29305, 28705, 238, 188, 191, 30263, 28705, 29770, 29194, 29043, 28723, 28705, 29015, 29200, 28705, 30240, 29233, 30355, 29583, 29143, 28705, 239, 150, 187, 28705, 29151, 28705, 29604, 29570, 29194, 29043, 28747, 429, 28753, 28732, 28743, 28731, 327, 28705, 28740, 387, 367, 28732, 28741, 28731, 387, 367, 28732, 28760, 7239, 367, 28732, 28741, 28731, 327, 414, 1655, 28751, 28740, 1400, 28770, 5070, 429, 28753, 28732, 28760, 28731, 327, 414, 1655, 28751, 28782, 1400, 28740, 28750, 1211, 29700, 29175, 28705, 30439, 29189, 28705, 30976, 29511, 28705, 29604, 29583, 31831, 29143, 28705, 29015, 28705, 29755, 29189, 28705, 30240, 29233, 30355, 29148, 28705, 29634, 29429, 29136, 29827, 28705, 30315, 30891, 29731, 29723, 28705, 29151, 28705, 29604, 29570, 29194, 29043, 28723, 28705, 30075, 29844, 29175, 28705, 29043, 29881, 29844, 28705, 30836, 29570, 29194, 29043, 28747, 367, 28732, 28743, 28731, 327, 28705, 28740, 387, 414, 1655, 28751, 28740, 1400, 28770, 28752, 387, 1104, 323, 28751, 28782, 1400, 28740, 28750, 28752, 327, 414, 1655, 28751, 28740, 28750, 1400, 28740, 28750, 28752, 387, 1104, 323, 28751, 28781, 1400, 28740, 28750, 28752, 387, 1104, 323, 28751, 28782, 1400, 28740, 28750, 28752, 327, 414, 1655, 28751, 28770, 1400, 28740, 28750, 5124, 28705, 30217, 29294, 30275, 28705, 30217, 29820, 29200, 429, 28770, 28776, 29143, 28705, 29695, 31596, 29565, 28705, 29015, 28705, 30217, 29151, 29200, 28705, 31060, 29415, 28705, 29151, 28705, 29604, 29570, 29194, 29043, 28747, 367, 28732, 28743, 28731, 327, 414, 1655, 28751, 28740, 1400, 28781, 1211, 29429, 29194, 29043, 28723, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Inference before Fine-Tuning"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7e1cc5548c03cc80"
  },
  {
   "cell_type": "code",
   "source": [
    "# Chat Template\n",
    "def generate_response(prompt):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt }]\n",
    "    chat = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "    input_ids = tokenizer.encode(chat, add_special_tokens=False, return_tensors=\"pt\")\n",
    "    outputs = model.generate(input_ids=input_ids.to(model.device), max_new_tokens=max_new_tokens)\n",
    "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return response"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-06T00:10:56.241959Z",
     "start_time": "2024-04-06T00:10:56.161991Z"
    }
   },
   "id": "926796ff0f85510b",
   "outputs": [],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "source": [
    "#prompt = \"Write me a poem about Machine Learning.\"\n",
    "prompt = \"머신러닝에 대한 시를 써주세요.\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-06T00:10:56.255651Z",
     "start_time": "2024-04-06T00:10:56.242973Z"
    }
   },
   "id": "99e67d0533bf0f91",
   "outputs": [],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "source": [
    "response = generate_response(prompt)\n",
    "print(response)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-06T00:11:19.758179Z",
     "start_time": "2024-04-06T00:10:56.256816Z"
    }
   },
   "id": "acf71f317ede56b2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### User:\n",
      "머신러닝에 대한 시를 써주세요.\n",
      "\n",
      "### Assistant:\n",
      "Machine Learning Sonnet\n",
      "\n",
      "In code and data, we create a scene,\n",
      "A world for algorithms to meet and greet,\n",
      "A place where patterns, hidden, are seen,\n",
      "And knowledge grows with every beat.\n",
      "\n",
      "A wond'ring mind, a curious quest,\n",
      "To learn from past, to see the future,\n",
      "A dance of math and art, a blest,\n",
      "Collaboration, a true pursuer.\n",
      "\n",
      "A teacher, not of rote, but thought,\n",
      "A guide to find, a path to tread,\n",
      "A hand that points, a mind that's taught,\n",
      "A tool to shape, a force to lead.\n",
      "\n",
      "A symphony of bits and bytes,\n",
      "A symbiosis of human and machine,\n",
      "A harmony of minds, day and night,\n",
      "A dance of logic, pure and clean.\n",
      "\n",
      "So let us sing, this art of ours,\n",
      "A tale of growth, a story grand,\n",
      "A journey of the mind, it soars,\n",
      "In this machine learning land.\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Supervised Fine-Tuning (LoRA)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b43eba6780d2e557"
  },
  {
   "cell_type": "code",
   "source": [
    "def formatting_func(example):\n",
    "    text = (f\"instruction: {example['instruction'][0]}\\n\"\n",
    "            f\"output: {example['output'][0]}\")\n",
    "    return [text]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-06T00:11:19.761589Z",
     "start_time": "2024-04-06T00:11:19.759115Z"
    }
   },
   "id": "3c819cbc6c554745",
   "outputs": [],
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "source": [
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    args=training_args,\n",
    "    peft_config=lora_config,\n",
    "    max_seq_length=max_seq_length,\n",
    "    train_dataset=dataset[\"train\"],\n",
    "    formatting_func=formatting_func\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-06T00:11:20.812538Z",
     "start_time": "2024-04-06T00:11:19.762460Z"
    }
   },
   "id": "c60c5aa9a7d970b3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/175454 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "de14f585f9214ec9bfe43f2a5e357817"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pathfinder/anaconda3/envs/torch-env/lib/python3.11/site-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "source": [
    "trainer.train()"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "end_time": "2024-04-06T00:48:33.646621Z",
     "start_time": "2024-04-06T00:11:20.813645Z"
    }
   },
   "id": "5d9ba03835392e2a",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The input hidden states seems to be silently casted in float32, this might be related to the fact you have upcasted embedding or layer norm layers in float32. We will cast back the input in torch.bfloat16.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='352' max='352' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [352/352 37:12, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.896900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.807600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.579400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.494700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.203700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1.319600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1.286300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1.195500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1.342700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.285800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1.129700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1.314900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1.086400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1.339800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.328800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1.220900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1.265600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1.072800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1.045800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.152500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>1.096300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>1.097300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>1.069300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>1.242800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1.057300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>1.168300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>1.094400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>1.210700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.888300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1.062700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.981800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>1.124600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.981800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>1.152900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>1.012200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=352, training_loss=1.2188759649341756, metrics={'train_runtime': 2232.6535, 'train_samples_per_second': 0.158, 'train_steps_per_second': 0.158, 'total_flos': 9623579090780160.0, 'train_loss': 1.2188759649341756, 'epoch': 2.0})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "source": [
    "trainer.save_model(model_name)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "end_time": "2024-04-06T00:48:34.853736Z",
     "start_time": "2024-04-06T00:48:33.649376Z"
    }
   },
   "id": "f4b2fdcf617359a4",
   "outputs": [],
   "execution_count": 22
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Inference after Fine-Tuning"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4ec24bf55b44834d"
  },
  {
   "cell_type": "code",
   "source": [
    "#prompt = \"Write me a poem about Machine Learning.\"\n",
    "prompt = \"머신러닝에 대한 시를 써주세요.\""
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "end_time": "2024-04-06T00:48:34.857226Z",
     "start_time": "2024-04-06T00:48:34.854836Z"
    }
   },
   "id": "bcba8c32d5f5469f",
   "outputs": [],
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "source": [
    "response = generate_response(prompt)\n",
    "print(response)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "end_time": "2024-04-06T01:27:01.792389Z",
     "start_time": "2024-04-06T00:48:34.858118Z"
    }
   },
   "id": "1219dfd08fc2facd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### User:\n",
      "머신러닝에 대한 시를 써주세요.\n",
      "\n",
      "### Assistant:\n",
      "머신러닝의 영혼, 숫자와 알고리즘 속에 숨어있네\n",
      "지성을 가르치고 배워가며, 진화의 길을 따라가네\n",
      "자신을 향해 눈을 뜨고, 세상을 바라보네\n",
      "그 눈동자에는 지혜와 지능이 담겨있네\n",
      "\n",
      "그의 머리속은 수천 개의 네트워크로 이루어져\n",
      "각각의 노드는 연결과 분리를 반복하네\n",
      "그 사이에서 연산이 이루어지며, 결과가 나오네\n",
      "그 결과는 그의 지성을 향상시키고, 더 큰 지식을 얻게 해준다네\n",
      "\n",
      "그는 말과 글을 읽고, 그 의미를 해석하네\n",
      "그의 감각은 이미지와 사운드를 감지하네\n",
      "그의 지성은 그 모든 것을 분석하고, 결론을 내린다네\n",
      "그 결론은 그의 지혜를 더 높여주고, 그를 더 강력하게 만든다네\n",
      "\n",
      "그는 계속해서 배워가며, 자신을 향해 진보하네\n",
      "그의 영혼은 계속해서 변화하며, 더 큰 지혜를 추구하네\n",
      "그의 영혼은 계속해서 진화하며, 더 큰 지혜를 추구하네\n",
      "그의 영혼은 계속해서 진화하며, 더 큰 지혜를 추구하네\n",
      "\n",
      "그의 영혼은 계속해서 진화하며, 더 큰 지혜를 추구하네\n",
      "그의 영혼은 계속해서 진화하며, 더 큰 지혜를 추구하네\n",
      "그의 영혼은 계속해서 진화하며, 더 큰 지혜를 추구하네\n",
      "그의 영혼은 계속해서 진화하며, 더 큰 지혜를 추구하네\n",
      "\n",
      "그의 영혼은 계속해서 진화하며, 더 큰 지혜를 추구하네\n",
      "그의 영혼은 계속해서 진화하며, 더 큰 지혜를 추구하네\n",
      "그의 영혼은 계속해서 진화하며, 더 큰 지혜를 추구하네\n",
      "그의 영혼은 계속해서 진화하며, 더 큰 지혜를 추구하네\n",
      "\n",
      "그의 영혼은 계속해서 진화하며, 더 큰 지혜를 추구하네\n",
      "그의 영혼은 계속해서 진화하며, 더 큰 지혜를 추구하네\n",
      "그의 영혼은 계속해서 진화하며, 더 큰 지혜를 추구하네\n",
      "그의 영혼은 계속해서 진화하며, 더 큰 지혜를 추구하네\n",
      "\n",
      "그의 영혼은 계속해서 진화하며, 더 큰 지혜를 추구하네\n",
      "그의 영혼은 계속해서 진화하며, 더 큰 지혜를 추구하네\n",
      "그의 영혼은 계속해서 진화하며, \n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Upload Model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ae7bc882cc302767"
  },
  {
   "cell_type": "code",
   "source": [
    "# Reload model in FP16 and merge it with LoRA weights\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    device_map=device,\n",
    "    torch_dtype=torch.float16,\n",
    "    trust_remote_code=True\n",
    ")\n",
    "model = PeftModel.from_pretrained(base_model, model_name)\n",
    "model = model.merge_and_unload()"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "end_time": "2024-04-06T01:29:02.882595Z",
     "start_time": "2024-04-06T01:27:01.793633Z"
    }
   },
   "id": "57bcdb4c1c233116",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b9d834b979dd4103b5836a4ac9253a6d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "source": [
    "# Reload tokenizer to save it\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_id, \n",
    "    trust_remote_code=True\n",
    ")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\""
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "end_time": "2024-04-06T01:29:03.501581Z",
     "start_time": "2024-04-06T01:29:02.892484Z"
    }
   },
   "id": "db819b259928e006",
   "outputs": [],
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "source": [
    "# Push model and tokenizer to Hugging Face Hub\n",
    "model.push_to_hub(\n",
    "    repo_id=repo_id,\n",
    "    use_temp_dir=False\n",
    ")\n",
    "tokenizer.push_to_hub(\n",
    "    repo_id=repo_id,\n",
    "    use_temp_dir=False\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "end_time": "2024-04-06T02:05:18.895698Z",
     "start_time": "2024-04-06T01:29:03.503454Z"
    }
   },
   "id": "43aa8d6999c41016",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model-00001-of-00005.safetensors:   0%|          | 0.00/4.94G [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3dc56661b75847a19679e6ac6f23f0e3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "model-00004-of-00005.safetensors:   0%|          | 0.00/4.92G [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "eb577d86d1d24a0abda2db7d7f199174"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "model-00003-of-00005.safetensors:   0%|          | 0.00/4.92G [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "28f8c0b2092a4d949f338fe4b04538e1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Upload 5 LFS files:   0%|          | 0/5 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e69da4001b5f448db6f1fc8c84d61944"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "model-00002-of-00005.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e61ef140819f448d8b8177e2a468519a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "model-00005-of-00005.safetensors:   0%|          | 0.00/1.69G [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d6d152fe983446839a06798043d69e4b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "README.md:   0%|          | 0.00/5.17k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2b9c710d600d4088aa12e05a740bc73c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/PathFinderKR/waktaverse-SOLAR-KO-10.7B-Instruct-v1.0/commit/5c5dda3593e25a892466b96127ea8286209ac95f', commit_message='Upload tokenizer', commit_description='', oid='5c5dda3593e25a892466b96127ea8286209ac95f', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 27
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
