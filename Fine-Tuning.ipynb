{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Login to Hugging Face"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7c2f9104252a4bb"
  },
  {
   "cell_type": "code",
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from huggingface_hub import login\n",
    "\n",
    "load_dotenv()\n",
    "token = os.getenv(\"HUGGINGFACE_TOKEN\")\n",
    "login(\n",
    "    token=token, # ADD YOUR TOKEN HERE\n",
    "    add_to_git_credential=True\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-19T01:22:56.933986Z",
     "start_time": "2024-04-19T01:22:56.338549Z"
    }
   },
   "id": "4eee58c68eb02d85",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token is valid (permission: write).\n",
      "Your token has been saved in your configured git credential helpers (store).\n",
      "Your token has been saved to /home/pathfinder/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "source": [
    "model_name = \"Waktaverse-Llama-3-KO-8B-Instruct\"  # ADD YOUR MODEL NAME HERE\n",
    "username = \"PathFinderKR\"  # ADD YOUR USERNAME HERE\n",
    "repo_id = f\"{username}/{model_name}\"  # repository id"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-19T01:22:56.937428Z",
     "start_time": "2024-04-19T01:22:56.935169Z"
    }
   },
   "id": "cd4c26069d51a597",
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Downloads"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "78114e8f78ee19ec"
  },
  {
   "cell_type": "code",
   "source": [
    "#!pip install huggingface_hub\n",
    "#!pip install transformers\n",
    "#!pip install bitsandbytes\n",
    "#!pip install peft\n",
    "#!pip install trl\n",
    "#!pip install accelerate\n",
    "#!pip install datasets\n",
    "#!pip install scikit-learn\n",
    "#!pip install packaging\n",
    "#!pip install ninja\n",
    "#!pip install flash-attn --no-build-isolation"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-19T01:22:56.948655Z",
     "start_time": "2024-04-19T01:22:56.938333Z"
    }
   },
   "id": "ce6454f84604b9e4",
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Imports"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "685ac8c0e05ac872"
  },
  {
   "cell_type": "code",
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "# pytorch\n",
    "import torch\n",
    "\n",
    "# huggingface\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    BitsAndBytesConfig,\n",
    "    TrainingArguments\n",
    ")\n",
    "from peft import LoraConfig, PeftModel\n",
    "from trl import SFTTrainer\n",
    "\n",
    "# datasets\n",
    "from datasets import load_dataset"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-19T01:22:59.793321Z",
     "start_time": "2024-04-19T01:22:56.950192Z"
    }
   },
   "id": "f8c108abcd576306",
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Device"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e512d30c21d105c2"
  },
  {
   "cell_type": "code",
   "source": [
    "device = (\n",
    "    \"cuda:0\" if torch.cuda.is_available() else # Nvidia GPU\n",
    "    \"mps\" if torch.backends.mps.is_available() else # Apple Silicon GPU\n",
    "    \"cpu\"\n",
    ")\n",
    "print(f\"Device = {device}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-19T01:22:59.796918Z",
     "start_time": "2024-04-19T01:22:59.794234Z"
    }
   },
   "id": "fdf3a2a4e0e31554",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device = cuda:0\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Hyperparameters"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "84ce31a12e172a64"
  },
  {
   "cell_type": "code",
   "source": [
    "# seed\n",
    "seed=42\n",
    "\n",
    "# Tokenizer arguments\n",
    "max_length=64\n",
    "padding=\"max_length\"\n",
    "truncation=True\n",
    "\n",
    "# model arguments\n",
    "min_new_tokens=1\n",
    "max_new_tokens=128\n",
    "temperature=0.8\n",
    "top_k=40\n",
    "top_p=0.9\n",
    "repetition_penalty=1.1\n",
    "\n",
    "# validation split\n",
    "validation_size=0.1\n",
    "\n",
    "# mixed precision\n",
    "dtype=torch.bfloat16\n",
    "\n",
    "# quantization configuration\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_compute_dtype=dtype,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_use_doulbe_quant=False\n",
    ")\n",
    "\n",
    "# LoRA configuration\n",
    "lora_config = LoraConfig(\n",
    "    task_type=\"CAUSAL_LM\",\n",
    "    r=16,\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\"\n",
    ")\n",
    "\n",
    "# training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    logging_dir=\"./logs\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    save_total_limit=1,\n",
    "    \n",
    "    learning_rate=2e-5,\n",
    "    num_train_epochs=2,\n",
    "    per_device_train_batch_size=1,\n",
    "    per_device_eval_batch_size=1,\n",
    "    optim=\"adamw_torch\",\n",
    "    weight_decay=0.1,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    seed=seed\n",
    ")\n",
    "\n",
    "# SFTTrainer arguments\n",
    "max_seq_length=512"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-19T01:22:59.809039Z",
     "start_time": "2024-04-19T01:22:59.797708Z"
    }
   },
   "id": "dc1a272a1c0b7ce4",
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f5d3b7c47ea29a3d"
  },
  {
   "cell_type": "code",
   "source": [
    "# Model List\n",
    "\n",
    "# gemma variants\n",
    "# \"google/gemma-1.1-7b-it\"\n",
    "# \"google/codegemma-7b-it\"\n",
    "\n",
    "# llama2 variants\n",
    "# \"meta-llama/Meta-Llama-3-8B-Instruct\" // downloaded\n",
    "# \"codellama/CodeLlama-7b-Instruct-hf\"\n",
    "# \"PathFinderKR/Waktaverse-Llama-3-KO-8B-Instruct\"\n",
    "\n",
    "# mistral variants\n",
    "# \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "\n",
    "# solar variants\n",
    "# \"upstage/SOLAR-10.7B-Instruct-v1.0\" // downloaded\n",
    "# \"PathFinderKR/Waktaverse-SOLAR-KO-10.7B-Instruct\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-19T01:22:59.812261Z",
     "start_time": "2024-04-19T01:22:59.810027Z"
    }
   },
   "id": "70d2fbe5c0980a54",
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "source": "model_id = \"meta-llama/Meta-Llama-3-8B-Instruct\"",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-19T01:22:59.819280Z",
     "start_time": "2024-04-19T01:22:59.813183Z"
    }
   },
   "id": "eb8160d8919cdaeb",
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-19T01:23:00.239602Z",
     "start_time": "2024-04-19T01:22:59.820361Z"
    }
   },
   "id": "4ebbf883fce9aa8",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    device_map=device,\n",
    "    attn_implementation=\"flash_attention_2\",\n",
    "    torch_dtype=dtype,\n",
    "    quantization_config=quantization_config\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-19T01:23:18.540502Z",
     "start_time": "2024-04-19T01:23:00.241212Z"
    }
   },
   "id": "978055543828a014",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "56b5054773a745e6ad5a36770b9e4e8a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-19T01:23:18.545829Z",
     "start_time": "2024-04-19T01:23:18.541455Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# display the model architecture\n",
    "display(Markdown(f'```{model}```'))"
   ],
   "id": "e224c50f423698e1",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "```LlamaForCausalLM(\n  (model): LlamaModel(\n    (embed_tokens): Embedding(128256, 4096)\n    (layers): ModuleList(\n      (0-31): 32 x LlamaDecoderLayer(\n        (self_attn): LlamaFlashAttention2(\n          (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n          (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n          (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n          (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n          (rotary_emb): LlamaRotaryEmbedding()\n        )\n        (mlp): LlamaMLP(\n          (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n          (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n          (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n          (act_fn): SiLU()\n        )\n        (input_layernorm): LlamaRMSNorm()\n        (post_attention_layernorm): LlamaRMSNorm()\n      )\n    )\n    (norm): LlamaRMSNorm()\n  )\n  (lm_head): Linear(in_features=4096, out_features=128256, bias=False)\n)```"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a4042d4b7cd2d0fd"
  },
  {
   "cell_type": "code",
   "source": [
    "dataset = load_dataset(\"MarkrAI/KoCommercial-Dataset\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-19T01:23:23.523098Z",
     "start_time": "2024-04-19T01:23:18.546838Z"
    }
   },
   "id": "4373ef1c6a85e5e2",
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "source": [
    "# display the dataset information\n",
    "display(Markdown(f'```{dataset}```'))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-19T01:23:23.527290Z",
     "start_time": "2024-04-19T01:23:23.524079Z"
    }
   },
   "id": "aabd9487c235d581",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "```DatasetDict({\n    train: Dataset({\n        features: ['input', 'instruction', 'output'],\n        num_rows: 175454\n    })\n})```"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "source": [
    "# display the first example in the dataset\n",
    "display(Markdown(f'```{dataset[\"train\"][0]}```'))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-19T01:23:23.545393Z",
     "start_time": "2024-04-19T01:23:23.528116Z"
    }
   },
   "id": "760399232efac9ea",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "```{'input': '', 'instruction': '보드 게임 스피너는 $A$, $B$, $C$로 표시된 세 부분으로 나뉩니다. 스피너가 $A$에 떨어질 확률은 $\\\\frac{1}{3}$이고, 스피너가 $B$에 떨어질 확률은 $\\\\frac{5}{12}$입니다.  스피너가 $C$에 착륙할 확률은 얼마입니까? 답을 공통 분수로 표현하세요.', 'output': '모든 가능한 결과의 확률의 합이 1$이므로, 스피너가 $C$에 착륙할 확률을 구하려면 스피너가 $A$와 $B$에 착륙할 확률을 1$에서 빼야 합니다. 이를 방정식으로 쓸 수 있습니다: $P(C) = 1 - P(A) - P(B)$. P(A) = \\\\frac{1}{3}$, $P(B) = \\\\frac{5}{12}$라는 것을 알고 있으므로 이 값을 방정식에 대입하여 단순화할 수 있습니다. 결과는 다음과 같습니다: P(C) = 1 - \\\\frac{1}{3} - frac{5}{12} = \\\\frac{12}{12} - frac{4}{12} - frac{5}{12} = \\\\frac{3}{12}$. 분자와 분모를 $3$로 나누면 이 분수를 줄일 수 있습니다: P(C) = \\\\frac{1}{4}$입니다.'}```"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Preprocessing",
   "id": "6e54c42138a256a8"
  },
  {
   "cell_type": "code",
   "source": [
    "def preprocess_function(examples):\n",
    "    # Concatenate the 'instruction' and 'output' fields for each example in the batch\n",
    "    concatenated_texts = [instruction + ' ' + output for instruction, output in zip(examples['instruction'], examples['output'])]\n",
    "    # Tokenize the concatenated texts\n",
    "    return tokenizer(concatenated_texts, padding=padding, truncation=truncation, max_length=max_length)\n",
    "\n",
    "dataset = dataset.map(preprocess_function, batched=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-19T01:23:23.717825Z",
     "start_time": "2024-04-19T01:23:23.546354Z"
    }
   },
   "id": "5f8905546b688101",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-19T01:23:23.746773Z",
     "start_time": "2024-04-19T01:23:23.718989Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Split the dataset into a training and a validation dataset\n",
    "dataset = dataset[\"train\"].train_test_split(test_size=validation_size, seed=seed)\n",
    "\n",
    "# Number of questions in the train, validation dataset\n",
    "print(f\"Number of questions in the train dataset: {len(dataset['train'])}\")\n",
    "print(f\"Number of questions in the validation dataset: {len(dataset['test'])}\")"
   ],
   "id": "e78ed83f07034d92",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of questions in the train dataset: 157908\n",
      "Number of questions in the validation dataset: 17546\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "source": [
    "# display the first example in the train dataset\n",
    "display(Markdown(f'```{dataset[\"train\"][0]}```'))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-19T01:23:23.751030Z",
     "start_time": "2024-04-19T01:23:23.747709Z"
    }
   },
   "id": "a71461b0df690398",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "```{'input': '', 'instruction': '경산경찰서는 경산시 일대를 관할하나요?', 'output': '경산경찰서는 경상북도 경산시 일대를 관할하며, 경산시 원효로 68(계양동503번지)에 위치해 있습니다. 경산경찰서는 1개의 지구대와 7개의 파출소를 운영하고 있으며, 각 파출소들은 치안센터, 자인파출소, 남산치안센터, 진량파출소, 하양파출소, 청천치안센터, 압량파출소, 와촌파출소로 구성되어 있습니다.', 'input_ids': [66406, 86157, 66406, 108168, 118135, 44215, 86157, 30426, 84656, 124784, 93851, 48936, 16582, 114067, 30, 44215, 86157, 66406, 108168, 118135, 44215, 57002, 126008, 44215, 86157, 30426, 84656, 124784, 93851, 48936, 108859, 11, 44215, 86157, 30426, 102467, 111966, 17835, 220, 2614, 7, 101015, 101927, 58189, 17735, 43144, 22035, 121055, 100087, 34983, 103924, 13, 44215, 86157, 66406, 108168, 118135, 220, 16, 123590, 67890, 89359, 67945, 81673], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}```"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-19T01:23:23.757460Z",
     "start_time": "2024-04-19T01:23:23.751843Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# display the first example in the validation dataset\n",
    "display(Markdown(f'```{dataset[\"test\"][0]}```'))"
   ],
   "id": "7007cb7bc16e52a5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "```{'input': '', 'instruction': '정진영은 어떤 분야에서 활동을 했나요?', 'output': \"정진영은 1964년 11월 19일에 태어난 대한민국의 배우로, 1988년 뮤지컬 배우로 데뷔했고 1989년 연극 배우로 데뷔했다. 그는 30년 동안 깊이 있는 연기력으로 관객들의 사랑을 받았다. 그의 대표적인 작품으로는 '왕의 남자', '7번방의 선물', '국제시장' 등이 있다. 또한 연극, TV 프로그램, 영화 등 다양한 매체에서 활약했으며, 여러 상을 수상했다.\", 'input_ids': [30381, 86351, 101090, 34804, 112700, 127290, 57575, 114291, 18359, 107762, 114067, 30, 37155, 86351, 101090, 34804, 220, 5162, 19, 100392, 220, 806, 100551, 220, 777, 124521, 106891, 32179, 103777, 110342, 21028, 116921, 17835, 11, 220, 3753, 23, 100392, 5251, 112800, 22035, 121735, 116921, 17835, 103659, 111368, 242, 122196, 220, 3753, 24, 100392, 78453, 110616, 116921, 17835, 103659, 111368, 242, 101528, 13, 108154, 220, 966], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}```"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Prompt Engineering",
   "id": "b54606c539497026"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-19T01:23:23.763260Z",
     "start_time": "2024-04-19T01:23:23.758324Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Chat Template\n",
    "system_prompt = \"You are a poet. Write a poem about the following topic. Use Korean Only.\""
   ],
   "id": "6296a3ab5e72f67b",
   "outputs": [],
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "source": [
    "def generate_response(user_prompt):\n",
    "    prompt = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt }\n",
    "    ]\n",
    "    prompt = tokenizer.apply_chat_template(prompt, tokenize=False, add_generation_prompt=True)\n",
    "    input_ids = tokenizer.encode(prompt, add_special_tokens=True, return_tensors=\"pt\").to(device)\n",
    "    outputs = model.generate(\n",
    "        input_ids=input_ids,\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "        min_new_tokens=min_new_tokens,\n",
    "        max_new_tokens=max_new_tokens,\n",
    "        do_sample=True,\n",
    "        temperature=temperature,\n",
    "        top_k=top_k,\n",
    "        top_p=top_p,\n",
    "        repetition_penalty=repetition_penalty\n",
    "    )\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-19T01:23:23.770044Z",
     "start_time": "2024-04-19T01:23:23.764106Z"
    }
   },
   "id": "926796ff0f85510b",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Inference before Fine-Tuning",
   "id": "7e1cc5548c03cc80"
  },
  {
   "cell_type": "code",
   "source": [
    "#message = \"Write me a poem about Machine Learning.\"\n",
    "message = \"머신러닝에 대한 시를 써주세요.\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-19T01:23:23.777969Z",
     "start_time": "2024-04-19T01:23:23.770936Z"
    }
   },
   "id": "99e67d0533bf0f91",
   "outputs": [],
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "source": [
    "response = generate_response(message)\n",
    "print(response)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-19T01:23:28.979812Z",
     "start_time": "2024-04-19T01:23:23.778778Z"
    }
   },
   "id": "acf71f317ede56b2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "You are a poet. Write a poem about the following topic. Use Korean Only.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "머신러닝에 대한 시를 써주세요.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      " AI의 고단한 노래\n",
      "\n",
      "가상 세계 속에서 춤을 추는 것 같아\n",
      "머신러닝의 정령은 숨어 있는 것 같아\n",
      "데이터의 흐름에 따라 움직이는 것 같아\n",
      "지식의 결을 맺는 것 같아\n",
      "\n",
      "이 세상에는 비밀스러운 힘들이 있지만\n",
      "머신러닝의 손길에 의해 그늘로 덮힌 것 같아\n",
      "성과도 없고, 부도 없는 것 같아\n",
      "만약에 실패하면 다시 시작하는 것 같아\n",
      "\n",
      "AI의 시련을 견디시고 싶다\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Supervised Fine-Tuning (LoRA)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b43eba6780d2e557"
  },
  {
   "cell_type": "code",
   "source": [
    "def formatting_func(example):\n",
    "    text = (f\"instruction: {example['instruction'][0]}\\n\"\n",
    "            f\"output: {example['output'][0]}\")\n",
    "    return [text]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-19T01:23:28.982982Z",
     "start_time": "2024-04-19T01:23:28.980742Z"
    }
   },
   "id": "3c819cbc6c554745",
   "outputs": [],
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "source": [
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    args=training_args,\n",
    "    peft_config=lora_config,\n",
    "    max_seq_length=max_seq_length,\n",
    "    train_dataset=dataset[\"train\"],\n",
    "    eval_dataset=dataset[\"test\"],\n",
    "    formatting_func=formatting_func\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-19T01:23:29.608511Z",
     "start_time": "2024-04-19T01:23:28.984197Z"
    }
   },
   "id": "c60c5aa9a7d970b3",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pathfinder/anaconda3/envs/torch-env/lib/python3.11/site-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "source": [
    "trainer.train()"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "end_time": "2024-04-19T01:34:33.122622Z",
     "start_time": "2024-04-19T01:23:29.609627Z"
    }
   },
   "id": "5d9ba03835392e2a",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The input hidden states seems to be silently casted in float32, this might be related to the fact you have upcasted embedding or layer norm layers in float32. We will cast back the input in torch.bfloat16.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='316' max='316' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [316/316 10:59, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2.422300</td>\n",
       "      <td>2.247169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>2.382900</td>\n",
       "      <td>2.176457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>2.163800</td>\n",
       "      <td>2.111722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>2.157400</td>\n",
       "      <td>2.055972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2.054300</td>\n",
       "      <td>2.004975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>2.070800</td>\n",
       "      <td>1.973776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1.969700</td>\n",
       "      <td>1.954580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>2.050800</td>\n",
       "      <td>1.935925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>2.210400</td>\n",
       "      <td>1.913988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>2.053000</td>\n",
       "      <td>1.902555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1.976100</td>\n",
       "      <td>1.892840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>2.046900</td>\n",
       "      <td>1.886565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1.988700</td>\n",
       "      <td>1.883666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>2.114500</td>\n",
       "      <td>1.880377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.832300</td>\n",
       "      <td>1.876730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1.985500</td>\n",
       "      <td>1.875282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1.591600</td>\n",
       "      <td>1.874769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1.863700</td>\n",
       "      <td>1.873408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1.824900</td>\n",
       "      <td>1.872996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.992500</td>\n",
       "      <td>1.873642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>1.782300</td>\n",
       "      <td>1.872156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>1.806100</td>\n",
       "      <td>1.870392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>1.847100</td>\n",
       "      <td>1.869298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>1.800600</td>\n",
       "      <td>1.868667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1.812500</td>\n",
       "      <td>1.868137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>1.910700</td>\n",
       "      <td>1.868121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>1.934000</td>\n",
       "      <td>1.867583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>1.820300</td>\n",
       "      <td>1.866926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>1.421400</td>\n",
       "      <td>1.867079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1.969300</td>\n",
       "      <td>1.866812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>1.935800</td>\n",
       "      <td>1.866965</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=316, training_loss=1.9584842905213562, metrics={'train_runtime': 663.3519, 'train_samples_per_second': 0.476, 'train_steps_per_second': 0.476, 'total_flos': 4038359100162048.0, 'train_loss': 1.9584842905213562, 'epoch': 2.0})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "source": [
    "trainer.save_model(model_name)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "end_time": "2024-04-19T01:34:34.258388Z",
     "start_time": "2024-04-19T01:34:33.123956Z"
    }
   },
   "id": "f4b2fdcf617359a4",
   "outputs": [],
   "execution_count": 26
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Inference after Fine-Tuning"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4ec24bf55b44834d"
  },
  {
   "cell_type": "code",
   "source": [
    "#message = \"Write me a poem about Machine Learning.\"\n",
    "message = \"머신러닝에 대한 시를 써주세요.\""
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "end_time": "2024-04-19T01:34:34.261540Z",
     "start_time": "2024-04-19T01:34:34.259297Z"
    }
   },
   "id": "bcba8c32d5f5469f",
   "outputs": [],
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "source": [
    "response = generate_response(message)\n",
    "print(response)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "end_time": "2024-04-19T01:34:44.088427Z",
     "start_time": "2024-04-19T01:34:34.263131Z"
    }
   },
   "id": "1219dfd08fc2facd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "You are a poet. Write a poem about the following topic. Use Korean Only.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "머신러닝에 대한 시를 써주세요.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "기계학습의 숲 속에서\n",
      "로봇들이 배운다네\n",
      "자율주행차는 어디로 간단하오?\n",
      "사람들은 그려져 있네\n",
      "\n",
      "알고리즘의 기초를 다지게 하라\n",
      "데이터들을 모아보자\n",
      "이동하는 목표가 무엇인지 파악하게 하라\n",
      "성공을 거둘 수 있도록 보조자로 나서자\n",
      "\n",
      "물리학과 인공지능이 함께 춤을 출라\n",
      "AI의 발명은 인류에게도 알려졌다\n",
      "인간의 머릿속에서 어떤 생각을 하\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Upload Model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ae7bc882cc302767"
  },
  {
   "cell_type": "code",
   "source": [
    "# Reload model in FP16 and merge it with LoRA weights\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    device_map=device,\n",
    "    torch_dtype=torch.float16,\n",
    "    trust_remote_code=True\n",
    ")\n",
    "model = PeftModel.from_pretrained(base_model, model_name)\n",
    "model = model.merge_and_unload()"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "end_time": "2024-04-19T01:35:16.364080Z",
     "start_time": "2024-04-19T01:34:44.089423Z"
    }
   },
   "id": "57bcdb4c1c233116",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1d3d5d09c8704155aa839786bdddde42"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 29
  },
  {
   "cell_type": "code",
   "source": [
    "# Reload tokenizer to save it\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_id, \n",
    "    trust_remote_code=True\n",
    ")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\""
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "end_time": "2024-04-19T01:35:16.926170Z",
     "start_time": "2024-04-19T01:35:16.365373Z"
    }
   },
   "id": "db819b259928e006",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "cell_type": "code",
   "source": [
    "# Push model and tokenizer to Hugging Face Hub\n",
    "model.push_to_hub(\n",
    "    repo_id=repo_id,\n",
    "    use_temp_dir=False\n",
    ")\n",
    "tokenizer.push_to_hub(\n",
    "    repo_id=repo_id,\n",
    "    use_temp_dir=False\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "end_time": "2024-04-19T02:01:03.877753Z",
     "start_time": "2024-04-19T01:35:16.927239Z"
    }
   },
   "id": "43aa8d6999c41016",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model-00001-of-00004.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f6db356a44e14d38822946d2e7dcf439"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "model-00003-of-00004.safetensors:   0%|          | 0.00/4.92G [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "18401098fe164dc292455d5c7f2536b9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "model-00004-of-00004.safetensors:   0%|          | 0.00/1.17G [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9ca3fc3c2111441ba491577413aa64f9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Upload 4 LFS files:   0%|          | 0/4 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "62e963e0274f4ea68e2405d21f44ec82"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "model-00002-of-00004.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4001042ec0504fa7bb60474dbfb9b50a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "README.md:   0%|          | 0.00/5.17k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7587d1e2a70c4c4989a7af7ae89137a3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/PathFinderKR/Waktaverse-Llama-3-KO-8B-Instruct/commit/19f5b563d383dfc101af1d562698b58dc83adbe4', commit_message='Upload tokenizer', commit_description='', oid='19f5b563d383dfc101af1d562698b58dc83adbe4', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 31
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
