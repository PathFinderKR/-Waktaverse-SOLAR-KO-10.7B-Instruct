{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Login to Hugging Face"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7c2f9104252a4bb"
  },
  {
   "cell_type": "code",
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from huggingface_hub import login\n",
    "\n",
    "load_dotenv()\n",
    "token = os.getenv(\"HUGGINGFACE_TOKEN\")\n",
    "login(\n",
    "    token=token,  # ADD YOUR TOKEN HERE\n",
    "    add_to_git_credential=True\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-22T08:49:30.495951Z",
     "start_time": "2024-04-22T08:49:29.964793Z"
    }
   },
   "id": "4eee58c68eb02d85",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token is valid (permission: write).\n",
      "Your token has been saved in your configured git credential helpers (store).\n",
      "Your token has been saved to /home/pathfinder/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "source": [
    "model_name = \"Waktaverse-Llama-3-KO-8B-Instruct\"  # ADD YOUR MODEL NAME HERE\n",
    "username = \"PathFinderKR\"  # ADD YOUR USERNAME HERE\n",
    "repo_id = f\"{username}/{model_name}\"  # repository id"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-22T08:49:30.499731Z",
     "start_time": "2024-04-22T08:49:30.497382Z"
    }
   },
   "id": "cd4c26069d51a597",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Login to Weights and Biases",
   "id": "45b93503027bc62"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T08:49:32.388347Z",
     "start_time": "2024-04-22T08:49:30.500665Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import wandb\n",
    "\n",
    "api_key = os.getenv(\"WANDB_API_KEY\")\n",
    "wandb.login(\n",
    "    key=api_key  # ADD YOUR API KEY HERE\n",
    ")"
   ],
   "id": "bd9885bdc6270f76",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33mpathfinderkr\u001B[0m (\u001B[33mwaktaverse\u001B[0m). Use \u001B[1m`wandb login --relogin`\u001B[0m to force relogin\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \u001B[33mWARNING\u001B[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \u001B[33mWARNING\u001B[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Appending key for api.wandb.ai to your netrc file: /home/pathfinder/.netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Downloads"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "78114e8f78ee19ec"
  },
  {
   "cell_type": "code",
   "source": [
    "#!pip install huggingface_hub\n",
    "#!pip install wandb\n",
    "#!pip install transformers\n",
    "#!pip install bitsandbytes\n",
    "#!pip install peft\n",
    "#!pip install trl\n",
    "#!pip install accelerate\n",
    "#!pip install datasets\n",
    "#!pip install scikit-learn\n",
    "#!pip install packaging\n",
    "#!pip install ninja\n",
    "#!pip install flash-attn --no-build-isolation"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-22T08:49:32.391623Z",
     "start_time": "2024-04-22T08:49:32.389390Z"
    }
   },
   "id": "ce6454f84604b9e4",
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Imports"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "685ac8c0e05ac872"
  },
  {
   "cell_type": "code",
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "# pytorch\n",
    "import torch\n",
    "\n",
    "# huggingface\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    BitsAndBytesConfig,\n",
    "    TrainingArguments\n",
    ")\n",
    "from peft import LoraConfig, PeftModel\n",
    "from trl import SFTTrainer, DataCollatorForCompletionOnlyLM\n",
    "\n",
    "# datasets\n",
    "from datasets import load_dataset"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-22T08:49:35.403635Z",
     "start_time": "2024-04-22T08:49:32.392871Z"
    }
   },
   "id": "f8c108abcd576306",
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Device"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e512d30c21d105c2"
  },
  {
   "cell_type": "code",
   "source": [
    "# Device setup\n",
    "device = (\n",
    "    \"cuda:0\" if torch.cuda.is_available() else # Nvidia GPU\n",
    "    \"mps\" if torch.backends.mps.is_available() else # Apple Silicon GPU\n",
    "    \"cpu\"\n",
    ")\n",
    "print(f\"Device = {device}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-22T08:49:35.407357Z",
     "start_time": "2024-04-22T08:49:35.404765Z"
    }
   },
   "id": "fdf3a2a4e0e31554",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device = cuda:0\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T08:49:35.414381Z",
     "start_time": "2024-04-22T08:49:35.408350Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Flashlight Attention Implementation\n",
    "if torch.cuda.get_device_capability()[0] >= 8: # Ampere, Ada, or Hopper GPUs\n",
    "    attn_implementation = \"flash_attention_2\"\n",
    "    torch_dtype = torch.bfloat16\n",
    "else:\n",
    "    attn_implementation = \"eager\"\n",
    "    torch_dtype = torch.float16\n",
    "print(f\"Attention Implementation = {attn_implementation}\")"
   ],
   "id": "d96a4ad9abc2d0ed",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention Implementation = flash_attention_2\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Hyperparameters"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "84ce31a12e172a64"
  },
  {
   "cell_type": "code",
   "source": [
    "################################################################################\n",
    "# seed\n",
    "################################################################################\n",
    "seed=42\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "################################################################################\n",
    "# Tokenizer parameters\n",
    "################################################################################\n",
    "max_length=1024\n",
    "padding=\"do_not_pad\" # \"max_length\", \"longest\", \"do_not_pad\"\n",
    "truncation=True\n",
    "\n",
    "################################################################################\n",
    "# Generation parameters\n",
    "################################################################################\n",
    "num_return_sequences=1\n",
    "min_new_tokens=1\n",
    "max_new_tokens=1024\n",
    "do_sample=True # True for sampling, False for greedy decoding\n",
    "temperature=0.6\n",
    "top_k=40\n",
    "top_p=0.9\n",
    "repetition_penalty=1.1\n",
    "\n",
    "################################################################################\n",
    "# Dataset parameters\n",
    "################################################################################\n",
    "validation_size=0.1\n",
    "\n",
    "################################################################################\n",
    "# bitsandbytes parameters\n",
    "################################################################################\n",
    "load_in_4bit=True\n",
    "bnb_4bit_compute_dtype=torch_dtype\n",
    "bnb_4bit_quant_type=\"nf4\" # \"nf4\", #fp4\"\n",
    "bnb_4bit_use_double_quant=True\n",
    "\n",
    "################################################################################\n",
    "# LoRA parameters\n",
    "################################################################################\n",
    "task_type=\"CAUSAL_LM\"\n",
    "target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"]\n",
    "r=8\n",
    "lora_alpha=16\n",
    "lora_dropout=0.05\n",
    "bias=\"none\"\n",
    "\n",
    "################################################################################\n",
    "# TrainingArguments parameters\n",
    "################################################################################\n",
    "output_dir=\"./results\"\n",
    "logging_dir=\"./logs\"\n",
    "save_strategy=\"epoch\" # \"steps\", \"epoch\"\n",
    "logging_strategy=\"steps\" # \"steps\", \"epoch\"\n",
    "if logging_strategy == \"steps\":\n",
    "    logging_steps=10\n",
    "else:\n",
    "    logging_steps=None\n",
    "evaluation_strategy=\"steps\" # \"steps\", \"epoch\"\n",
    "if evaluation_strategy == \"steps\":\n",
    "    eval_steps=10\n",
    "else:\n",
    "    eval_steps=None\n",
    "save_total_limit=1\n",
    "report_to=\"wandb\"\n",
    "\n",
    "learning_rate=2e-5\n",
    "num_train_epochs=1\n",
    "per_device_train_batch_size=1\n",
    "per_device_eval_batch_size=1\n",
    "grad_accumulation_steps=1\n",
    "optim=\"adamw_torch\" # \"sgd\", \"adamw_torch\"\n",
    "weight_decay=0.1\n",
    "lr_scheduler_type=\"cosine\" # \"constant\", \"linear\", \"cosine\"\n",
    "warmup_steps=10\n",
    "warmup_ratio=0.1\n",
    "\n",
    "################################################################################\n",
    "# SFT parameters\n",
    "################################################################################\n",
    "max_seq_length=1024\n",
    "packing=False"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-22T08:49:35.421714Z",
     "start_time": "2024-04-22T08:49:35.415467Z"
    }
   },
   "id": "dc1a272a1c0b7ce4",
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f5d3b7c47ea29a3d"
  },
  {
   "cell_type": "code",
   "source": [
    "# Model List\n",
    "\n",
    "# gemma variants\n",
    "# \"google/gemma-1.1-7b-it\"\n",
    "# \"google/codegemma-7b-it\"\n",
    "\n",
    "# llama2 variants\n",
    "# \"meta-llama/Meta-Llama-3-8B-Instruct\" // downloaded\n",
    "# \"codellama/CodeLlama-7b-Instruct-hf\"\n",
    "# \"PathFinderKR/Waktaverse-Llama-3-KO-8B-Instruct\"\n",
    "\n",
    "# mistral variants\n",
    "# \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "\n",
    "# solar variants\n",
    "# \"upstage/SOLAR-10.7B-Instruct-v1.0\" // downloaded\n",
    "# \"PathFinderKR/Waktaverse-SOLAR-KO-10.7B-Instruct\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-22T08:49:35.430054Z",
     "start_time": "2024-04-22T08:49:35.422776Z"
    }
   },
   "id": "70d2fbe5c0980a54",
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "source": [
    "# Model ID for base model\n",
    "model_id = \"meta-llama/Meta-Llama-3-8B-Instruct\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-22T08:49:35.438908Z",
     "start_time": "2024-04-22T08:49:35.431286Z"
    }
   },
   "id": "eb8160d8919cdaeb",
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "source": [
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "tokenizer.add_special_tokens({'pad_token': '[PAD]'}) # add padding token\n",
    "tokenizer.padding_side = \"right\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-22T08:49:35.878509Z",
     "start_time": "2024-04-22T08:49:35.439995Z"
    }
   },
   "id": "4ebbf883fce9aa8",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T08:49:35.883282Z",
     "start_time": "2024-04-22T08:49:35.879808Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Quantization\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=load_in_4bit,\n",
    "    bnb_4bit_compute_dtype=bnb_4bit_compute_dtype,\n",
    "    bnb_4bit_quant_type=bnb_4bit_quant_type,\n",
    "    bnb_4bit_use_double_quant=bnb_4bit_use_double_quant\n",
    ")"
   ],
   "id": "69d30da42bd6cf7b",
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "source": [
    "# Load model\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    device_map=device,\n",
    "    attn_implementation=attn_implementation,\n",
    "    torch_dtype=torch_dtype,\n",
    "    quantization_config=quantization_config,\n",
    "    use_cache=True\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-22T08:49:58.840108Z",
     "start_time": "2024-04-22T08:49:35.884146Z"
    }
   },
   "id": "978055543828a014",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "be488243f139485fb052c8ef5d80cf80"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T08:49:58.846354Z",
     "start_time": "2024-04-22T08:49:58.842025Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# display the model architecture\n",
    "display(Markdown(f'```{model}```'))"
   ],
   "id": "e224c50f423698e1",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "```LlamaForCausalLM(\n  (model): LlamaModel(\n    (embed_tokens): Embedding(128256, 4096)\n    (layers): ModuleList(\n      (0-31): 32 x LlamaDecoderLayer(\n        (self_attn): LlamaFlashAttention2(\n          (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n          (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n          (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n          (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n          (rotary_emb): LlamaRotaryEmbedding()\n        )\n        (mlp): LlamaMLP(\n          (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n          (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n          (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n          (act_fn): SiLU()\n        )\n        (input_layernorm): LlamaRMSNorm()\n        (post_attention_layernorm): LlamaRMSNorm()\n      )\n    )\n    (norm): LlamaRMSNorm()\n  )\n  (lm_head): Linear(in_features=4096, out_features=128256, bias=False)\n)```"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a4042d4b7cd2d0fd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T08:49:58.852949Z",
     "start_time": "2024-04-22T08:49:58.847263Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Dataset ID\n",
    "dataset_id = \"MarkrAI/KoCommercial-Dataset\""
   ],
   "id": "4cd4661dab93e4c8",
   "outputs": [],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "source": [
    "# Load the dataset\n",
    "dataset = load_dataset(dataset_id)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-22T08:50:03.017856Z",
     "start_time": "2024-04-22T08:49:58.854189Z"
    }
   },
   "id": "4373ef1c6a85e5e2",
   "outputs": [],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "source": [
    "# Dataset information\n",
    "dataset"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-22T08:50:03.021977Z",
     "start_time": "2024-04-22T08:50:03.018971Z"
    }
   },
   "id": "aabd9487c235d581",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input', 'instruction', 'output'],\n",
       "        num_rows: 175454\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "source": [
    "# Dataset example\n",
    "dataset[\"train\"][0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-22T08:50:03.029557Z",
     "start_time": "2024-04-22T08:50:03.022998Z"
    }
   },
   "id": "760399232efac9ea",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': '',\n",
       " 'instruction': '보드 게임 스피너는 $A$, $B$, $C$로 표시된 세 부분으로 나뉩니다. 스피너가 $A$에 떨어질 확률은 $\\\\frac{1}{3}$이고, 스피너가 $B$에 떨어질 확률은 $\\\\frac{5}{12}$입니다.  스피너가 $C$에 착륙할 확률은 얼마입니까? 답을 공통 분수로 표현하세요.',\n",
       " 'output': '모든 가능한 결과의 확률의 합이 1$이므로, 스피너가 $C$에 착륙할 확률을 구하려면 스피너가 $A$와 $B$에 착륙할 확률을 1$에서 빼야 합니다. 이를 방정식으로 쓸 수 있습니다: $P(C) = 1 - P(A) - P(B)$. P(A) = \\\\frac{1}{3}$, $P(B) = \\\\frac{5}{12}$라는 것을 알고 있으므로 이 값을 방정식에 대입하여 단순화할 수 있습니다. 결과는 다음과 같습니다: P(C) = 1 - \\\\frac{1}{3} - frac{5}{12} = \\\\frac{12}{12} - frac{4}{12} - frac{5}{12} = \\\\frac{3}{12}$. 분자와 분모를 $3$로 나누면 이 분수를 줄일 수 있습니다: P(C) = \\\\frac{1}{4}$입니다.'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Preprocessing",
   "id": "6e54c42138a256a8"
  },
  {
   "cell_type": "code",
   "source": [
    "# Alpaca dataset format\n",
    "def preprocess_function(examples):\n",
    "    instruction = examples[\"instruction\"]\n",
    "    input_text = examples[\"input\"]\n",
    "    output_text = examples[\"output\"]\n",
    "    return {\n",
    "        \"instruction\": instruction,\n",
    "        \"input\": input_text,\n",
    "        \"output\": output_text\n",
    "    }\n",
    "    \n",
    "dataset = dataset.map(preprocess_function, batched=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-22T08:50:03.131418Z",
     "start_time": "2024-04-22T08:50:03.030455Z"
    }
   },
   "id": "5f8905546b688101",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T08:50:03.163519Z",
     "start_time": "2024-04-22T08:50:03.132443Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Split the dataset into a training and a validation dataset\n",
    "dataset = dataset[\"train\"].train_test_split(test_size=validation_size, seed=seed)\n",
    "\n",
    "# Number of questions in the train, validation dataset\n",
    "print(f\"Number of questions in the train dataset: {len(dataset['train'])}\")\n",
    "print(f\"Number of questions in the validation dataset: {len(dataset['test'])}\")"
   ],
   "id": "e78ed83f07034d92",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of questions in the train dataset: 157908\n",
      "Number of questions in the validation dataset: 17546\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T08:50:03.167791Z",
     "start_time": "2024-04-22T08:50:03.164511Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Dataset examples\n",
    "print(dataset[\"train\"][0][\"instruction\"])\n",
    "print(dataset[\"train\"][0][\"input\"])\n",
    "print(dataset[\"train\"][0][\"output\"])"
   ],
   "id": "4cf2c30835e34a13",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "경산경찰서는 경산시 일대를 관할하나요?\n",
      "\n",
      "경산경찰서는 경상북도 경산시 일대를 관할하며, 경산시 원효로 68(계양동503번지)에 위치해 있습니다. 경산경찰서는 1개의 지구대와 7개의 파출소를 운영하고 있으며, 각 파출소들은 치안센터, 자인파출소, 남산치안센터, 진량파출소, 하양파출소, 청천치안센터, 압량파출소, 와촌파출소로 구성되어 있습니다.\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T08:50:03.174554Z",
     "start_time": "2024-04-22T08:50:03.168801Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(dataset[\"test\"][0][\"instruction\"])\n",
    "print(dataset[\"test\"][0][\"input\"])\n",
    "print(dataset[\"test\"][0][\"output\"])"
   ],
   "id": "64a375461a6190c6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정진영은 어떤 분야에서 활동을 했나요?\n",
      "\n",
      "정진영은 1964년 11월 19일에 태어난 대한민국의 배우로, 1988년 뮤지컬 배우로 데뷔했고 1989년 연극 배우로 데뷔했다. 그는 30년 동안 깊이 있는 연기력으로 관객들의 사랑을 받았다. 그의 대표적인 작품으로는 '왕의 남자', '7번방의 선물', '국제시장' 등이 있다. 또한 연극, TV 프로그램, 영화 등 다양한 매체에서 활약했으며, 여러 상을 수상했다.\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T08:50:03.182970Z",
     "start_time": "2024-04-22T08:50:03.175653Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Train on only a subset of the dataset for demonstration purposes\n",
    "dataset[\"train\"] = dataset[\"train\"].select(range(100))\n",
    "dataset[\"test\"] = dataset[\"test\"].select(range(10))"
   ],
   "id": "8a321aa7dbe80a3e",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Inference before Fine-Tuning",
   "id": "7e1cc5548c03cc80"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T08:50:03.188905Z",
     "start_time": "2024-04-22T08:50:03.183903Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def generate_response(system ,user):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system},\n",
    "        {\"role\": \"user\", \"content\": user}\n",
    "    ]\n",
    "    prompt = tokenizer.apply_chat_template(\n",
    "        messages, \n",
    "        tokenize=False, \n",
    "        add_generation_prompt=False\n",
    "    )\n",
    "    \n",
    "    input_ids = tokenizer.encode(\n",
    "        prompt,\n",
    "        max_length=max_length,\n",
    "        padding=padding,\n",
    "        truncation=truncation,\n",
    "        add_special_tokens=True,\n",
    "        return_tensors=\"pt\"\n",
    "    ).to(device)\n",
    "    \n",
    "    outputs = model.generate(\n",
    "        input_ids=input_ids,\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "        num_return_sequences=num_return_sequences,\n",
    "        min_new_tokens=min_new_tokens,\n",
    "        max_new_tokens=max_new_tokens,\n",
    "        do_sample=do_sample,\n",
    "        temperature=temperature,\n",
    "        top_k=top_k,\n",
    "        top_p=top_p,\n",
    "        repetition_penalty=repetition_penalty\n",
    "    )\n",
    "    \n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=False)"
   ],
   "id": "926796ff0f85510b",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T08:50:03.195746Z",
     "start_time": "2024-04-22T08:50:03.190055Z"
    }
   },
   "cell_type": "code",
   "source": "system_prompt = \"You are a helpful assistant. Respond to the following user prompt. Use Korean only. 한국어만 사용하세요.\"",
   "id": "6296a3ab5e72f67b",
   "outputs": [],
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "source": [
    "#user_prompt = \"Write me a poem about Machine Learning.\"\n",
    "user_prompt = \"머신러닝에 대한 시를 써주세요.\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-22T08:50:03.202375Z",
     "start_time": "2024-04-22T08:50:03.196722Z"
    }
   },
   "id": "99e67d0533bf0f91",
   "outputs": [],
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "source": [
    "response = generate_response(system_prompt, user_prompt)\n",
    "print(response)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-22T08:50:12.808793Z",
     "start_time": "2024-04-22T08:50:03.203283Z"
    }
   },
   "id": "acf71f317ede56b2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "You are a helpful assistant. Respond to the following user prompt. Use Korean only. 한국어만 사용하세요.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "머신러닝에 대한 시를 써주세요.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "머신 러닝의 노래\n",
      "\n",
      "머신 러닝의 꿈은 하늘 높이\n",
      "데이터를 모으면 새로운 세상\n",
      "알고리즘의 춤을 추는 밤\n",
      "인공지능의 새벽을 맞이할 것\n",
      "\n",
      "자료의 흐름 속에서 우리는 찾는다\n",
      "패턴과 상관관계를 파악하여\n",
      "새로운 지식을 얻는 데 성공하라\n",
      "인간의 삶을 더 잘 이해할 수 있게\n",
      "\n",
      "머신 러닝의 노래는 끝나지 않아\n",
      "계속적으로 발전하고 있는 그릇\n",
      "인류의 미래를 예측하는 데 도움이 되리\n",
      "새로운 세상을 창조하는 데 일조하게\n",
      "\n",
      "(Note: This is a poem written in Korean about machine learning.)<|eot_id|>\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Supervised Fine-Tuning (LoRA)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b43eba6780d2e557"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T08:50:12.812603Z",
     "start_time": "2024-04-22T08:50:12.809833Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def formatting_func(example):\n",
    "    texts = []\n",
    "    for i in range(len(example['instruction'])):\n",
    "        instruction = example['instruction'][i]\n",
    "        input_text = example['input'][i]\n",
    "        output_text = example['output'][i]\n",
    "        text = (\n",
    "            f\"### Instruction: {instruction}\\n\"\n",
    "            f\"### Input: {input_text}\\n\"\n",
    "            f\"### Output: {output_text}\\n\"\n",
    "        )\n",
    "        texts.append(text)\n",
    "    return texts"
   ],
   "id": "39f4d0e17c42f13d",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T08:50:12.819813Z",
     "start_time": "2024-04-22T08:50:12.813396Z"
    }
   },
   "cell_type": "code",
   "source": [
    "response_template = \"### Output:\"\n",
    "data_collator = DataCollatorForCompletionOnlyLM(\n",
    "    response_template=response_template, \n",
    "    tokenizer=tokenizer\n",
    ")"
   ],
   "id": "6bf404f160aba0ce",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T08:50:12.826253Z",
     "start_time": "2024-04-22T08:50:12.820955Z"
    }
   },
   "cell_type": "code",
   "source": [
    "lora_config = LoraConfig(\n",
    "    task_type=task_type,\n",
    "    target_modules=target_modules,\n",
    "    r=r,\n",
    "    lora_alpha=lora_alpha,\n",
    "    lora_dropout=lora_dropout,\n",
    "    bias=bias\n",
    ")"
   ],
   "id": "75ef555547f56ebf",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T08:50:12.876387Z",
     "start_time": "2024-04-22T08:50:12.827187Z"
    }
   },
   "cell_type": "code",
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    logging_dir=logging_dir,\n",
    "    save_strategy=save_strategy,\n",
    "    logging_strategy=logging_strategy,\n",
    "    logging_steps=logging_steps,\n",
    "    evaluation_strategy=evaluation_strategy,\n",
    "    eval_steps=eval_steps,\n",
    "    save_total_limit=save_total_limit,\n",
    "    report_to=report_to,\n",
    "    \n",
    "    learning_rate=learning_rate,\n",
    "    num_train_epochs=num_train_epochs,\n",
    "    per_device_train_batch_size=per_device_train_batch_size,\n",
    "    per_device_eval_batch_size=per_device_eval_batch_size,\n",
    "    gradient_accumulation_steps=grad_accumulation_steps,\n",
    "    optim=optim,\n",
    "    weight_decay=weight_decay,\n",
    "    lr_scheduler_type=lr_scheduler_type,\n",
    "    warmup_steps=warmup_steps,\n",
    "    warmup_ratio=warmup_ratio,\n",
    "    seed=seed\n",
    ")"
   ],
   "id": "2e29a9a3ca3b96b1",
   "outputs": [],
   "execution_count": 31
  },
  {
   "cell_type": "code",
   "source": [
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    args=training_args,\n",
    "    peft_config=lora_config,\n",
    "    max_seq_length=max_seq_length,\n",
    "    train_dataset=dataset[\"train\"],\n",
    "    eval_dataset=dataset[\"test\"],\n",
    "    formatting_func=formatting_func,\n",
    "    data_collator=data_collator,\n",
    "    packing=packing\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-22T08:50:13.352798Z",
     "start_time": "2024-04-22T08:50:12.877465Z"
    }
   },
   "id": "c60c5aa9a7d970b3",
   "outputs": [],
   "execution_count": 32
  },
  {
   "cell_type": "code",
   "source": [
    "trainer.train()"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "end_time": "2024-04-22T09:04:28.415053Z",
     "start_time": "2024-04-22T08:50:13.353681Z"
    }
   },
   "id": "5d9ba03835392e2a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Run data is saved locally in <code>/mnt/c/Users/cheir/GitHub/Waktaverse-LLM/wandb/run-20240422_175013-6vyys2o7</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/waktaverse/huggingface/runs/6vyys2o7' target=\"_blank\">trim-galaxy-11</a></strong> to <a href='https://wandb.ai/waktaverse/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View project at <a href='https://wandb.ai/waktaverse/huggingface' target=\"_blank\">https://wandb.ai/waktaverse/huggingface</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run at <a href='https://wandb.ai/waktaverse/huggingface/runs/6vyys2o7' target=\"_blank\">https://wandb.ai/waktaverse/huggingface/runs/6vyys2o7</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The input hidden states seems to be silently casted in float32, this might be related to the fact you have upcasted embedding or layer norm layers in float32. We will cast back the input in torch.bfloat16.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='100' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [100/100 14:11, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2.168700</td>\n",
       "      <td>2.149209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>2.166400</td>\n",
       "      <td>2.108505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.809700</td>\n",
       "      <td>2.058484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.960500</td>\n",
       "      <td>2.024441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.974800</td>\n",
       "      <td>2.000844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1.744800</td>\n",
       "      <td>1.988035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>2.145200</td>\n",
       "      <td>1.980157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>2.172800</td>\n",
       "      <td>1.975713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1.923200</td>\n",
       "      <td>1.974792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.974700</td>\n",
       "      <td>1.974206</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=100, training_loss=2.0040821647644043, metrics={'train_runtime': 854.8698, 'train_samples_per_second': 0.117, 'train_steps_per_second': 0.117, 'total_flos': 1367214509408256.0, 'train_loss': 2.0040821647644043, 'epoch': 1.0})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 33
  },
  {
   "cell_type": "code",
   "source": [
    "wandb.finish()\n",
    "trainer.save_model(model_name)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "end_time": "2024-04-22T09:04:38.625177Z",
     "start_time": "2024-04-22T09:04:28.416726Z"
    }
   },
   "id": "f4b2fdcf617359a4",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VBox(children=(Label(value='0.003 MB of 0.003 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3a2b61de570741e8aed0d24f382418e3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "W&B sync reduced upload amount by 7.5%             "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>█▆▄▃▂▂▁▁▁▁</td></tr><tr><td>eval/runtime</td><td>▁▁██▅▅▅▅▅▅</td></tr><tr><td>eval/samples_per_second</td><td>▅█▁▁▁▁▁▁▁▁</td></tr><tr><td>eval/steps_per_second</td><td>▅█▁▁▁▁▁▁▁▁</td></tr><tr><td>train/epoch</td><td>▁▁▂▂▃▃▃▃▄▄▅▅▆▆▆▆▇▇███</td></tr><tr><td>train/global_step</td><td>▁▁▂▂▃▃▃▃▄▄▅▅▆▆▆▆▇▇███</td></tr><tr><td>train/grad_norm</td><td>█▆▄▄▁▅▁▂▄▆</td></tr><tr><td>train/learning_rate</td><td>██▇▆▅▄▃▂▁▁</td></tr><tr><td>train/loss</td><td>██▂▅▅▁██▄▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>1.97421</td></tr><tr><td>eval/runtime</td><td>38.3531</td></tr><tr><td>eval/samples_per_second</td><td>0.261</td></tr><tr><td>eval/steps_per_second</td><td>0.261</td></tr><tr><td>total_flos</td><td>1367214509408256.0</td></tr><tr><td>train/epoch</td><td>1.0</td></tr><tr><td>train/global_step</td><td>100</td></tr><tr><td>train/grad_norm</td><td>3.92344</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>1.9747</td></tr><tr><td>train_loss</td><td>2.00408</td></tr><tr><td>train_runtime</td><td>854.8698</td></tr><tr><td>train_samples_per_second</td><td>0.117</td></tr><tr><td>train_steps_per_second</td><td>0.117</td></tr></table><br/></div></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">trim-galaxy-11</strong> at: <a href='https://wandb.ai/waktaverse/huggingface/runs/6vyys2o7' target=\"_blank\">https://wandb.ai/waktaverse/huggingface/runs/6vyys2o7</a><br/> View project at: <a href='https://wandb.ai/waktaverse/huggingface' target=\"_blank\">https://wandb.ai/waktaverse/huggingface</a><br/>Synced 6 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Find logs at: <code>./wandb/run-20240422_175013-6vyys2o7/logs</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 34
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Inference after Fine-Tuning"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4ec24bf55b44834d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T09:04:38.628876Z",
     "start_time": "2024-04-22T09:04:38.626256Z"
    }
   },
   "cell_type": "code",
   "source": "system_prompt = \"You are a helpful assistant. Respond to the following user prompt. Use Korean only. 한국어만 사용하세요.\"",
   "id": "d35aa851e8176d2d",
   "outputs": [],
   "execution_count": 35
  },
  {
   "cell_type": "code",
   "source": [
    "#user_prompt = \"Write me a poem about Machine Learning.\"\n",
    "user_prompt = \"머신러닝에 대한 시를 써주세요.\""
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "end_time": "2024-04-22T09:04:38.637584Z",
     "start_time": "2024-04-22T09:04:38.629818Z"
    }
   },
   "id": "bcba8c32d5f5469f",
   "outputs": [],
   "execution_count": 36
  },
  {
   "cell_type": "code",
   "source": [
    "response = generate_response(system_prompt, user_prompt)\n",
    "print(response)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "end_time": "2024-04-22T09:04:58.016756Z",
     "start_time": "2024-04-22T09:04:38.638548Z"
    }
   },
   "id": "1219dfd08fc2facd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "You are a helpful assistant. Respond to the following user prompt. Use Korean only. 한국어만 사용하세요.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "머신러닝에 대한 시를 써주세요.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "머신러닝의 꿈은 하늘 높은데\n",
      "데이터의 바다에서 배를 타고 가는 길이 멀다\n",
      "하나씩 모아보지만 결코 끝나지 않네\n",
      "시작하는 것은 언제라도 늦지 않네\n",
      "\n",
      "머신러닝의 노래는 데이터의 노래\n",
      "가라미의 보이스로 울리는 노래\n",
      "숫자와 문자로 이루어진 노래\n",
      "시각과 음성으로 표현되는 노래\n",
      "\n",
      "머신러닝의 꿈은 하늘 높인데\n",
      "하늘 높이 솟은 탑이 있어도\n",
      "뛰어오르는 것은 언제라도 늦지 않네\n",
      "시작하는 것은 언제라도 늦지 않네\n",
      "\n",
      "시작하고 싶다면 이제 시작해\n",
      "한 단계씩 나아가고 가는 길이 멀다\n",
      "끝나기 전에 끝내고 가는 길이 멀다\n",
      "시작하고 싶다면 이제 시작해<|eot_id|>\n"
     ]
    }
   ],
   "execution_count": 37
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Upload Model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ae7bc882cc302767"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T09:04:59.699767Z",
     "start_time": "2024-04-22T09:04:58.017704Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Flush memory\n",
    "import gc\n",
    "\n",
    "del trainer, model\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ],
   "id": "7bdce331b3e87139",
   "outputs": [],
   "execution_count": 38
  },
  {
   "cell_type": "code",
   "source": [
    "# Reload model in FP16 and merge it with LoRA weights\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    device_map=device,\n",
    "    torch_dtype=torch.float16\n",
    ")\n",
    "model = PeftModel.from_pretrained(base_model, model_name)\n",
    "model = model.merge_and_unload()"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "end_time": "2024-04-22T09:05:15.002811Z",
     "start_time": "2024-04-22T09:04:59.700988Z"
    }
   },
   "id": "57bcdb4c1c233116",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fe99d3076e8d493399223dd1807836b2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 39
  },
  {
   "cell_type": "code",
   "source": [
    "# Reload tokenizer to save it\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\""
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "end_time": "2024-04-22T09:05:15.397342Z",
     "start_time": "2024-04-22T09:05:15.003984Z"
    }
   },
   "id": "db819b259928e006",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "execution_count": 40
  },
  {
   "cell_type": "code",
   "source": [
    "# Push model and tokenizer to Hugging Face Hub\n",
    "model.push_to_hub(\n",
    "    repo_id=repo_id,\n",
    "    use_temp_dir=False\n",
    ")\n",
    "tokenizer.push_to_hub(\n",
    "    repo_id=repo_id,\n",
    "    use_temp_dir=False\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "end_time": "2024-04-22T09:31:29.599281Z",
     "start_time": "2024-04-22T09:05:15.399748Z"
    }
   },
   "id": "43aa8d6999c41016",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Upload 4 LFS files:   0%|          | 0/4 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e2bcb45837c44fb08f9c1f3a9e7f337b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "model-00004-of-00004.safetensors:   0%|          | 0.00/1.17G [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c4dbbfbe95c8464b890425027072d636"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "model-00001-of-00004.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8e9e33528ce74f11b3ae833801bd7749"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "model-00003-of-00004.safetensors:   0%|          | 0.00/4.92G [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4627d0f767b74520a808bff8878be642"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "model-00002-of-00004.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9f5c97e7d0b248b380befb2934307e32"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/PathFinderKR/Waktaverse-Llama-3-KO-8B-Instruct/commit/50bd171220b0634c3cdf44411e96ec2138cf40b8', commit_message='Upload tokenizer', commit_description='', oid='50bd171220b0634c3cdf44411e96ec2138cf40b8', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 41
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
