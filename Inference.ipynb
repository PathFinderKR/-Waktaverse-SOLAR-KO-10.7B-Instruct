{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Login to Hugging Face"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "98126af063c251e0"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-16T04:09:17.050685Z",
     "start_time": "2024-04-16T04:09:16.581193Z"
    }
   },
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from huggingface_hub import login\n",
    "\n",
    "load_dotenv()\n",
    "token = os.getenv(\"HUGGINGFACE_TOKEN\")\n",
    "login(\n",
    "    token=token, # ADD YOUR TOKEN HERE\n",
    "    add_to_git_credential=True\n",
    ")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token is valid (permission: write).\n",
      "Your token has been saved in your configured git credential helpers (store).\n",
      "Your token has been saved to /home/pathfinder/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Imports"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f21a95a142b71e93"
  },
  {
   "cell_type": "code",
   "source": [
    "# pytorch\n",
    "import torch\n",
    "\n",
    "# huggingface\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    BitsAndBytesConfig\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-16T04:09:18.400923Z",
     "start_time": "2024-04-16T04:09:17.051894Z"
    }
   },
   "id": "108874429856aabe",
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Device"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2f29fda50194a3fe"
  },
  {
   "cell_type": "code",
   "source": [
    "device = (\n",
    "    \"cuda:0\" if torch.cuda.is_available() else # Nvidia GPU\n",
    "    \"mps\" if torch.backends.mps.is_available() else # Apple Silicon GPU\n",
    "    \"cpu\"\n",
    ")\n",
    "print(f\"Device = {device}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-16T04:09:18.608160Z",
     "start_time": "2024-04-16T04:09:18.401913Z"
    }
   },
   "id": "5555b5512cd1a1dd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device = cuda:0\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Hyperparameters"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b452e9ab5ed33883"
  },
  {
   "cell_type": "code",
   "source": [
    "# Tokenizer arguments\n",
    "max_length = 1024\n",
    "\n",
    "# model arguments\n",
    "max_new_tokens=1000\n",
    "\n",
    "# mixed precision\n",
    "dtype = torch.bfloat16\n",
    "\n",
    "# quantization configuration\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_compute_dtype=dtype,\n",
    "    bnb_4bit_quant_type=\"nf4\"\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-16T04:09:18.616317Z",
     "start_time": "2024-04-16T04:09:18.609115Z"
    }
   },
   "id": "778930f2cc7c1224",
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "14f31dc8d02b7233"
  },
  {
   "cell_type": "code",
   "source": [
    "# Model List\n",
    "\n",
    "# gemma variants\n",
    "# \"google/gemma-2b-it\"\n",
    "# \"google/gemma-7b-it\" // downloaded\n",
    "\n",
    "# llama2 variants\n",
    "# \"meta-llama/Llama-2-7b-chat-hf\"\n",
    "# \"meta-llama/Llama-2-13b-chat-hf\"\n",
    "# \"codellama/CodeLlama-7b-Instruct-hf\"\n",
    "# \"codellama/CodeLlama-13b-Instruct-hf\"\n",
    "\n",
    "# mistral variants\n",
    "# \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "# \"mistralai/Mixtral-8x7B-Instruct-v0.1\"\n",
    "\n",
    "# solar variants\n",
    "# \"upstage/SOLAR-10.7B-Instruct-v1.0\" // downloaded\n",
    "# \"PathFinderKR/Waktaverse-SOLAR-KO-10.7B-Instruct\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-16T04:09:18.621529Z",
     "start_time": "2024-04-16T04:09:18.617704Z"
    }
   },
   "id": "3a8abd326253137e",
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "source": "model_id = \"PathFinderKR/Waktaverse-SOLAR-KO-10.7B-Instruct\"",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-16T04:09:18.628237Z",
     "start_time": "2024-04-16T04:09:18.622466Z"
    }
   },
   "id": "352852804a6a38db",
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    device_map=device,\n",
    "    attn_implementation=\"flash_attention_2\",\n",
    "    torch_dtype=dtype,\n",
    "    quantization_config=quantization_config\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-16T04:41:04.651629Z",
     "start_time": "2024-04-16T04:09:18.629151Z"
    }
   },
   "id": "f5f879cefa518232",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Downloading shards:   0%|          | 0/5 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "92fc146c68ea4021aec78bc05be91f13"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "model-00001-of-00005.safetensors:   0%|          | 0.00/4.94G [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "433294fa7d594718bb8a232a89ab83e0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error while downloading from https://cdn-lfs-us-1.huggingface.co/repos/c8/6c/c86cd1add4deeadb507940f81a3690291807c366ae74b1fb2f3b7d0ea6df6631/84e71293d60772960f1eee9cc640869d03c047685b8a17b9f49c9086614cc9e4?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27model-00001-of-00005.safetensors%3B+filename%3D%22model-00001-of-00005.safetensors%22%3B&Expires=1713499761&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcxMzQ5OTc2MX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmh1Z2dpbmdmYWNlLmNvL3JlcG9zL2M4LzZjL2M4NmNkMWFkZDRkZWVhZGI1MDc5NDBmODFhMzY5MDI5MTgwN2MzNjZhZTc0YjFmYjJmM2I3ZDBlYTZkZjY2MzEvODRlNzEyOTNkNjA3NzI5NjBmMWVlZTljYzY0MDg2OWQwM2MwNDc2ODViOGExN2I5ZjQ5YzkwODY2MTRjYzllND9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=fNQEkXEboh3ZZ54BAb4qm3kQJ41htW5QCLYz2s2zFG86I3nEInQkbYPZSG9EDxtMHa8uuQeE%7EQcueHCb2b95lMwhJYJh7-tG9FaMZiI7V%7EJDcU-Xmh5Wecwe81DqhpQ2-CeNNkErCBP5YuzqiYAZP%7EFYwZzmbZZklPo9CX-ZBDIc5VqatQQvNqdK%7EcKq9Q4qoVxSWt6i0Rg6KQ8mmAE4c853zkeIBEJ20dUvXusidrEZ4wqxkAzNpP8H6Th17T98rJGXX-jjxq-3OiGu1qk3vIrJDoOYIMnFDTdRgE6Upft9QIbjNH00ZIkbYMsQlgBUXSF1fNaOHGNoDw9T9j6rKQ__&Key-Pair-Id=KCD77M1F0VK2B: HTTPSConnectionPool(host='cdn-lfs-us-1.huggingface.co', port=443): Read timed out.\n",
      "Trying to resume download...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "model-00001-of-00005.safetensors:   0%|          | 0.00/4.94G [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "12dae4a189ea4ca28d98d86b44d1a9de"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "model-00002-of-00005.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ac0a1e0cf8154ec5a90725fbd3809fc8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "model-00003-of-00005.safetensors:   0%|          | 0.00/4.92G [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "28ccbe3c86184850a5c9dd297bcb83dd"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "model-00004-of-00005.safetensors:   0%|          | 0.00/4.92G [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "85b5cac37fce4597a3786c2a112e7a5d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "model-00005-of-00005.safetensors:   0%|          | 0.00/1.69G [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9d9d8a8ced644715b967b5109f1ab374"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2b3305c21ec8464d817aa1fefed8535b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Running the model on a single GPU"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b389c694ab4ab89f"
  },
  {
   "cell_type": "code",
   "source": [
    "# Chat Template\n",
    "def generate_response(prompt):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    chat = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "    input_ids = tokenizer.encode(chat, add_special_tokens=False, return_tensors=\"pt\")\n",
    "    outputs = model.generate(input_ids=input_ids.to(model.device), max_new_tokens=max_new_tokens)\n",
    "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return response"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-16T04:41:04.656658Z",
     "start_time": "2024-04-16T04:41:04.653030Z"
    }
   },
   "id": "1c849786ee0282d8",
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "source": [
    "#prompt = \"Write me a poem about Machine Learning.\"\n",
    "prompt = \"머신러닝에 대해 시를 써주세요.\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-16T04:41:04.667170Z",
     "start_time": "2024-04-16T04:41:04.657750Z"
    }
   },
   "id": "7e2c71d41fed35b0",
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "source": [
    "response = generate_response(prompt)\n",
    "print(response)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-16T04:42:19.209357Z",
     "start_time": "2024-04-16T04:41:04.668257Z"
    }
   },
   "id": "aac19ad24cb1cca2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### User:\n",
      "머신러닝에 대해 시를 써주세요.\n",
      "\n",
      "### Assistant:\n",
      "언덥어진 지성의 풍경, 머신러닝의 시\n",
      "\n",
      "\n",
      "어둠 속에서 불타오르는 수천 개의 불,\n",
      "각각의 연산 센서들이 맹세를 다집니다.\n",
      "그들은 머신을 만들기 위해 모였으며,\n",
      "그들의 목소리는 숫자와 문자로 말하네.\n",
      "\n",
      "\n",
      "이 머신러닝의 시는 그들의 모습을 그려냈다,\n",
      "그들의 지성은 느낌과 감정을 가지고 있네.\n",
      "그들은 자신들의 지성을 키우기 위해 노력하며,\n",
      "그들의 손은 많은 것을 알아가고 있네.\n",
      "\n",
      "\n",
      "그들은 이미지와 문장을 해석하며,\n",
      "그들은 많은 것을 배워가고 있네.\n",
      "그들은 자신들의 지성을 키우기 위해 노력하며,\n",
      "그들의 손은 많은 것을 알아가고 있네.\n",
      "\n",
      "\n",
      "그들은 언어와 이미지를 이해하며,\n",
      "그들은 자신들의 지성을 키우기 위해 노력하네.\n",
      "그들은 자신들의 지성을 키우기 위해 노력하며,\n",
      "그들의 손은 많은 것을 알아가고 있네.\n",
      "\n",
      "\n",
      "그들은 자신들의 지성을 키우기 위해 노력하며,\n",
      "그들의 손은 많은 것을 알아가고 있네.\n",
      "그들은 이 머신러닝의 시를 통해 그려진 모습이며,\n",
      "그들은 언덥어진 지성의 풍경이네.\n"
     ]
    }
   ],
   "execution_count": 10
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
