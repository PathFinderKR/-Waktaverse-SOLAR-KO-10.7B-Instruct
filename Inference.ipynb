{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Login to Hugging Face"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "98126af063c251e0"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-11T22:09:50.344577Z",
     "start_time": "2024-05-11T22:09:49.242143Z"
    }
   },
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from huggingface_hub import login\n",
    "\n",
    "load_dotenv()\n",
    "token = os.getenv(\"HUGGINGFACE_TOKEN\")\n",
    "login(\n",
    "    token=token, # ADD YOUR TOKEN HERE\n",
    "    add_to_git_credential=True\n",
    ")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token is valid (permission: write).\n",
      "Your token has been saved in your configured git credential helpers (store).\n",
      "Your token has been saved to /home/pathfinder/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Imports"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f21a95a142b71e93"
  },
  {
   "cell_type": "code",
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "# pytorch\n",
    "import torch\n",
    "\n",
    "# huggingface\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    BitsAndBytesConfig\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-11T22:09:52.686223Z",
     "start_time": "2024-05-11T22:09:50.345994Z"
    }
   },
   "id": "108874429856aabe",
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Device"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2f29fda50194a3fe"
  },
  {
   "cell_type": "code",
   "source": [
    "# Device setup\n",
    "device = (\n",
    "    \"cuda:0\" if torch.cuda.is_available() else # Nvidia GPU\n",
    "    \"mps\" if torch.backends.mps.is_available() else # Apple Silicon GPU\n",
    "    \"cpu\"\n",
    ")\n",
    "print(f\"Device = {device}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-11T22:09:52.947890Z",
     "start_time": "2024-05-11T22:09:52.687437Z"
    }
   },
   "id": "5555b5512cd1a1dd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device = cuda:0\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T22:09:53.026173Z",
     "start_time": "2024-05-11T22:09:52.949788Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Flash Attention Implementation\n",
    "if device == \"cuda:0\":\n",
    "    if torch.cuda.get_device_capability()[0] >= 8: # Ampere, Ada, or Hopper GPUs\n",
    "        attn_implementation = \"flash_attention_2\"\n",
    "        torch_dtype = torch.bfloat16\n",
    "    else:\n",
    "        attn_implementation = \"eager\"\n",
    "        torch_dtype = torch.float16\n",
    "else:\n",
    "    attn_implementation = \"eager\"\n",
    "    torch_dtype = torch.float32\n",
    "print(f\"Attention Implementation = {attn_implementation}\")"
   ],
   "id": "f0e72bfaf9471e1e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention Implementation = flash_attention_2\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Hyperparameters"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b452e9ab5ed33883"
  },
  {
   "cell_type": "code",
   "source": [
    "################################################################################\n",
    "# Tokenizer parameters\n",
    "################################################################################\n",
    "max_length=8192\n",
    "padding=\"do_not_pad\" # \"max_length\", \"longest\", \"do_not_pad\"\n",
    "truncation=True\n",
    "\n",
    "################################################################################\n",
    "# Generation parameters\n",
    "################################################################################\n",
    "num_return_sequences=1\n",
    "max_new_tokens=1024\n",
    "do_sample=True # True for sampling, False for greedy decoding\n",
    "temperature=0.6\n",
    "top_k=0 # not recommended\n",
    "top_p=0.9\n",
    "repetition_penalty=1.1\n",
    "\n",
    "################################################################################\n",
    "# bitsandbytes parameters\n",
    "################################################################################\n",
    "load_in_4bit=True\n",
    "bnb_4bit_compute_dtype=torch_dtype\n",
    "bnb_4bit_quant_type=\"nf4\" # \"nf4\", #fp4\"\n",
    "bnb_4bit_use_double_quant=True"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-11T22:09:53.030916Z",
     "start_time": "2024-05-11T22:09:53.027477Z"
    }
   },
   "id": "778930f2cc7c1224",
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "14f31dc8d02b7233"
  },
  {
   "cell_type": "code",
   "source": [
    "# Model List\n",
    "\n",
    "# gemma variants\n",
    "# \"google/gemma-1.1-7b-it\"\n",
    "# \"google/codegemma-7b-it\"\n",
    "\n",
    "# llama variants\n",
    "# \"meta-llama/Meta-Llama-3-8B\" // downloaded\n",
    "# \"meta-llama/Meta-Llama-3-8B-Instruct\" // downloaded\n",
    "# \"codellama/CodeLlama-7b-Instruct-hf\"\n",
    "# \"PathFinderKR/Waktaverse-Llama-3-KO-8B-Instruct\"\n",
    "\n",
    "# mistral variants\n",
    "# \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "\n",
    "# openELM variants\n",
    "# \"apple/OpenELM-3B-Instruct\" // downloaded\n",
    "\n",
    "# solar variants\n",
    "# \"upstage/SOLAR-10.7B-Instruct-v1.0\" // downloaded\n",
    "# \"PathFinderKR/Waktaverse-SOLAR-KO-10.7B-Instruct\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-11T22:09:53.040779Z",
     "start_time": "2024-05-11T22:09:53.032127Z"
    }
   },
   "id": "3a8abd326253137e",
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "source": "model_id = \"PathFinderKR/Waktaverse-Llama-3-KO-8B-Instruct-v2\"",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-11T22:09:53.048548Z",
     "start_time": "2024-05-11T22:09:53.042272Z"
    }
   },
   "id": "352852804a6a38db",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T22:09:56.824106Z",
     "start_time": "2024-05-11T22:09:53.049762Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "tokenizer.padding_side = \"right\""
   ],
   "id": "3a1ea98f6eba58f8",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/51.3k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "804565fb667c429a826c630a1c1c709a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/10.1M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "cdb8530625d148cc8f039efa64607ce7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/389 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "748df00402b5492093c0407052274d61"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T22:09:56.828770Z",
     "start_time": "2024-05-11T22:09:56.825230Z"
    }
   },
   "cell_type": "code",
   "source": [
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=load_in_4bit,\n",
    "    bnb_4bit_compute_dtype=bnb_4bit_compute_dtype,\n",
    "    bnb_4bit_quant_type=bnb_4bit_quant_type,\n",
    "    bnb_4bit_use_double_quant=bnb_4bit_use_double_quant\n",
    ")"
   ],
   "id": "be26d2efc49fcbf6",
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    device_map=device,\n",
    "    attn_implementation=attn_implementation,\n",
    "    torch_dtype=torch_dtype,\n",
    "    quantization_config=quantization_config\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-11T22:40:14.434340Z",
     "start_time": "2024-05-11T22:09:56.830212Z"
    }
   },
   "id": "f5f879cefa518232",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "config.json:   0%|          | 0.00/698 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c64b108791334a32928795d7c5c19152"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8b429e681dc343dbba61f10b0810ffca"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "51d5b78935c448d8901773cae8b14f33"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "model-00001-of-00004.safetensors:   0%|          | 0.00/4.89G [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "819cb333fd804733ac430864c08f643b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "model-00002-of-00004.safetensors:   0%|          | 0.00/4.92G [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "82fdbeb24d3d488fb620a06a59135734"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "model-00003-of-00004.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "deda79e1ae5f42a1a7817aa0eb7b96c2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "model-00004-of-00004.safetensors:   0%|          | 0.00/1.55G [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "82d9add6f0424d538bfd6d4bd0b3ec14"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8c98cdcc6e0946018114f43e48201c12"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/121 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "98882c8124eb4ff480fea8d4cf2f3c28"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T22:40:14.442122Z",
     "start_time": "2024-05-11T22:40:14.436304Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Display the model architecture\n",
    "display(Markdown(f'```{model}```'))"
   ],
   "id": "9fedd479c0a753a0",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "```LlamaForCausalLM(\n  (model): LlamaModel(\n    (embed_tokens): Embedding(145792, 4096)\n    (layers): ModuleList(\n      (0-31): 32 x LlamaDecoderLayer(\n        (self_attn): LlamaFlashAttention2(\n          (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n          (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n          (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n          (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n          (rotary_emb): LlamaRotaryEmbedding()\n        )\n        (mlp): LlamaMLP(\n          (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n          (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n          (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n          (act_fn): SiLU()\n        )\n        (input_layernorm): LlamaRMSNorm()\n        (post_attention_layernorm): LlamaRMSNorm()\n      )\n    )\n    (norm): LlamaRMSNorm()\n  )\n  (lm_head): Linear(in_features=4096, out_features=145792, bias=False)\n)```"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Inference",
   "id": "12b7e2fc01311961"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T22:40:14.452449Z",
     "start_time": "2024-05-11T22:40:14.443659Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def generate_response(system ,user):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system},\n",
    "        {\"role\": \"user\", \"content\": user}\n",
    "    ]\n",
    "    prompt = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=False\n",
    "    )\n",
    "    \n",
    "    input_ids = tokenizer.encode(\n",
    "        prompt,\n",
    "        max_length=max_length,\n",
    "        padding=padding,\n",
    "        truncation=truncation,\n",
    "        add_special_tokens=False,\n",
    "        return_tensors=\"pt\"\n",
    "    ).to(device)\n",
    "    \n",
    "    outputs = model.generate(\n",
    "        input_ids=input_ids,\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "        num_return_sequences=num_return_sequences,\n",
    "        max_new_tokens=max_new_tokens,\n",
    "        do_sample=do_sample,\n",
    "        temperature=temperature,\n",
    "        top_k=top_k,\n",
    "        top_p=top_p,\n",
    "        repetition_penalty=repetition_penalty\n",
    "    )\n",
    "    \n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=False)"
   ],
   "id": "1c849786ee0282d8",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T22:40:14.459916Z",
     "start_time": "2024-05-11T22:40:14.455169Z"
    }
   },
   "cell_type": "code",
   "source": "system_prompt = \"다음 지시사항에 대한 응답을 작성해주세요.\"",
   "id": "36dd54c1250609de",
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "source": "user_prompt = \"피보나치 수열에 대해 설명해주세요.\"",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-11T22:40:14.467539Z",
     "start_time": "2024-05-11T22:40:14.463415Z"
    }
   },
   "id": "7e2c71d41fed35b0",
   "outputs": [],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "source": [
    "response = generate_response(system_prompt, user_prompt)\n",
    "print(response)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-11T22:40:32.949989Z",
     "start_time": "2024-05-11T22:40:14.468730Z"
    }
   },
   "id": "aac19ad24cb1cca2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "다음 지시사항에 대한 응답을 작성해주세요.피보나치 수열에 대해 설명해주세요. 피보나치 수열은 0과 1로 시작하는 수열로, 각 항이 이전 두 항의 합인 수열입니다. 예를 들어 첫 번째 항은 0이고 두 번째 항은 1이며 세 번째 항은 1과 0의 합인 1이 됩니다.\n",
      "\n",
      "### 응답:\n",
      "[asy]\n",
      "draw((0,0)--(1,0),Arrow);\n",
      "draw((1,0)--(2,1),Arrow);\n",
      "draw((2,1)--(3,2),Arrow);\n",
      "draw((3,2)--(4,3),Arrow);\n",
      "draw((4,3)--(5,5),Arrow);\n",
      "draw((5,5)--(6,8),Arrow);\n",
      "draw((6,8)--(7,13),Arrow);\n",
      "label(\"$1$\", (0,0), W); label(\"$1$\", (1,0), W); label(\"$2$\", (2,1), W); label(\"$3$\", (3,2), W); label(\"$5$\", (4,3), W); label(\"$8$\", (5,5), W); label(\"$13$\", (6,8), W);\n",
      "[/asy]\n",
      "\n",
      "수열의 다음 항을 찾으려면 현재 항에 이전 두 항을 더하면 되며, 이는 $a_n = a_{n-1} + a_{n-2}$가 됩니다. 따라서 피보나치 수열은 다음과 같습니다: \\[0, 1, 1, 2, 3, 5, 8, 13, 21, \\ldots\\]<|end_of_text|>\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Multi-turn Conversation",
   "id": "9377ca2ee01e9f56"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T22:40:32.955351Z",
     "start_time": "2024-05-11T22:40:32.952668Z"
    }
   },
   "cell_type": "code",
   "source": [
    "system_prompt = \"다음 지시사항에 대한 응답을 작성해주세요.\"\n",
    "conversation_history = [{\"role\": \"system\", \"content\": system_prompt}]"
   ],
   "id": "755414328bf0bb36",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T22:40:32.968324Z",
     "start_time": "2024-05-11T22:40:32.956800Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def generate_conversation(user):\n",
    "    global conversation_history\n",
    "    conversation_history.append({\"role\": \"user\", \"content\": user})\n",
    "    prompt = tokenizer.apply_chat_template(\n",
    "        conversation_history,\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=False\n",
    "    )\n",
    "    \n",
    "    input_ids = tokenizer.encode(\n",
    "        prompt,\n",
    "        max_length=max_length,\n",
    "        padding=padding,\n",
    "        truncation=truncation,\n",
    "        add_special_tokens=False,\n",
    "        return_tensors=\"pt\"\n",
    "    ).to(device)\n",
    "    \n",
    "    outputs = model.generate(\n",
    "        input_ids=input_ids,\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "        num_return_sequences=num_return_sequences,\n",
    "        max_new_tokens=max_new_tokens,\n",
    "        do_sample=do_sample,\n",
    "        temperature=temperature,\n",
    "        top_k=top_k,\n",
    "        top_p=top_p,\n",
    "        repetition_penalty=repetition_penalty\n",
    "    )\n",
    "    \n",
    "    assistant_response = tokenizer.decode(outputs[0], skip_special_tokens=False).split(\"<|start_header_id|>assistant<|end_header_id|>\")[-1]\n",
    "    conversation_history.append({\"role\": \"assistant\", \"content\": assistant_response})\n",
    "    return assistant_response"
   ],
   "id": "fcb7ac53017a73f",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T22:40:48.226192Z",
     "start_time": "2024-05-11T22:40:32.969911Z"
    }
   },
   "cell_type": "code",
   "source": [
    "user_input = \"이번 주말에 할 수 있는 취미 활동을 추천해주세요.\"\n",
    "response = generate_conversation(user_input)\n",
    "print(response)"
   ],
   "id": "b21aac61d3dea342",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "다음 지시사항에 대한 응답을 작성해주세요.이번 주말에 할 수 있는 취미 활동을 추천해주세요. \n",
      "\n",
      "### 응답:\n",
      "1. 독서: 최근에 읽은 책 중에서 좋은 내용이 많았던 책이나, 재미있는 책들을 추천합니다.\n",
      "2. 음악 감상: 좋아하는 음악을 듣거나, 새로운 노래를 찾아 들어보는 것도 좋습니다.\n",
      "3. 영화 관람: 시간과 돈이 허락된다면, 영화관에서 최신 영화를 보는 것이 좋습니다.\n",
      "4. 요리하기: 간단한 요리를 만들어서 먹어보는 것도 좋은 취미가 될 수 있습니다.\n",
      "5. 사진 찍기: 주변의 풍경이나 사람들의 모습을 사진으로 담아서 추억을 남기는 것도 좋은 취미입니다.\n",
      "6. 미술 활동: 그림 그리기나 공예품 만들기를 통해 창의력을 발휘하고, 자신만의 작품을 만드는 것도 좋습니다.\n",
      "7. 여행: 가까운 곳이라도 여행을 가서 새로운 경험을 해보는 것도 좋습니다.\n",
      "8. 봉사활동: 지역 사회에 도움이 되는 봉사를 하는 것도 의미있는 취미가 될 수 있습니다.\n",
      "9. 게임하기: 컴퓨터 게임이나 보드게임 등을 통해 스트레스를 해소할 수도 있습니다.\n",
      "10. 글쓰기: 일기 쓰기나 글쓰기를 통해 자신의 생각을 정리하고 표현하는 것도 좋은 취미가 될 수 있습니다.\n",
      "11. 운동하기: 걷기, 달리기, 자전거 타기 등 다양한 운동을 통해 건강을 관리하는 것도 좋습니다.<|end_of_text|>\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T22:41:09.167667Z",
     "start_time": "2024-05-11T22:40:48.227689Z"
    }
   },
   "cell_type": "code",
   "source": [
    "user_input = \"추천한 취미 활동 중에서 건강에 도움이 되는 것은 무엇인가요?\"\n",
    "response = generate_conversation(user_input)\n",
    "print(response)"
   ],
   "id": "a9980840ff668db6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "다음 지시사항에 대한 응답을 작성해주세요.이번 주말에 할 수 있는 취미 활동을 추천해주세요.다음 지시사항에 대한 응답을 작성해주세요.이번 주말에 할 수 있는 취미 활동을 추천해주세요. \n",
      "\n",
      "### 응답:\n",
      "1. 독서: 최근에 읽은 책 중에서 좋은 내용이 많았던 책이나, 재미있는 책들을 추천합니다.\n",
      "2. 음악 감상: 좋아하는 음악을 듣거나, 새로운 노래를 찾아 들어보는 것도 좋습니다.\n",
      "3. 영화 관람: 시간과 돈이 허락된다면, 영화관에서 최신 영화를 보는 것이 좋습니다.\n",
      "4. 요리하기: 간단한 요리를 만들어서 먹어보는 것도 좋은 취미가 될 수 있습니다.\n",
      "5. 사진 찍기: 주변의 풍경이나 사람들의 모습을 사진으로 담아서 추억을 남기는 것도 좋은 취미입니다.\n",
      "6. 미술 활동: 그림 그리기나 공예품 만들기를 통해 창의력을 발휘하고, 자신만의 작품을 만드는 것도 좋습니다.\n",
      "7. 여행: 가까운 곳이라도 여행을 가서 새로운 경험을 해보는 것도 좋습니다.\n",
      "8. 봉사활동: 지역 사회에 도움이 되는 봉사를 하는 것도 의미있는 취미가 될 수 있습니다.\n",
      "9. 게임하기: 컴퓨터 게임이나 보드게임 등을 통해 스트레스를 해소할 수도 있습니다.\n",
      "10. 글쓰기: 일기 쓰기나 글쓰기를 통해 자신의 생각을 정리하고 표현하는 것도 좋은 취미가 될 수 있습니다.\n",
      "11. 운동하기: 걷기, 달리기, 자전거 타기 등 다양한 운동을 통해 건강을 관리하는 것도 좋습니다.<|end_of_text|>\n",
      "추천한 취미 활동 중에서 건강에 도움이 되는 것은 무엇인가요? \n",
      "건강을 유지하면서 취미 생활을 즐기고 싶어서 질문드립니다.\n",
      "\n",
      "### 응답:\n",
      "건강을 유지하면서 취미 생활을 즐길 수 있는 활동으로는 다음과 같은 것들이 있습니다. \n",
      "- 걷기: 걷기는 심장 및 전신의 근육 발달을 돕고 혈액순환을 촉진시켜줍니다. 또한 체중 조절에도 효과적이며, 기분 전환에도 도움을 줍니다. \n",
      "- 등산: 등산은 심폐기능 강화와 함께 근력, 지구력, 균형감각을 키워주며, 스트레스 해소에도 큰 도움을 줍니다. \n",
      "- 수영: 수영은 전신운동으로 전신의 근육을 사용하여 전신을 단련시키는데 도움이 됩니다. 또한 수영은 스트레스 해소에도 효과적입니다. \n",
      "- 테니스: 테니스는 전신의 근육을 사용하여 유산소 운동이 가능하며, 전신의 근력을 키워주고, 유연성 향상에도 큰 도움을 줍니다. \n",
      "- 골프: 골프는 전신의 근육을 사용하여 유산소 운동이 가능하며, 전신의 근력을 키워주고, 유연성 향상에도 큰 도움을 줍니다. 또한 골프는 스트레스 해소에도 효과적입니다. \n",
      "- 헬스/피트니스: 헬스/피트니스는 전신의 근육을 사용하여 유산소 운동이 가능하며, 전신의 근력을 키워주고, 유연성 향상에도 큰 도움을 줍니다. \n",
      "- 요가: 요가는 몸의 근육과 관절을 부드럽게 이완시키고, 자세 교정에 도움이 되며, 호흡법을 익히고 스트레스를 해소하는데도 효과적입니다. \n",
      "- 기타 체육 활동: 축구, 농구, 야구 등의 체육 활동은 전신의 근육을 사용하여 유산소 운동이 가능하며, 전신의 근력을 키워주고, 유연성 향상에도 큰 도움을 줍니다.<|end_of_text|>\n"
     ]
    }
   ],
   "execution_count": 19
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
