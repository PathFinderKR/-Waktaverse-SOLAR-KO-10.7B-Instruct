{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Login to Hugging Face"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "98126af063c251e0"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-03T10:55:40.129669Z",
     "start_time": "2024-04-03T10:55:39.066473Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token is valid (permission: write).\n",
      "Your token has been saved in your configured git credential helpers (store).\n",
      "Your token has been saved to /home/pathfinder/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from huggingface_hub import login\n",
    "\n",
    "load_dotenv()\n",
    "token = os.getenv(\"HUGGINGFACE_TOKEN\")\n",
    "login(\n",
    "    token=token, # ADD YOUR TOKEN HERE\n",
    "    add_to_git_credential=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Imports"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f21a95a142b71e93"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# pytorch\n",
    "import torch\n",
    "\n",
    "# huggingface\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    BitsAndBytesConfig\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T10:55:42.409611Z",
     "start_time": "2024-04-03T10:55:40.131262Z"
    }
   },
   "id": "108874429856aabe",
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Device"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2f29fda50194a3fe"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device = cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = (\n",
    "    \"cuda:0\" if torch.cuda.is_available() else # Nvidia GPU\n",
    "    \"mps\" if torch.backends.mps.is_available() else # Apple Silicon GPU\n",
    "    \"cpu\"\n",
    ")\n",
    "print(f\"Device = {device}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T10:55:42.565196Z",
     "start_time": "2024-04-03T10:55:42.410564Z"
    }
   },
   "id": "5555b5512cd1a1dd",
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Hyperparameters"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b452e9ab5ed33883"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Tokenizer arguments\n",
    "max_length = 1024\n",
    "\n",
    "# model arguments\n",
    "max_new_tokens=1000\n",
    "\n",
    "# mixed precision\n",
    "dtype = torch.bfloat16\n",
    "\n",
    "# quantization configuration\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_compute_dtype=dtype,\n",
    "    bnb_4bit_quant_type=\"nf4\"\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T10:55:42.622501Z",
     "start_time": "2024-04-03T10:55:42.566525Z"
    }
   },
   "id": "778930f2cc7c1224",
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "14f31dc8d02b7233"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Model List\n",
    "\n",
    "# gemma variants\n",
    "# \"google/gemma-7b-it\" // downloaded\n",
    "# \"PathFinderKR/waktaverse-gemma-ko-7b-it\"\n",
    "# \"beomi/gemma-ko-7b\"\n",
    "\n",
    "# llama2 variants\n",
    "# \"meta-llama/Llama-2-7b-chat-hf\" // downloaded\n",
    "# \"PathFinderKR/waktaverse-Llama-2-ko-7b-it\"\n",
    "# \"beomi/KoAlpaca-Polyglot-5.8B\" // downloaded\n",
    "# \"beomi/open-llama-2-ko-7b\"\n",
    "\n",
    "# solar variants\n",
    "# \"chihoonlee10/T3Q-ko-solar-dpo-v4.0\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T10:55:42.630170Z",
     "start_time": "2024-04-03T10:55:42.624176Z"
    }
   },
   "id": "3a8abd326253137e",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model_id = \"PathFinderKR/waktaverse-gemma-ko-7b-it\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T10:55:42.637627Z",
     "start_time": "2024-04-03T10:55:42.631194Z"
    }
   },
   "id": "352852804a6a38db",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "364cc57590d04846b4b20098de758400"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "model-00001-of-00004.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a8d698ee26fe4f42b878efdeb00cef82"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "model-00002-of-00004.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0af1bf6844f342e1a60a7958f1a700f4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "model-00003-of-00004.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "100861b5915b4f7193be5adf0953ef2f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "model-00004-of-00004.safetensors:   0%|          | 0.00/2.11G [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d4dee01ae5e3416eb69387c0ab9d0dbc"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gemma's activation function should be approximate GeLU and not exact GeLU.\n",
      "Changing the activation function to `gelu_pytorch_tanh`.if you want to use the legacy `gelu`, edit the `model.config` to set `hidden_activation=gelu`   instead of `hidden_act`. See https://github.com/huggingface/transformers/pull/29402 for more details.\n"
     ]
    },
    {
     "data": {
      "text/plain": "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c70465f780fd4e24a0945f44962bb688"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    device_map=device,\n",
    "    attn_implementation=\"flash_attention_2\",\n",
    "    torch_dtype=dtype,\n",
    "    quantization_config=quantization_config\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T11:23:39.540832Z",
     "start_time": "2024-04-03T10:55:42.638658Z"
    }
   },
   "id": "f5f879cefa518232",
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Running the model on a single GPU"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b389c694ab4ab89f"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Chat Template\n",
    "def generate_response(prompt):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    chat = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "    input_ids = tokenizer.encode(chat, add_special_tokens=False, return_tensors=\"pt\")\n",
    "    outputs = model.generate(input_ids=input_ids.to(model.device), max_new_tokens=max_new_tokens)\n",
    "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return response"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T11:23:39.560214Z",
     "start_time": "2024-04-03T11:23:39.548205Z"
    }
   },
   "id": "1c849786ee0282d8",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#prompt = \"Write me a poem about Machine Learning.\"\n",
    "#prompt = \"머신러닝에 대한 시를 써주세요.\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T11:23:39.580483Z",
     "start_time": "2024-04-03T11:23:39.561927Z"
    }
   },
   "id": "7e2c71d41fed35b0",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "prompt = \"ppo 알고리즘에 대해 설명해줘\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T11:23:39.593641Z",
     "start_time": "2024-04-03T11:23:39.583835Z"
    }
   },
   "id": "e9e50b0e4eece0c2",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user\n",
      "ppo 알고리즘에 대해 설명해줘\n",
      "model\n",
      "**Policy-Based Optimization (PPO)**는 강화 학습 알고리즘으로, 에이전트가 정책을 추정하는 과정에서 사용됩니다. 이 알고리즘은 기존 정책을 기반으로 새로운 정책을 생성하고, 이를 사용하여 에이전트가 더 많은 보상을 받도록 최적화합니다.\n",
      "\n",
      "**주요 특징:**\n",
      "\n",
      "* **정책 추정:** PPO는 기존 정책을 기반으로 새로운 정책을 생성합니다.\n",
      "* **정책 평가:** 새로운 정책의 성능을 평가하고, 이를 기존 정책과 비교합니다.\n",
      "* **정책 개선:** 새로운 정책의 성능을 기반으로 기존 정책을 개선합니다.\n",
      "* **반복:** 위 과정을 반복하여 최적의 정책을 찾습니다.\n",
      "\n",
      "**주요 단계:**\n",
      "\n",
      "1. **정책 생성:** 기존 정책을 기반으로 새로운 정책을 생성합니다.\n",
      "2. **정책 평가:** 새로운 정책의 성능을 평가하고, 이를 기존 정책과 비교합니다.\n",
      "3. **정책 개선:** 새로운 정책의 성능을 기반으로 기존 정책을 개선합니다.\n",
      "4. **정책 수동:** 최적의 정책을 찾으면, 이를 사용하여 에이전트가 더 많은 보상을 받도록 최적화합니다.\n",
      "\n",
      "**장점:**\n",
      "\n",
      "* **정책 추정:** PPO는 기존 정책을 기반으로 새로운 정책을 생성하므로, 기존 정책의 장점을 유지하면서도 개선할 수 있습니다.\n",
      "* **정책 평가:** PPO는 정책의 성능을 평가하는 과정에서, 기존 정책의 확률 분포를 사용하여 정책의 성능을 평가할 수 있습니다.\n",
      "* **정책 개선:** PPO는 새로운 정책의 성능을 기반으로 기존 정책을 개선할 수 있습니다.\n",
      "\n",
      "**단점:**\n",
      "\n",
      "* **정책 수동:** PPO는 최적의 정책을 찾는 과정에서, 이를 수동으로 수동으로 선택하는 것이 필요합니다.\n",
      "* **정책 과대:** PPO는 기존 정책의 확률 분포를 사용하여 정책의 성능을 평가하므로, 기존 정책의 과대 분포에 의해 정책의 성능에 영향을 미칠 수 있습니다.\n"
     ]
    }
   ],
   "source": [
    "response = generate_response(prompt)\n",
    "print(response)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T11:24:03.404505Z",
     "start_time": "2024-04-03T11:23:39.597371Z"
    }
   },
   "id": "aac19ad24cb1cca2",
   "execution_count": 11
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
