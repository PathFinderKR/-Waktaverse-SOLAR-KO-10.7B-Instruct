{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Login to Hugging Face"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "98126af063c251e0"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-02T04:51:31.700021Z",
     "start_time": "2024-05-02T04:51:31.154816Z"
    }
   },
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from huggingface_hub import login\n",
    "\n",
    "load_dotenv()\n",
    "token = os.getenv(\"HUGGINGFACE_TOKEN\")\n",
    "login(\n",
    "    token=token, # ADD YOUR TOKEN HERE\n",
    "    add_to_git_credential=True\n",
    ")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token is valid (permission: write).\n",
      "Your token has been saved in your configured git credential helpers (osxkeychain).\n",
      "Your token has been saved to /Users/pathfinder/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Imports"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f21a95a142b71e93"
  },
  {
   "cell_type": "code",
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "# pytorch\n",
    "import torch\n",
    "\n",
    "# huggingface\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    BitsAndBytesConfig\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-02T04:51:34.678644Z",
     "start_time": "2024-05-02T04:51:31.702752Z"
    }
   },
   "id": "108874429856aabe",
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Device"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2f29fda50194a3fe"
  },
  {
   "cell_type": "code",
   "source": [
    "# Device setup\n",
    "device = (\n",
    "    \"cuda:0\" if torch.cuda.is_available() else # Nvidia GPU\n",
    "    \"mps\" if torch.backends.mps.is_available() else # Apple Silicon GPU\n",
    "    \"cpu\"\n",
    ")\n",
    "print(f\"Device = {device}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-02T04:51:34.701409Z",
     "start_time": "2024-05-02T04:51:34.680374Z"
    }
   },
   "id": "5555b5512cd1a1dd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device = mps\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T04:51:34.707063Z",
     "start_time": "2024-05-02T04:51:34.703215Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Flash Attention Implementation\n",
    "if device == \"cuda:0\":\n",
    "    if torch.cuda.get_device_capability()[0] >= 8: # Ampere, Ada, or Hopper GPUs\n",
    "        attn_implementation = \"flash_attention_2\"\n",
    "        torch_dtype = torch.bfloat16\n",
    "    else:\n",
    "        attn_implementation = \"eager\"\n",
    "        torch_dtype = torch.float16\n",
    "else:\n",
    "    attn_implementation = \"eager\"\n",
    "    torch_dtype = torch.float32\n",
    "print(f\"Attention Implementation = {attn_implementation}\")"
   ],
   "id": "f0e72bfaf9471e1e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention Implementation = eager\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Hyperparameters"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b452e9ab5ed33883"
  },
  {
   "cell_type": "code",
   "source": [
    "################################################################################\n",
    "# Tokenizer parameters\n",
    "################################################################################\n",
    "max_length=1024\n",
    "padding=\"do_not_pad\" # \"max_length\", \"longest\", \"do_not_pad\"\n",
    "truncation=True\n",
    "\n",
    "################################################################################\n",
    "# Generation parameters\n",
    "################################################################################\n",
    "num_return_sequences=1\n",
    "max_new_tokens=1024\n",
    "do_sample=True # True for sampling, False for greedy decoding\n",
    "temperature=0.9\n",
    "top_k=40\n",
    "top_p=0.9\n",
    "repetition_penalty=1.1\n",
    "\n",
    "################################################################################\n",
    "# bitsandbytes parameters\n",
    "################################################################################\n",
    "load_in_4bit=True\n",
    "bnb_4bit_compute_dtype=torch_dtype\n",
    "bnb_4bit_quant_type=\"nf4\" # \"nf4\", #fp4\"\n",
    "bnb_4bit_use_double_quant=True"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-02T04:51:34.715956Z",
     "start_time": "2024-05-02T04:51:34.710496Z"
    }
   },
   "id": "778930f2cc7c1224",
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "14f31dc8d02b7233"
  },
  {
   "cell_type": "code",
   "source": [
    "# Model List\n",
    "\n",
    "# gemma variants\n",
    "# \"google/gemma-1.1-7b-it\"\n",
    "# \"google/codegemma-7b-it\"\n",
    "\n",
    "# llama variants\n",
    "# \"meta-llama/Meta-Llama-3-8B\" // downloaded\n",
    "# \"meta-llama/Meta-Llama-3-8B-Instruct\" // downloaded\n",
    "# \"codellama/CodeLlama-7b-Instruct-hf\"\n",
    "# \"PathFinderKR/Waktaverse-Llama-3-KO-8B-Instruct\"\n",
    "\n",
    "# mistral variants\n",
    "# \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "\n",
    "# openELM variants\n",
    "# \"apple/OpenELM-3B-Instruct\" // downloaded\n",
    "\n",
    "# solar variants\n",
    "# \"upstage/SOLAR-10.7B-Instruct-v1.0\" // downloaded\n",
    "# \"PathFinderKR/Waktaverse-SOLAR-KO-10.7B-Instruct\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-02T04:51:34.719243Z",
     "start_time": "2024-05-02T04:51:34.716845Z"
    }
   },
   "id": "3a8abd326253137e",
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "source": "model_id = \"apple/OpenELM-3B-Instruct\"",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-02T04:51:34.723254Z",
     "start_time": "2024-05-02T04:51:34.720392Z"
    }
   },
   "id": "352852804a6a38db",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T04:51:34.993200Z",
     "start_time": "2024-05-02T04:51:34.724258Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('meta-llama/Llama-2-7b-hf', trust_remote_code=True)\n",
    "tokenizer.padding_side = \"right\""
   ],
   "id": "3a1ea98f6eba58f8",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T04:51:35.005899Z",
     "start_time": "2024-05-02T04:51:34.996309Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Display tokenizer information\n",
    "display(Markdown(f'```{tokenizer}```'))"
   ],
   "id": "3752ef0c02bd71f6",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "```LlamaTokenizerFast(name_or_path='meta-llama/Llama-2-7b-hf', vocab_size=32000, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>'}, clean_up_tokenization_spaces=False),  added_tokens_decoder={\n\t0: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t1: AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t2: AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n}```"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T04:51:35.012850Z",
     "start_time": "2024-05-02T04:51:35.007005Z"
    }
   },
   "cell_type": "code",
   "source": [
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=load_in_4bit,\n",
    "    bnb_4bit_compute_dtype=bnb_4bit_compute_dtype,\n",
    "    bnb_4bit_quant_type=bnb_4bit_quant_type,\n",
    "    bnb_4bit_use_double_quant=bnb_4bit_use_double_quant\n",
    ")"
   ],
   "id": "be26d2efc49fcbf6",
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    device_map=device,\n",
    "    attn_implementation=attn_implementation,\n",
    "    torch_dtype=torch_dtype,\n",
    "    #quantization_config=quantization_config,\n",
    "    trust_remote_code=True\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-02T04:52:06.105281Z",
     "start_time": "2024-05-02T04:51:35.015395Z"
    }
   },
   "id": "f5f879cefa518232",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f93df954c8b244c0a62c7ee688581ceb"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T04:52:06.136254Z",
     "start_time": "2024-05-02T04:52:06.112566Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Display the model architecture\n",
    "display(Markdown(f'```{model}```'))"
   ],
   "id": "9fedd479c0a753a0",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "```OpenELMForCausalLM(\n  (transformer): OpenELMModel(\n    (token_embeddings): Embedding(32000, 3072)\n    (layers): ModuleList(\n      (0): OpenELMDecoderLayer(\n        (attn): OpenELMMultiHeadCausalAttention(\n          query_heads=12, key_heads=3, value_heads=3\n          (qkv_proj): Linear(in_features=3072, out_features=2304, bias=False)\n          (pos_embedding): OpenELMRotaryEmbedding(\tmodel_dim=128, max_seq_length=4096, freq_constant=10000)\n          (q_norm): OpenELMRMSNorm(num_features=128, eps=1e-06)\n          (k_norm): OpenELMRMSNorm(num_features=128, eps=1e-06)\n          (out_proj): Linear(in_features=1536, out_features=3072, bias=False)\n        )\n        (ffn): OpenELMFeedForwardNetwork(\n          (ffn_with_glu) : True\n          (proj_1): Linear(in_features=3072, out_features=3072, bias=False)\n          (proj_2): Linear(in_features=1536, out_features=3072, bias=False)\n          (act): SiLU()\n        )\n        (ffn_norm): OpenELMRMSNorm(num_features=3072, eps=1e-06)\n        (attn_norm): OpenELMRMSNorm(num_features=3072, eps=1e-06)\n      )\n      (1): OpenELMDecoderLayer(\n        (attn): OpenELMMultiHeadCausalAttention(\n          query_heads=12, key_heads=3, value_heads=3\n          (qkv_proj): Linear(in_features=3072, out_features=2304, bias=False)\n          (pos_embedding): OpenELMRotaryEmbedding(\tmodel_dim=128, max_seq_length=4096, freq_constant=10000)\n          (q_norm): OpenELMRMSNorm(num_features=128, eps=1e-06)\n          (k_norm): OpenELMRMSNorm(num_features=128, eps=1e-06)\n          (out_proj): Linear(in_features=1536, out_features=3072, bias=False)\n        )\n        (ffn): OpenELMFeedForwardNetwork(\n          (ffn_with_glu) : True\n          (proj_1): Linear(in_features=3072, out_features=3584, bias=False)\n          (proj_2): Linear(in_features=1792, out_features=3072, bias=False)\n          (act): SiLU()\n        )\n        (ffn_norm): OpenELMRMSNorm(num_features=3072, eps=1e-06)\n        (attn_norm): OpenELMRMSNorm(num_features=3072, eps=1e-06)\n      )\n      (2): OpenELMDecoderLayer(\n        (attn): OpenELMMultiHeadCausalAttention(\n          query_heads=12, key_heads=3, value_heads=3\n          (qkv_proj): Linear(in_features=3072, out_features=2304, bias=False)\n          (pos_embedding): OpenELMRotaryEmbedding(\tmodel_dim=128, max_seq_length=4096, freq_constant=10000)\n          (q_norm): OpenELMRMSNorm(num_features=128, eps=1e-06)\n          (k_norm): OpenELMRMSNorm(num_features=128, eps=1e-06)\n          (out_proj): Linear(in_features=1536, out_features=3072, bias=False)\n        )\n        (ffn): OpenELMFeedForwardNetwork(\n          (ffn_with_glu) : True\n          (proj_1): Linear(in_features=3072, out_features=4096, bias=False)\n          (proj_2): Linear(in_features=2048, out_features=3072, bias=False)\n          (act): SiLU()\n        )\n        (ffn_norm): OpenELMRMSNorm(num_features=3072, eps=1e-06)\n        (attn_norm): OpenELMRMSNorm(num_features=3072, eps=1e-06)\n      )\n      (3): OpenELMDecoderLayer(\n        (attn): OpenELMMultiHeadCausalAttention(\n          query_heads=12, key_heads=3, value_heads=3\n          (qkv_proj): Linear(in_features=3072, out_features=2304, bias=False)\n          (pos_embedding): OpenELMRotaryEmbedding(\tmodel_dim=128, max_seq_length=4096, freq_constant=10000)\n          (q_norm): OpenELMRMSNorm(num_features=128, eps=1e-06)\n          (k_norm): OpenELMRMSNorm(num_features=128, eps=1e-06)\n          (out_proj): Linear(in_features=1536, out_features=3072, bias=False)\n        )\n        (ffn): OpenELMFeedForwardNetwork(\n          (ffn_with_glu) : True\n          (proj_1): Linear(in_features=3072, out_features=5120, bias=False)\n          (proj_2): Linear(in_features=2560, out_features=3072, bias=False)\n          (act): SiLU()\n        )\n        (ffn_norm): OpenELMRMSNorm(num_features=3072, eps=1e-06)\n        (attn_norm): OpenELMRMSNorm(num_features=3072, eps=1e-06)\n      )\n      (4): OpenELMDecoderLayer(\n        (attn): OpenELMMultiHeadCausalAttention(\n          query_heads=16, key_heads=4, value_heads=4\n          (qkv_proj): Linear(in_features=3072, out_features=3072, bias=False)\n          (pos_embedding): OpenELMRotaryEmbedding(\tmodel_dim=128, max_seq_length=4096, freq_constant=10000)\n          (q_norm): OpenELMRMSNorm(num_features=128, eps=1e-06)\n          (k_norm): OpenELMRMSNorm(num_features=128, eps=1e-06)\n          (out_proj): Linear(in_features=2048, out_features=3072, bias=False)\n        )\n        (ffn): OpenELMFeedForwardNetwork(\n          (ffn_with_glu) : True\n          (proj_1): Linear(in_features=3072, out_features=5632, bias=False)\n          (proj_2): Linear(in_features=2816, out_features=3072, bias=False)\n          (act): SiLU()\n        )\n        (ffn_norm): OpenELMRMSNorm(num_features=3072, eps=1e-06)\n        (attn_norm): OpenELMRMSNorm(num_features=3072, eps=1e-06)\n      )\n      (5): OpenELMDecoderLayer(\n        (attn): OpenELMMultiHeadCausalAttention(\n          query_heads=16, key_heads=4, value_heads=4\n          (qkv_proj): Linear(in_features=3072, out_features=3072, bias=False)\n          (pos_embedding): OpenELMRotaryEmbedding(\tmodel_dim=128, max_seq_length=4096, freq_constant=10000)\n          (q_norm): OpenELMRMSNorm(num_features=128, eps=1e-06)\n          (k_norm): OpenELMRMSNorm(num_features=128, eps=1e-06)\n          (out_proj): Linear(in_features=2048, out_features=3072, bias=False)\n        )\n        (ffn): OpenELMFeedForwardNetwork(\n          (ffn_with_glu) : True\n          (proj_1): Linear(in_features=3072, out_features=6144, bias=False)\n          (proj_2): Linear(in_features=3072, out_features=3072, bias=False)\n          (act): SiLU()\n        )\n        (ffn_norm): OpenELMRMSNorm(num_features=3072, eps=1e-06)\n        (attn_norm): OpenELMRMSNorm(num_features=3072, eps=1e-06)\n      )\n      (6): OpenELMDecoderLayer(\n        (attn): OpenELMMultiHeadCausalAttention(\n          query_heads=16, key_heads=4, value_heads=4\n          (qkv_proj): Linear(in_features=3072, out_features=3072, bias=False)\n          (pos_embedding): OpenELMRotaryEmbedding(\tmodel_dim=128, max_seq_length=4096, freq_constant=10000)\n          (q_norm): OpenELMRMSNorm(num_features=128, eps=1e-06)\n          (k_norm): OpenELMRMSNorm(num_features=128, eps=1e-06)\n          (out_proj): Linear(in_features=2048, out_features=3072, bias=False)\n        )\n        (ffn): OpenELMFeedForwardNetwork(\n          (ffn_with_glu) : True\n          (proj_1): Linear(in_features=3072, out_features=6656, bias=False)\n          (proj_2): Linear(in_features=3328, out_features=3072, bias=False)\n          (act): SiLU()\n        )\n        (ffn_norm): OpenELMRMSNorm(num_features=3072, eps=1e-06)\n        (attn_norm): OpenELMRMSNorm(num_features=3072, eps=1e-06)\n      )\n      (7): OpenELMDecoderLayer(\n        (attn): OpenELMMultiHeadCausalAttention(\n          query_heads=16, key_heads=4, value_heads=4\n          (qkv_proj): Linear(in_features=3072, out_features=3072, bias=False)\n          (pos_embedding): OpenELMRotaryEmbedding(\tmodel_dim=128, max_seq_length=4096, freq_constant=10000)\n          (q_norm): OpenELMRMSNorm(num_features=128, eps=1e-06)\n          (k_norm): OpenELMRMSNorm(num_features=128, eps=1e-06)\n          (out_proj): Linear(in_features=2048, out_features=3072, bias=False)\n        )\n        (ffn): OpenELMFeedForwardNetwork(\n          (ffn_with_glu) : True\n          (proj_1): Linear(in_features=3072, out_features=7168, bias=False)\n          (proj_2): Linear(in_features=3584, out_features=3072, bias=False)\n          (act): SiLU()\n        )\n        (ffn_norm): OpenELMRMSNorm(num_features=3072, eps=1e-06)\n        (attn_norm): OpenELMRMSNorm(num_features=3072, eps=1e-06)\n      )\n      (8): OpenELMDecoderLayer(\n        (attn): OpenELMMultiHeadCausalAttention(\n          query_heads=16, key_heads=4, value_heads=4\n          (qkv_proj): Linear(in_features=3072, out_features=3072, bias=False)\n          (pos_embedding): OpenELMRotaryEmbedding(\tmodel_dim=128, max_seq_length=4096, freq_constant=10000)\n          (q_norm): OpenELMRMSNorm(num_features=128, eps=1e-06)\n          (k_norm): OpenELMRMSNorm(num_features=128, eps=1e-06)\n          (out_proj): Linear(in_features=2048, out_features=3072, bias=False)\n        )\n        (ffn): OpenELMFeedForwardNetwork(\n          (ffn_with_glu) : True\n          (proj_1): Linear(in_features=3072, out_features=8192, bias=False)\n          (proj_2): Linear(in_features=4096, out_features=3072, bias=False)\n          (act): SiLU()\n        )\n        (ffn_norm): OpenELMRMSNorm(num_features=3072, eps=1e-06)\n        (attn_norm): OpenELMRMSNorm(num_features=3072, eps=1e-06)\n      )\n      (9): OpenELMDecoderLayer(\n        (attn): OpenELMMultiHeadCausalAttention(\n          query_heads=16, key_heads=4, value_heads=4\n          (qkv_proj): Linear(in_features=3072, out_features=3072, bias=False)\n          (pos_embedding): OpenELMRotaryEmbedding(\tmodel_dim=128, max_seq_length=4096, freq_constant=10000)\n          (q_norm): OpenELMRMSNorm(num_features=128, eps=1e-06)\n          (k_norm): OpenELMRMSNorm(num_features=128, eps=1e-06)\n          (out_proj): Linear(in_features=2048, out_features=3072, bias=False)\n        )\n        (ffn): OpenELMFeedForwardNetwork(\n          (ffn_with_glu) : True\n          (proj_1): Linear(in_features=3072, out_features=8704, bias=False)\n          (proj_2): Linear(in_features=4352, out_features=3072, bias=False)\n          (act): SiLU()\n        )\n        (ffn_norm): OpenELMRMSNorm(num_features=3072, eps=1e-06)\n        (attn_norm): OpenELMRMSNorm(num_features=3072, eps=1e-06)\n      )\n      (10): OpenELMDecoderLayer(\n        (attn): OpenELMMultiHeadCausalAttention(\n          query_heads=16, key_heads=4, value_heads=4\n          (qkv_proj): Linear(in_features=3072, out_features=3072, bias=False)\n          (pos_embedding): OpenELMRotaryEmbedding(\tmodel_dim=128, max_seq_length=4096, freq_constant=10000)\n          (q_norm): OpenELMRMSNorm(num_features=128, eps=1e-06)\n          (k_norm): OpenELMRMSNorm(num_features=128, eps=1e-06)\n          (out_proj): Linear(in_features=2048, out_features=3072, bias=False)\n        )\n        (ffn): OpenELMFeedForwardNetwork(\n          (ffn_with_glu) : True\n          (proj_1): Linear(in_features=3072, out_features=9216, bias=False)\n          (proj_2): Linear(in_features=4608, out_features=3072, bias=False)\n          (act): SiLU()\n        )\n        (ffn_norm): OpenELMRMSNorm(num_features=3072, eps=1e-06)\n        (attn_norm): OpenELMRMSNorm(num_features=3072, eps=1e-06)\n      )\n      (11): OpenELMDecoderLayer(\n        (attn): OpenELMMultiHeadCausalAttention(\n          query_heads=16, key_heads=4, value_heads=4\n          (qkv_proj): Linear(in_features=3072, out_features=3072, bias=False)\n          (pos_embedding): OpenELMRotaryEmbedding(\tmodel_dim=128, max_seq_length=4096, freq_constant=10000)\n          (q_norm): OpenELMRMSNorm(num_features=128, eps=1e-06)\n          (k_norm): OpenELMRMSNorm(num_features=128, eps=1e-06)\n          (out_proj): Linear(in_features=2048, out_features=3072, bias=False)\n        )\n        (ffn): OpenELMFeedForwardNetwork(\n          (ffn_with_glu) : True\n          (proj_1): Linear(in_features=3072, out_features=9728, bias=False)\n          (proj_2): Linear(in_features=4864, out_features=3072, bias=False)\n          (act): SiLU()\n        )\n        (ffn_norm): OpenELMRMSNorm(num_features=3072, eps=1e-06)\n        (attn_norm): OpenELMRMSNorm(num_features=3072, eps=1e-06)\n      )\n      (12): OpenELMDecoderLayer(\n        (attn): OpenELMMultiHeadCausalAttention(\n          query_heads=16, key_heads=4, value_heads=4\n          (qkv_proj): Linear(in_features=3072, out_features=3072, bias=False)\n          (pos_embedding): OpenELMRotaryEmbedding(\tmodel_dim=128, max_seq_length=4096, freq_constant=10000)\n          (q_norm): OpenELMRMSNorm(num_features=128, eps=1e-06)\n          (k_norm): OpenELMRMSNorm(num_features=128, eps=1e-06)\n          (out_proj): Linear(in_features=2048, out_features=3072, bias=False)\n        )\n        (ffn): OpenELMFeedForwardNetwork(\n          (ffn_with_glu) : True\n          (proj_1): Linear(in_features=3072, out_features=10240, bias=False)\n          (proj_2): Linear(in_features=5120, out_features=3072, bias=False)\n          (act): SiLU()\n        )\n        (ffn_norm): OpenELMRMSNorm(num_features=3072, eps=1e-06)\n        (attn_norm): OpenELMRMSNorm(num_features=3072, eps=1e-06)\n      )\n      (13): OpenELMDecoderLayer(\n        (attn): OpenELMMultiHeadCausalAttention(\n          query_heads=16, key_heads=4, value_heads=4\n          (qkv_proj): Linear(in_features=3072, out_features=3072, bias=False)\n          (pos_embedding): OpenELMRotaryEmbedding(\tmodel_dim=128, max_seq_length=4096, freq_constant=10000)\n          (q_norm): OpenELMRMSNorm(num_features=128, eps=1e-06)\n          (k_norm): OpenELMRMSNorm(num_features=128, eps=1e-06)\n          (out_proj): Linear(in_features=2048, out_features=3072, bias=False)\n        )\n        (ffn): OpenELMFeedForwardNetwork(\n          (ffn_with_glu) : True\n          (proj_1): Linear(in_features=3072, out_features=11264, bias=False)\n          (proj_2): Linear(in_features=5632, out_features=3072, bias=False)\n          (act): SiLU()\n        )\n        (ffn_norm): OpenELMRMSNorm(num_features=3072, eps=1e-06)\n        (attn_norm): OpenELMRMSNorm(num_features=3072, eps=1e-06)\n      )\n      (14): OpenELMDecoderLayer(\n        (attn): OpenELMMultiHeadCausalAttention(\n          query_heads=16, key_heads=4, value_heads=4\n          (qkv_proj): Linear(in_features=3072, out_features=3072, bias=False)\n          (pos_embedding): OpenELMRotaryEmbedding(\tmodel_dim=128, max_seq_length=4096, freq_constant=10000)\n          (q_norm): OpenELMRMSNorm(num_features=128, eps=1e-06)\n          (k_norm): OpenELMRMSNorm(num_features=128, eps=1e-06)\n          (out_proj): Linear(in_features=2048, out_features=3072, bias=False)\n        )\n        (ffn): OpenELMFeedForwardNetwork(\n          (ffn_with_glu) : True\n          (proj_1): Linear(in_features=3072, out_features=11776, bias=False)\n          (proj_2): Linear(in_features=5888, out_features=3072, bias=False)\n          (act): SiLU()\n        )\n        (ffn_norm): OpenELMRMSNorm(num_features=3072, eps=1e-06)\n        (attn_norm): OpenELMRMSNorm(num_features=3072, eps=1e-06)\n      )\n      (15): OpenELMDecoderLayer(\n        (attn): OpenELMMultiHeadCausalAttention(\n          query_heads=16, key_heads=4, value_heads=4\n          (qkv_proj): Linear(in_features=3072, out_features=3072, bias=False)\n          (pos_embedding): OpenELMRotaryEmbedding(\tmodel_dim=128, max_seq_length=4096, freq_constant=10000)\n          (q_norm): OpenELMRMSNorm(num_features=128, eps=1e-06)\n          (k_norm): OpenELMRMSNorm(num_features=128, eps=1e-06)\n          (out_proj): Linear(in_features=2048, out_features=3072, bias=False)\n        )\n        (ffn): OpenELMFeedForwardNetwork(\n          (ffn_with_glu) : True\n          (proj_1): Linear(in_features=3072, out_features=12288, bias=False)\n          (proj_2): Linear(in_features=6144, out_features=3072, bias=False)\n          (act): SiLU()\n        )\n        (ffn_norm): OpenELMRMSNorm(num_features=3072, eps=1e-06)\n        (attn_norm): OpenELMRMSNorm(num_features=3072, eps=1e-06)\n      )\n      (16): OpenELMDecoderLayer(\n        (attn): OpenELMMultiHeadCausalAttention(\n          query_heads=16, key_heads=4, value_heads=4\n          (qkv_proj): Linear(in_features=3072, out_features=3072, bias=False)\n          (pos_embedding): OpenELMRotaryEmbedding(\tmodel_dim=128, max_seq_length=4096, freq_constant=10000)\n          (q_norm): OpenELMRMSNorm(num_features=128, eps=1e-06)\n          (k_norm): OpenELMRMSNorm(num_features=128, eps=1e-06)\n          (out_proj): Linear(in_features=2048, out_features=3072, bias=False)\n        )\n        (ffn): OpenELMFeedForwardNetwork(\n          (ffn_with_glu) : True\n          (proj_1): Linear(in_features=3072, out_features=12800, bias=False)\n          (proj_2): Linear(in_features=6400, out_features=3072, bias=False)\n          (act): SiLU()\n        )\n        (ffn_norm): OpenELMRMSNorm(num_features=3072, eps=1e-06)\n        (attn_norm): OpenELMRMSNorm(num_features=3072, eps=1e-06)\n      )\n      (17): OpenELMDecoderLayer(\n        (attn): OpenELMMultiHeadCausalAttention(\n          query_heads=16, key_heads=4, value_heads=4\n          (qkv_proj): Linear(in_features=3072, out_features=3072, bias=False)\n          (pos_embedding): OpenELMRotaryEmbedding(\tmodel_dim=128, max_seq_length=4096, freq_constant=10000)\n          (q_norm): OpenELMRMSNorm(num_features=128, eps=1e-06)\n          (k_norm): OpenELMRMSNorm(num_features=128, eps=1e-06)\n          (out_proj): Linear(in_features=2048, out_features=3072, bias=False)\n        )\n        (ffn): OpenELMFeedForwardNetwork(\n          (ffn_with_glu) : True\n          (proj_1): Linear(in_features=3072, out_features=13312, bias=False)\n          (proj_2): Linear(in_features=6656, out_features=3072, bias=False)\n          (act): SiLU()\n        )\n        (ffn_norm): OpenELMRMSNorm(num_features=3072, eps=1e-06)\n        (attn_norm): OpenELMRMSNorm(num_features=3072, eps=1e-06)\n      )\n      (18): OpenELMDecoderLayer(\n        (attn): OpenELMMultiHeadCausalAttention(\n          query_heads=20, key_heads=5, value_heads=5\n          (qkv_proj): Linear(in_features=3072, out_features=3840, bias=False)\n          (pos_embedding): OpenELMRotaryEmbedding(\tmodel_dim=128, max_seq_length=4096, freq_constant=10000)\n          (q_norm): OpenELMRMSNorm(num_features=128, eps=1e-06)\n          (k_norm): OpenELMRMSNorm(num_features=128, eps=1e-06)\n          (out_proj): Linear(in_features=2560, out_features=3072, bias=False)\n        )\n        (ffn): OpenELMFeedForwardNetwork(\n          (ffn_with_glu) : True\n          (proj_1): Linear(in_features=3072, out_features=14336, bias=False)\n          (proj_2): Linear(in_features=7168, out_features=3072, bias=False)\n          (act): SiLU()\n        )\n        (ffn_norm): OpenELMRMSNorm(num_features=3072, eps=1e-06)\n        (attn_norm): OpenELMRMSNorm(num_features=3072, eps=1e-06)\n      )\n      (19): OpenELMDecoderLayer(\n        (attn): OpenELMMultiHeadCausalAttention(\n          query_heads=20, key_heads=5, value_heads=5\n          (qkv_proj): Linear(in_features=3072, out_features=3840, bias=False)\n          (pos_embedding): OpenELMRotaryEmbedding(\tmodel_dim=128, max_seq_length=4096, freq_constant=10000)\n          (q_norm): OpenELMRMSNorm(num_features=128, eps=1e-06)\n          (k_norm): OpenELMRMSNorm(num_features=128, eps=1e-06)\n          (out_proj): Linear(in_features=2560, out_features=3072, bias=False)\n        )\n        (ffn): OpenELMFeedForwardNetwork(\n          (ffn_with_glu) : True\n          (proj_1): Linear(in_features=3072, out_features=14848, bias=False)\n          (proj_2): Linear(in_features=7424, out_features=3072, bias=False)\n          (act): SiLU()\n        )\n        (ffn_norm): OpenELMRMSNorm(num_features=3072, eps=1e-06)\n        (attn_norm): OpenELMRMSNorm(num_features=3072, eps=1e-06)\n      )\n      (20): OpenELMDecoderLayer(\n        (attn): OpenELMMultiHeadCausalAttention(\n          query_heads=20, key_heads=5, value_heads=5\n          (qkv_proj): Linear(in_features=3072, out_features=3840, bias=False)\n          (pos_embedding): OpenELMRotaryEmbedding(\tmodel_dim=128, max_seq_length=4096, freq_constant=10000)\n          (q_norm): OpenELMRMSNorm(num_features=128, eps=1e-06)\n          (k_norm): OpenELMRMSNorm(num_features=128, eps=1e-06)\n          (out_proj): Linear(in_features=2560, out_features=3072, bias=False)\n        )\n        (ffn): OpenELMFeedForwardNetwork(\n          (ffn_with_glu) : True\n          (proj_1): Linear(in_features=3072, out_features=15360, bias=False)\n          (proj_2): Linear(in_features=7680, out_features=3072, bias=False)\n          (act): SiLU()\n        )\n        (ffn_norm): OpenELMRMSNorm(num_features=3072, eps=1e-06)\n        (attn_norm): OpenELMRMSNorm(num_features=3072, eps=1e-06)\n      )\n      (21): OpenELMDecoderLayer(\n        (attn): OpenELMMultiHeadCausalAttention(\n          query_heads=20, key_heads=5, value_heads=5\n          (qkv_proj): Linear(in_features=3072, out_features=3840, bias=False)\n          (pos_embedding): OpenELMRotaryEmbedding(\tmodel_dim=128, max_seq_length=4096, freq_constant=10000)\n          (q_norm): OpenELMRMSNorm(num_features=128, eps=1e-06)\n          (k_norm): OpenELMRMSNorm(num_features=128, eps=1e-06)\n          (out_proj): Linear(in_features=2560, out_features=3072, bias=False)\n        )\n        (ffn): OpenELMFeedForwardNetwork(\n          (ffn_with_glu) : True\n          (proj_1): Linear(in_features=3072, out_features=15872, bias=False)\n          (proj_2): Linear(in_features=7936, out_features=3072, bias=False)\n          (act): SiLU()\n        )\n        (ffn_norm): OpenELMRMSNorm(num_features=3072, eps=1e-06)\n        (attn_norm): OpenELMRMSNorm(num_features=3072, eps=1e-06)\n      )\n      (22): OpenELMDecoderLayer(\n        (attn): OpenELMMultiHeadCausalAttention(\n          query_heads=20, key_heads=5, value_heads=5\n          (qkv_proj): Linear(in_features=3072, out_features=3840, bias=False)\n          (pos_embedding): OpenELMRotaryEmbedding(\tmodel_dim=128, max_seq_length=4096, freq_constant=10000)\n          (q_norm): OpenELMRMSNorm(num_features=128, eps=1e-06)\n          (k_norm): OpenELMRMSNorm(num_features=128, eps=1e-06)\n          (out_proj): Linear(in_features=2560, out_features=3072, bias=False)\n        )\n        (ffn): OpenELMFeedForwardNetwork(\n          (ffn_with_glu) : True\n          (proj_1): Linear(in_features=3072, out_features=16384, bias=False)\n          (proj_2): Linear(in_features=8192, out_features=3072, bias=False)\n          (act): SiLU()\n        )\n        (ffn_norm): OpenELMRMSNorm(num_features=3072, eps=1e-06)\n        (attn_norm): OpenELMRMSNorm(num_features=3072, eps=1e-06)\n      )\n      (23): OpenELMDecoderLayer(\n        (attn): OpenELMMultiHeadCausalAttention(\n          query_heads=20, key_heads=5, value_heads=5\n          (qkv_proj): Linear(in_features=3072, out_features=3840, bias=False)\n          (pos_embedding): OpenELMRotaryEmbedding(\tmodel_dim=128, max_seq_length=4096, freq_constant=10000)\n          (q_norm): OpenELMRMSNorm(num_features=128, eps=1e-06)\n          (k_norm): OpenELMRMSNorm(num_features=128, eps=1e-06)\n          (out_proj): Linear(in_features=2560, out_features=3072, bias=False)\n        )\n        (ffn): OpenELMFeedForwardNetwork(\n          (ffn_with_glu) : True\n          (proj_1): Linear(in_features=3072, out_features=17408, bias=False)\n          (proj_2): Linear(in_features=8704, out_features=3072, bias=False)\n          (act): SiLU()\n        )\n        (ffn_norm): OpenELMRMSNorm(num_features=3072, eps=1e-06)\n        (attn_norm): OpenELMRMSNorm(num_features=3072, eps=1e-06)\n      )\n      (24): OpenELMDecoderLayer(\n        (attn): OpenELMMultiHeadCausalAttention(\n          query_heads=20, key_heads=5, value_heads=5\n          (qkv_proj): Linear(in_features=3072, out_features=3840, bias=False)\n          (pos_embedding): OpenELMRotaryEmbedding(\tmodel_dim=128, max_seq_length=4096, freq_constant=10000)\n          (q_norm): OpenELMRMSNorm(num_features=128, eps=1e-06)\n          (k_norm): OpenELMRMSNorm(num_features=128, eps=1e-06)\n          (out_proj): Linear(in_features=2560, out_features=3072, bias=False)\n        )\n        (ffn): OpenELMFeedForwardNetwork(\n          (ffn_with_glu) : True\n          (proj_1): Linear(in_features=3072, out_features=17920, bias=False)\n          (proj_2): Linear(in_features=8960, out_features=3072, bias=False)\n          (act): SiLU()\n        )\n        (ffn_norm): OpenELMRMSNorm(num_features=3072, eps=1e-06)\n        (attn_norm): OpenELMRMSNorm(num_features=3072, eps=1e-06)\n      )\n      (25): OpenELMDecoderLayer(\n        (attn): OpenELMMultiHeadCausalAttention(\n          query_heads=20, key_heads=5, value_heads=5\n          (qkv_proj): Linear(in_features=3072, out_features=3840, bias=False)\n          (pos_embedding): OpenELMRotaryEmbedding(\tmodel_dim=128, max_seq_length=4096, freq_constant=10000)\n          (q_norm): OpenELMRMSNorm(num_features=128, eps=1e-06)\n          (k_norm): OpenELMRMSNorm(num_features=128, eps=1e-06)\n          (out_proj): Linear(in_features=2560, out_features=3072, bias=False)\n        )\n        (ffn): OpenELMFeedForwardNetwork(\n          (ffn_with_glu) : True\n          (proj_1): Linear(in_features=3072, out_features=18432, bias=False)\n          (proj_2): Linear(in_features=9216, out_features=3072, bias=False)\n          (act): SiLU()\n        )\n        (ffn_norm): OpenELMRMSNorm(num_features=3072, eps=1e-06)\n        (attn_norm): OpenELMRMSNorm(num_features=3072, eps=1e-06)\n      )\n      (26): OpenELMDecoderLayer(\n        (attn): OpenELMMultiHeadCausalAttention(\n          query_heads=20, key_heads=5, value_heads=5\n          (qkv_proj): Linear(in_features=3072, out_features=3840, bias=False)\n          (pos_embedding): OpenELMRotaryEmbedding(\tmodel_dim=128, max_seq_length=4096, freq_constant=10000)\n          (q_norm): OpenELMRMSNorm(num_features=128, eps=1e-06)\n          (k_norm): OpenELMRMSNorm(num_features=128, eps=1e-06)\n          (out_proj): Linear(in_features=2560, out_features=3072, bias=False)\n        )\n        (ffn): OpenELMFeedForwardNetwork(\n          (ffn_with_glu) : True\n          (proj_1): Linear(in_features=3072, out_features=18944, bias=False)\n          (proj_2): Linear(in_features=9472, out_features=3072, bias=False)\n          (act): SiLU()\n        )\n        (ffn_norm): OpenELMRMSNorm(num_features=3072, eps=1e-06)\n        (attn_norm): OpenELMRMSNorm(num_features=3072, eps=1e-06)\n      )\n      (27): OpenELMDecoderLayer(\n        (attn): OpenELMMultiHeadCausalAttention(\n          query_heads=20, key_heads=5, value_heads=5\n          (qkv_proj): Linear(in_features=3072, out_features=3840, bias=False)\n          (pos_embedding): OpenELMRotaryEmbedding(\tmodel_dim=128, max_seq_length=4096, freq_constant=10000)\n          (q_norm): OpenELMRMSNorm(num_features=128, eps=1e-06)\n          (k_norm): OpenELMRMSNorm(num_features=128, eps=1e-06)\n          (out_proj): Linear(in_features=2560, out_features=3072, bias=False)\n        )\n        (ffn): OpenELMFeedForwardNetwork(\n          (ffn_with_glu) : True\n          (proj_1): Linear(in_features=3072, out_features=19456, bias=False)\n          (proj_2): Linear(in_features=9728, out_features=3072, bias=False)\n          (act): SiLU()\n        )\n        (ffn_norm): OpenELMRMSNorm(num_features=3072, eps=1e-06)\n        (attn_norm): OpenELMRMSNorm(num_features=3072, eps=1e-06)\n      )\n      (28): OpenELMDecoderLayer(\n        (attn): OpenELMMultiHeadCausalAttention(\n          query_heads=20, key_heads=5, value_heads=5\n          (qkv_proj): Linear(in_features=3072, out_features=3840, bias=False)\n          (pos_embedding): OpenELMRotaryEmbedding(\tmodel_dim=128, max_seq_length=4096, freq_constant=10000)\n          (q_norm): OpenELMRMSNorm(num_features=128, eps=1e-06)\n          (k_norm): OpenELMRMSNorm(num_features=128, eps=1e-06)\n          (out_proj): Linear(in_features=2560, out_features=3072, bias=False)\n        )\n        (ffn): OpenELMFeedForwardNetwork(\n          (ffn_with_glu) : True\n          (proj_1): Linear(in_features=3072, out_features=20480, bias=False)\n          (proj_2): Linear(in_features=10240, out_features=3072, bias=False)\n          (act): SiLU()\n        )\n        (ffn_norm): OpenELMRMSNorm(num_features=3072, eps=1e-06)\n        (attn_norm): OpenELMRMSNorm(num_features=3072, eps=1e-06)\n      )\n      (29): OpenELMDecoderLayer(\n        (attn): OpenELMMultiHeadCausalAttention(\n          query_heads=20, key_heads=5, value_heads=5\n          (qkv_proj): Linear(in_features=3072, out_features=3840, bias=False)\n          (pos_embedding): OpenELMRotaryEmbedding(\tmodel_dim=128, max_seq_length=4096, freq_constant=10000)\n          (q_norm): OpenELMRMSNorm(num_features=128, eps=1e-06)\n          (k_norm): OpenELMRMSNorm(num_features=128, eps=1e-06)\n          (out_proj): Linear(in_features=2560, out_features=3072, bias=False)\n        )\n        (ffn): OpenELMFeedForwardNetwork(\n          (ffn_with_glu) : True\n          (proj_1): Linear(in_features=3072, out_features=20992, bias=False)\n          (proj_2): Linear(in_features=10496, out_features=3072, bias=False)\n          (act): SiLU()\n        )\n        (ffn_norm): OpenELMRMSNorm(num_features=3072, eps=1e-06)\n        (attn_norm): OpenELMRMSNorm(num_features=3072, eps=1e-06)\n      )\n      (30): OpenELMDecoderLayer(\n        (attn): OpenELMMultiHeadCausalAttention(\n          query_heads=24, key_heads=6, value_heads=6\n          (qkv_proj): Linear(in_features=3072, out_features=4608, bias=False)\n          (pos_embedding): OpenELMRotaryEmbedding(\tmodel_dim=128, max_seq_length=4096, freq_constant=10000)\n          (q_norm): OpenELMRMSNorm(num_features=128, eps=1e-06)\n          (k_norm): OpenELMRMSNorm(num_features=128, eps=1e-06)\n          (out_proj): Linear(in_features=3072, out_features=3072, bias=False)\n        )\n        (ffn): OpenELMFeedForwardNetwork(\n          (ffn_with_glu) : True\n          (proj_1): Linear(in_features=3072, out_features=21504, bias=False)\n          (proj_2): Linear(in_features=10752, out_features=3072, bias=False)\n          (act): SiLU()\n        )\n        (ffn_norm): OpenELMRMSNorm(num_features=3072, eps=1e-06)\n        (attn_norm): OpenELMRMSNorm(num_features=3072, eps=1e-06)\n      )\n      (31): OpenELMDecoderLayer(\n        (attn): OpenELMMultiHeadCausalAttention(\n          query_heads=24, key_heads=6, value_heads=6\n          (qkv_proj): Linear(in_features=3072, out_features=4608, bias=False)\n          (pos_embedding): OpenELMRotaryEmbedding(\tmodel_dim=128, max_seq_length=4096, freq_constant=10000)\n          (q_norm): OpenELMRMSNorm(num_features=128, eps=1e-06)\n          (k_norm): OpenELMRMSNorm(num_features=128, eps=1e-06)\n          (out_proj): Linear(in_features=3072, out_features=3072, bias=False)\n        )\n        (ffn): OpenELMFeedForwardNetwork(\n          (ffn_with_glu) : True\n          (proj_1): Linear(in_features=3072, out_features=22016, bias=False)\n          (proj_2): Linear(in_features=11008, out_features=3072, bias=False)\n          (act): SiLU()\n        )\n        (ffn_norm): OpenELMRMSNorm(num_features=3072, eps=1e-06)\n        (attn_norm): OpenELMRMSNorm(num_features=3072, eps=1e-06)\n      )\n      (32): OpenELMDecoderLayer(\n        (attn): OpenELMMultiHeadCausalAttention(\n          query_heads=24, key_heads=6, value_heads=6\n          (qkv_proj): Linear(in_features=3072, out_features=4608, bias=False)\n          (pos_embedding): OpenELMRotaryEmbedding(\tmodel_dim=128, max_seq_length=4096, freq_constant=10000)\n          (q_norm): OpenELMRMSNorm(num_features=128, eps=1e-06)\n          (k_norm): OpenELMRMSNorm(num_features=128, eps=1e-06)\n          (out_proj): Linear(in_features=3072, out_features=3072, bias=False)\n        )\n        (ffn): OpenELMFeedForwardNetwork(\n          (ffn_with_glu) : True\n          (proj_1): Linear(in_features=3072, out_features=22528, bias=False)\n          (proj_2): Linear(in_features=11264, out_features=3072, bias=False)\n          (act): SiLU()\n        )\n        (ffn_norm): OpenELMRMSNorm(num_features=3072, eps=1e-06)\n        (attn_norm): OpenELMRMSNorm(num_features=3072, eps=1e-06)\n      )\n      (33): OpenELMDecoderLayer(\n        (attn): OpenELMMultiHeadCausalAttention(\n          query_heads=24, key_heads=6, value_heads=6\n          (qkv_proj): Linear(in_features=3072, out_features=4608, bias=False)\n          (pos_embedding): OpenELMRotaryEmbedding(\tmodel_dim=128, max_seq_length=4096, freq_constant=10000)\n          (q_norm): OpenELMRMSNorm(num_features=128, eps=1e-06)\n          (k_norm): OpenELMRMSNorm(num_features=128, eps=1e-06)\n          (out_proj): Linear(in_features=3072, out_features=3072, bias=False)\n        )\n        (ffn): OpenELMFeedForwardNetwork(\n          (ffn_with_glu) : True\n          (proj_1): Linear(in_features=3072, out_features=23552, bias=False)\n          (proj_2): Linear(in_features=11776, out_features=3072, bias=False)\n          (act): SiLU()\n        )\n        (ffn_norm): OpenELMRMSNorm(num_features=3072, eps=1e-06)\n        (attn_norm): OpenELMRMSNorm(num_features=3072, eps=1e-06)\n      )\n      (34): OpenELMDecoderLayer(\n        (attn): OpenELMMultiHeadCausalAttention(\n          query_heads=24, key_heads=6, value_heads=6\n          (qkv_proj): Linear(in_features=3072, out_features=4608, bias=False)\n          (pos_embedding): OpenELMRotaryEmbedding(\tmodel_dim=128, max_seq_length=4096, freq_constant=10000)\n          (q_norm): OpenELMRMSNorm(num_features=128, eps=1e-06)\n          (k_norm): OpenELMRMSNorm(num_features=128, eps=1e-06)\n          (out_proj): Linear(in_features=3072, out_features=3072, bias=False)\n        )\n        (ffn): OpenELMFeedForwardNetwork(\n          (ffn_with_glu) : True\n          (proj_1): Linear(in_features=3072, out_features=24064, bias=False)\n          (proj_2): Linear(in_features=12032, out_features=3072, bias=False)\n          (act): SiLU()\n        )\n        (ffn_norm): OpenELMRMSNorm(num_features=3072, eps=1e-06)\n        (attn_norm): OpenELMRMSNorm(num_features=3072, eps=1e-06)\n      )\n      (35): OpenELMDecoderLayer(\n        (attn): OpenELMMultiHeadCausalAttention(\n          query_heads=24, key_heads=6, value_heads=6\n          (qkv_proj): Linear(in_features=3072, out_features=4608, bias=False)\n          (pos_embedding): OpenELMRotaryEmbedding(\tmodel_dim=128, max_seq_length=4096, freq_constant=10000)\n          (q_norm): OpenELMRMSNorm(num_features=128, eps=1e-06)\n          (k_norm): OpenELMRMSNorm(num_features=128, eps=1e-06)\n          (out_proj): Linear(in_features=3072, out_features=3072, bias=False)\n        )\n        (ffn): OpenELMFeedForwardNetwork(\n          (ffn_with_glu) : True\n          (proj_1): Linear(in_features=3072, out_features=24576, bias=False)\n          (proj_2): Linear(in_features=12288, out_features=3072, bias=False)\n          (act): SiLU()\n        )\n        (ffn_norm): OpenELMRMSNorm(num_features=3072, eps=1e-06)\n        (attn_norm): OpenELMRMSNorm(num_features=3072, eps=1e-06)\n      )\n    )\n    (norm): OpenELMRMSNorm(num_features=3072, eps=1e-06)\n  )\n)```"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Inference",
   "id": "12b7e2fc01311961"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T04:52:07.156754Z",
     "start_time": "2024-05-02T04:52:06.137352Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def generate_response(system ,user):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system},\n",
    "        {\"role\": \"user\", \"content\": user}\n",
    "    ]\n",
    "    prompt = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=False\n",
    "    )\n",
    "    \n",
    "    input_ids = tokenizer.encode(\n",
    "        prompt,\n",
    "        max_length=max_length,\n",
    "        padding=padding,\n",
    "        truncation=truncation,\n",
    "        add_special_tokens=False,\n",
    "        return_tensors=\"pt\"\n",
    "    ).to(device)\n",
    "    \n",
    "    outputs = model.generate(\n",
    "        input_ids=input_ids,\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "        num_return_sequences=num_return_sequences,\n",
    "        max_new_tokens=max_new_tokens,\n",
    "        do_sample=do_sample,\n",
    "        temperature=temperature,\n",
    "        top_k=top_k,\n",
    "        top_p=top_p,\n",
    "        repetition_penalty=repetition_penalty\n",
    "    )\n",
    "    \n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=False)"
   ],
   "id": "1c849786ee0282d8",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T04:52:07.172785Z",
     "start_time": "2024-05-02T04:52:07.163313Z"
    }
   },
   "cell_type": "code",
   "source": "system_prompt = \"다음 지시사항에 대한 응답을 작성해주세요.\"",
   "id": "36dd54c1250609de",
   "outputs": [],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "source": "user_prompt = \"피보나치 수열에 대해 설명해주세요.\"",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-02T04:52:08.388727Z",
     "start_time": "2024-05-02T04:52:07.174225Z"
    }
   },
   "id": "7e2c71d41fed35b0",
   "outputs": [],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "source": [
    "response = generate_response(system_prompt, user_prompt)\n",
    "print(response)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-02T04:54:06.234921Z",
     "start_time": "2024-05-02T04:52:08.414982Z"
    }
   },
   "id": "aac19ad24cb1cca2",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "No chat template is defined for this tokenizer - using the default template for the LlamaTokenizerFast class. If the default is not appropriate for your model, please set `tokenizer.chat_template` to an appropriate template. See https://huggingface.co/docs/transformers/main/chat_templating for more information.\n",
      "\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "The operator 'aten::isin.Tensor_Tensor_out' is not currently implemented for the MPS device. If you want this op to be added in priority during the prototype phase of this feature, please comment on https://github.com/pytorch/pytorch/issues/77764. As a temporary fix, you can set the environment variable `PYTORCH_ENABLE_MPS_FALLBACK=1` to use the CPU as a fallback for this op. WARNING: this will be slower than running natively on MPS.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNotImplementedError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[16], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m response \u001B[38;5;241m=\u001B[39m generate_response(system_prompt, user_prompt)\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28mprint\u001B[39m(response)\n",
      "Cell \u001B[0;32mIn[13], line 21\u001B[0m, in \u001B[0;36mgenerate_response\u001B[0;34m(system, user)\u001B[0m\n\u001B[1;32m      6\u001B[0m prompt \u001B[38;5;241m=\u001B[39m tokenizer\u001B[38;5;241m.\u001B[39mapply_chat_template(\n\u001B[1;32m      7\u001B[0m     messages,\n\u001B[1;32m      8\u001B[0m     tokenize\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[1;32m      9\u001B[0m     add_generation_prompt\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[1;32m     10\u001B[0m )\n\u001B[1;32m     12\u001B[0m input_ids \u001B[38;5;241m=\u001B[39m tokenizer\u001B[38;5;241m.\u001B[39mencode(\n\u001B[1;32m     13\u001B[0m     prompt,\n\u001B[1;32m     14\u001B[0m     max_length\u001B[38;5;241m=\u001B[39mmax_length,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     18\u001B[0m     return_tensors\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpt\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     19\u001B[0m )\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[0;32m---> 21\u001B[0m outputs \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mgenerate(\n\u001B[1;32m     22\u001B[0m     input_ids\u001B[38;5;241m=\u001B[39minput_ids,\n\u001B[1;32m     23\u001B[0m     pad_token_id\u001B[38;5;241m=\u001B[39mtokenizer\u001B[38;5;241m.\u001B[39meos_token_id,\n\u001B[1;32m     24\u001B[0m     num_return_sequences\u001B[38;5;241m=\u001B[39mnum_return_sequences,\n\u001B[1;32m     25\u001B[0m     max_new_tokens\u001B[38;5;241m=\u001B[39mmax_new_tokens,\n\u001B[1;32m     26\u001B[0m     do_sample\u001B[38;5;241m=\u001B[39mdo_sample,\n\u001B[1;32m     27\u001B[0m     temperature\u001B[38;5;241m=\u001B[39mtemperature,\n\u001B[1;32m     28\u001B[0m     top_k\u001B[38;5;241m=\u001B[39mtop_k,\n\u001B[1;32m     29\u001B[0m     top_p\u001B[38;5;241m=\u001B[39mtop_p,\n\u001B[1;32m     30\u001B[0m     repetition_penalty\u001B[38;5;241m=\u001B[39mrepetition_penalty\n\u001B[1;32m     31\u001B[0m )\n\u001B[1;32m     33\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m tokenizer\u001B[38;5;241m.\u001B[39mdecode(outputs[\u001B[38;5;241m0\u001B[39m], skip_special_tokens\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n",
      "File \u001B[0;32m/opt/anaconda3/envs/torch-env/lib/python3.11/site-packages/torch/utils/_contextlib.py:115\u001B[0m, in \u001B[0;36mcontext_decorator.<locals>.decorate_context\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    112\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(func)\n\u001B[1;32m    113\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdecorate_context\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m    114\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m ctx_factory():\n\u001B[0;32m--> 115\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m/opt/anaconda3/envs/torch-env/lib/python3.11/site-packages/transformers/generation/utils.py:1622\u001B[0m, in \u001B[0;36mGenerationMixin.generate\u001B[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001B[0m\n\u001B[1;32m   1614\u001B[0m     input_ids, model_kwargs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_expand_inputs_for_generation(\n\u001B[1;32m   1615\u001B[0m         input_ids\u001B[38;5;241m=\u001B[39minput_ids,\n\u001B[1;32m   1616\u001B[0m         expand_size\u001B[38;5;241m=\u001B[39mgeneration_config\u001B[38;5;241m.\u001B[39mnum_return_sequences,\n\u001B[1;32m   1617\u001B[0m         is_encoder_decoder\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mis_encoder_decoder,\n\u001B[1;32m   1618\u001B[0m         \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mmodel_kwargs,\n\u001B[1;32m   1619\u001B[0m     )\n\u001B[1;32m   1621\u001B[0m     \u001B[38;5;66;03m# 13. run sample\u001B[39;00m\n\u001B[0;32m-> 1622\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sample(\n\u001B[1;32m   1623\u001B[0m         input_ids,\n\u001B[1;32m   1624\u001B[0m         logits_processor\u001B[38;5;241m=\u001B[39mprepared_logits_processor,\n\u001B[1;32m   1625\u001B[0m         logits_warper\u001B[38;5;241m=\u001B[39mlogits_warper,\n\u001B[1;32m   1626\u001B[0m         stopping_criteria\u001B[38;5;241m=\u001B[39mprepared_stopping_criteria,\n\u001B[1;32m   1627\u001B[0m         pad_token_id\u001B[38;5;241m=\u001B[39mgeneration_config\u001B[38;5;241m.\u001B[39mpad_token_id,\n\u001B[1;32m   1628\u001B[0m         output_scores\u001B[38;5;241m=\u001B[39mgeneration_config\u001B[38;5;241m.\u001B[39moutput_scores,\n\u001B[1;32m   1629\u001B[0m         output_logits\u001B[38;5;241m=\u001B[39mgeneration_config\u001B[38;5;241m.\u001B[39moutput_logits,\n\u001B[1;32m   1630\u001B[0m         return_dict_in_generate\u001B[38;5;241m=\u001B[39mgeneration_config\u001B[38;5;241m.\u001B[39mreturn_dict_in_generate,\n\u001B[1;32m   1631\u001B[0m         synced_gpus\u001B[38;5;241m=\u001B[39msynced_gpus,\n\u001B[1;32m   1632\u001B[0m         streamer\u001B[38;5;241m=\u001B[39mstreamer,\n\u001B[1;32m   1633\u001B[0m         \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mmodel_kwargs,\n\u001B[1;32m   1634\u001B[0m     )\n\u001B[1;32m   1636\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m generation_mode \u001B[38;5;241m==\u001B[39m GenerationMode\u001B[38;5;241m.\u001B[39mBEAM_SEARCH:\n\u001B[1;32m   1637\u001B[0m     \u001B[38;5;66;03m# 11. prepare beam search scorer\u001B[39;00m\n\u001B[1;32m   1638\u001B[0m     beam_scorer \u001B[38;5;241m=\u001B[39m BeamSearchScorer(\n\u001B[1;32m   1639\u001B[0m         batch_size\u001B[38;5;241m=\u001B[39mbatch_size,\n\u001B[1;32m   1640\u001B[0m         num_beams\u001B[38;5;241m=\u001B[39mgeneration_config\u001B[38;5;241m.\u001B[39mnum_beams,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1645\u001B[0m         max_length\u001B[38;5;241m=\u001B[39mgeneration_config\u001B[38;5;241m.\u001B[39mmax_length,\n\u001B[1;32m   1646\u001B[0m     )\n",
      "File \u001B[0;32m/opt/anaconda3/envs/torch-env/lib/python3.11/site-packages/transformers/generation/utils.py:2847\u001B[0m, in \u001B[0;36mGenerationMixin._sample\u001B[0;34m(self, input_ids, logits_processor, stopping_criteria, logits_warper, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, output_logits, return_dict_in_generate, synced_gpus, streamer, **model_kwargs)\u001B[0m\n\u001B[1;32m   2840\u001B[0m         streamer\u001B[38;5;241m.\u001B[39mput(next_tokens\u001B[38;5;241m.\u001B[39mcpu())\n\u001B[1;32m   2841\u001B[0m     model_kwargs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_update_model_kwargs_for_generation(\n\u001B[1;32m   2842\u001B[0m         outputs,\n\u001B[1;32m   2843\u001B[0m         model_kwargs,\n\u001B[1;32m   2844\u001B[0m         is_encoder_decoder\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mis_encoder_decoder,\n\u001B[1;32m   2845\u001B[0m     )\n\u001B[0;32m-> 2847\u001B[0m     unfinished_sequences \u001B[38;5;241m=\u001B[39m unfinished_sequences \u001B[38;5;241m&\u001B[39m \u001B[38;5;241m~\u001B[39mstopping_criteria(input_ids, scores)\n\u001B[1;32m   2848\u001B[0m     this_peer_finished \u001B[38;5;241m=\u001B[39m unfinished_sequences\u001B[38;5;241m.\u001B[39mmax() \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[1;32m   2850\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m streamer \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[0;32m/opt/anaconda3/envs/torch-env/lib/python3.11/site-packages/transformers/generation/stopping_criteria.py:158\u001B[0m, in \u001B[0;36mStoppingCriteriaList.__call__\u001B[0;34m(self, input_ids, scores, **kwargs)\u001B[0m\n\u001B[1;32m    156\u001B[0m is_done \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mfull((input_ids\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m],), \u001B[38;5;28;01mFalse\u001B[39;00m, device\u001B[38;5;241m=\u001B[39minput_ids\u001B[38;5;241m.\u001B[39mdevice)\n\u001B[1;32m    157\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m criteria \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m:\n\u001B[0;32m--> 158\u001B[0m     is_done \u001B[38;5;241m=\u001B[39m is_done \u001B[38;5;241m|\u001B[39m criteria(input_ids, scores, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    159\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m is_done\n",
      "File \u001B[0;32m/opt/anaconda3/envs/torch-env/lib/python3.11/site-packages/transformers/generation/stopping_criteria.py:149\u001B[0m, in \u001B[0;36mEosTokenCriteria.__call__\u001B[0;34m(self, input_ids, scores, **kwargs)\u001B[0m\n\u001B[1;32m    147\u001B[0m \u001B[38;5;129m@add_start_docstrings\u001B[39m(STOPPING_CRITERIA_INPUTS_DOCSTRING)\n\u001B[1;32m    148\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, input_ids: torch\u001B[38;5;241m.\u001B[39mLongTensor, scores: torch\u001B[38;5;241m.\u001B[39mFloatTensor, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m torch\u001B[38;5;241m.\u001B[39mBoolTensor:\n\u001B[0;32m--> 149\u001B[0m     is_done \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39misin(input_ids[:, \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m], \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39meos_token_id\u001B[38;5;241m.\u001B[39mto(input_ids\u001B[38;5;241m.\u001B[39mdevice))\n\u001B[1;32m    150\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m is_done\n",
      "\u001B[0;31mNotImplementedError\u001B[0m: The operator 'aten::isin.Tensor_Tensor_out' is not currently implemented for the MPS device. If you want this op to be added in priority during the prototype phase of this feature, please comment on https://github.com/pytorch/pytorch/issues/77764. As a temporary fix, you can set the environment variable `PYTORCH_ENABLE_MPS_FALLBACK=1` to use the CPU as a fallback for this op. WARNING: this will be slower than running natively on MPS."
     ]
    }
   ],
   "execution_count": 16
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
