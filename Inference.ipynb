{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Login to Hugging Face"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "98126af063c251e0"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-06T06:39:07.016976Z",
     "start_time": "2024-05-06T06:39:06.405781Z"
    }
   },
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from huggingface_hub import login\n",
    "\n",
    "load_dotenv()\n",
    "token = os.getenv(\"HUGGINGFACE_TOKEN\")\n",
    "login(\n",
    "    token=token, # ADD YOUR TOKEN HERE\n",
    "    add_to_git_credential=True\n",
    ")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token is valid (permission: write).\n",
      "Your token has been saved in your configured git credential helpers (store).\n",
      "Your token has been saved to /home/pathfinder/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Imports"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f21a95a142b71e93"
  },
  {
   "cell_type": "code",
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "# pytorch\n",
    "import torch\n",
    "\n",
    "# huggingface\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    BitsAndBytesConfig\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T06:39:09.004887Z",
     "start_time": "2024-05-06T06:39:07.018609Z"
    }
   },
   "id": "108874429856aabe",
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Device"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2f29fda50194a3fe"
  },
  {
   "cell_type": "code",
   "source": [
    "# Device setup\n",
    "device = (\n",
    "    \"cuda:0\" if torch.cuda.is_available() else # Nvidia GPU\n",
    "    \"mps\" if torch.backends.mps.is_available() else # Apple Silicon GPU\n",
    "    \"cpu\"\n",
    ")\n",
    "print(f\"Device = {device}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T06:39:09.343957Z",
     "start_time": "2024-05-06T06:39:09.006258Z"
    }
   },
   "id": "5555b5512cd1a1dd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device = cuda:0\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T06:39:09.442222Z",
     "start_time": "2024-05-06T06:39:09.345792Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Flash Attention Implementation\n",
    "if device == \"cuda:0\":\n",
    "    if torch.cuda.get_device_capability()[0] >= 8: # Ampere, Ada, or Hopper GPUs\n",
    "        attn_implementation = \"flash_attention_2\"\n",
    "        torch_dtype = torch.bfloat16\n",
    "    else:\n",
    "        attn_implementation = \"eager\"\n",
    "        torch_dtype = torch.float16\n",
    "else:\n",
    "    attn_implementation = \"eager\"\n",
    "    torch_dtype = torch.float32\n",
    "print(f\"Attention Implementation = {attn_implementation}\")"
   ],
   "id": "f0e72bfaf9471e1e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention Implementation = flash_attention_2\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Hyperparameters"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b452e9ab5ed33883"
  },
  {
   "cell_type": "code",
   "source": [
    "################################################################################\n",
    "# Tokenizer parameters\n",
    "################################################################################\n",
    "max_length=8192\n",
    "padding=\"do_not_pad\" # \"max_length\", \"longest\", \"do_not_pad\"\n",
    "truncation=True\n",
    "\n",
    "################################################################################\n",
    "# Generation parameters\n",
    "################################################################################\n",
    "num_return_sequences=1\n",
    "max_new_tokens=1024\n",
    "do_sample=True # True for sampling, False for greedy decoding\n",
    "temperature=0.6\n",
    "top_k=0 # not recommended\n",
    "top_p=0.9\n",
    "repetition_penalty=1.1\n",
    "\n",
    "################################################################################\n",
    "# bitsandbytes parameters\n",
    "################################################################################\n",
    "load_in_4bit=True\n",
    "bnb_4bit_compute_dtype=torch_dtype\n",
    "bnb_4bit_quant_type=\"nf4\" # \"nf4\", #fp4\"\n",
    "bnb_4bit_use_double_quant=True"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T06:39:09.446007Z",
     "start_time": "2024-05-06T06:39:09.443276Z"
    }
   },
   "id": "778930f2cc7c1224",
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "14f31dc8d02b7233"
  },
  {
   "cell_type": "code",
   "source": [
    "# Model List\n",
    "\n",
    "# gemma variants\n",
    "# \"google/gemma-1.1-7b-it\"\n",
    "# \"google/codegemma-7b-it\"\n",
    "\n",
    "# llama variants\n",
    "# \"meta-llama/Meta-Llama-3-8B\" // downloaded\n",
    "# \"meta-llama/Meta-Llama-3-8B-Instruct\" // downloaded\n",
    "# \"codellama/CodeLlama-7b-Instruct-hf\"\n",
    "# \"PathFinderKR/Waktaverse-Llama-3-KO-8B-Instruct\"\n",
    "\n",
    "# mistral variants\n",
    "# \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "\n",
    "# openELM variants\n",
    "# \"apple/OpenELM-3B-Instruct\" // downloaded\n",
    "\n",
    "# solar variants\n",
    "# \"upstage/SOLAR-10.7B-Instruct-v1.0\" // downloaded\n",
    "# \"PathFinderKR/Waktaverse-SOLAR-KO-10.7B-Instruct\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T06:39:09.460105Z",
     "start_time": "2024-05-06T06:39:09.447221Z"
    }
   },
   "id": "3a8abd326253137e",
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "source": "model_id = \"PathFinderKR/Waktaverse-Llama-3-KO-8B-Instruct\"",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T06:39:09.473046Z",
     "start_time": "2024-05-06T06:39:09.461233Z"
    }
   },
   "id": "352852804a6a38db",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T06:39:10.017892Z",
     "start_time": "2024-05-06T06:39:09.474333Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "tokenizer.padding_side = \"right\""
   ],
   "id": "3a1ea98f6eba58f8",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T06:39:10.024446Z",
     "start_time": "2024-05-06T06:39:10.019444Z"
    }
   },
   "cell_type": "code",
   "source": [
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=load_in_4bit,\n",
    "    bnb_4bit_compute_dtype=bnb_4bit_compute_dtype,\n",
    "    bnb_4bit_quant_type=bnb_4bit_quant_type,\n",
    "    bnb_4bit_use_double_quant=bnb_4bit_use_double_quant\n",
    ")"
   ],
   "id": "be26d2efc49fcbf6",
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    device_map=device,\n",
    "    attn_implementation=attn_implementation,\n",
    "    torch_dtype=torch_dtype,\n",
    "    quantization_config=quantization_config\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T07:03:00.390821Z",
     "start_time": "2024-05-06T06:39:10.026342Z"
    }
   },
   "id": "f5f879cefa518232",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c5f173ff8e31470e90a7148894069343"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "model-00001-of-00004.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "55992f30c5384a1b95d5b744e7290857"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "model-00002-of-00004.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d68dd1d99dcb48dbaeb44dc6e3daede5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "model-00003-of-00004.safetensors:   0%|          | 0.00/4.92G [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "03cb3d73e59a455cb199679204acea92"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "model-00004-of-00004.safetensors:   0%|          | 0.00/1.17G [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "094de8a3476c4886b3941810022c079b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1ec1745afc234454b867fedb2cc871cd"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T07:03:00.396473Z",
     "start_time": "2024-05-06T07:03:00.391881Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Display the model architecture\n",
    "display(Markdown(f'```{model}```'))"
   ],
   "id": "9fedd479c0a753a0",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "```LlamaForCausalLM(\n  (model): LlamaModel(\n    (embed_tokens): Embedding(128256, 4096)\n    (layers): ModuleList(\n      (0-31): 32 x LlamaDecoderLayer(\n        (self_attn): LlamaFlashAttention2(\n          (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n          (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n          (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n          (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n          (rotary_emb): LlamaRotaryEmbedding()\n        )\n        (mlp): LlamaMLP(\n          (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n          (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n          (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n          (act_fn): SiLU()\n        )\n        (input_layernorm): LlamaRMSNorm()\n        (post_attention_layernorm): LlamaRMSNorm()\n      )\n    )\n    (norm): LlamaRMSNorm()\n  )\n  (lm_head): Linear(in_features=4096, out_features=128256, bias=False)\n)```"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Inference",
   "id": "12b7e2fc01311961"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T07:03:00.403914Z",
     "start_time": "2024-05-06T07:03:00.397556Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def generate_response(system ,user):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system},\n",
    "        {\"role\": \"user\", \"content\": user}\n",
    "    ]\n",
    "    prompt = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=False\n",
    "    )\n",
    "    \n",
    "    input_ids = tokenizer.encode(\n",
    "        prompt,\n",
    "        max_length=max_length,\n",
    "        padding=padding,\n",
    "        truncation=truncation,\n",
    "        add_special_tokens=False,\n",
    "        return_tensors=\"pt\"\n",
    "    ).to(device)\n",
    "    \n",
    "    outputs = model.generate(\n",
    "        input_ids=input_ids,\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "        num_return_sequences=num_return_sequences,\n",
    "        max_new_tokens=max_new_tokens,\n",
    "        do_sample=do_sample,\n",
    "        temperature=temperature,\n",
    "        top_k=top_k,\n",
    "        top_p=top_p,\n",
    "        repetition_penalty=repetition_penalty\n",
    "    )\n",
    "    \n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=False)"
   ],
   "id": "1c849786ee0282d8",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T07:03:00.413244Z",
     "start_time": "2024-05-06T07:03:00.405160Z"
    }
   },
   "cell_type": "code",
   "source": "system_prompt = \"다음 지시사항에 대한 응답을 작성해주세요.\"",
   "id": "36dd54c1250609de",
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "source": "user_prompt = \"피보나치 수열에 대해 설명해주세요.\"",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T07:03:00.420558Z",
     "start_time": "2024-05-06T07:03:00.414228Z"
    }
   },
   "id": "7e2c71d41fed35b0",
   "outputs": [],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "source": [
    "response = generate_response(system_prompt, user_prompt)\n",
    "print(response)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T07:03:22.954087Z",
     "start_time": "2024-05-06T07:03:00.421699Z"
    }
   },
   "id": "aac19ad24cb1cca2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "다음 지시사항에 대한 응답을 작성해주세요.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "피보나치 수열에 대해 설명해주세요.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\"\n",
      "\n",
      "피보나치 수열은 0과 1로 시작하며, 각 항이 이전 두 개의 항을 더한 값으로 정의되는 수열입니다. 피보나치 수열은 수학에서 가장 유명한 수열 중 하나이며, 특히 재귀 함수와 관련된 문제에 자주 사용됩니다.\n",
      "\n",
      "피보나치 수열의 첫 번째 12개의 항은 다음과 같습니다:\n",
      "\n",
      "0, 1, 1, 2, 3, 5, 8, 13, 21, 34, 55, 89\n",
      "\n",
      "피보나치 수열은 0과 1로 시작하여, 각 항이 이전 두 개의 항을 더한 값으로 정의됩니다. 예를 들어, 7번째 항은 (5 + 2) = 7이고, 8번째 항은 (8 + 3) = 11입니다.\n",
      "\n",
      "피보나치 수열은 수학적 구조를 가지고 있으며, 이 구조는 자연스럽게 나타납니다. 피보나치 수열은 수학에서 매우 중요하며, 다양한 분야에서 적용될 수 있습니다. 예를 들어, 피보나치 수열은 재귀 함수와 관련된 문제에 자주 사용되며, 컴퓨터 프로그래밍에서도 자주 활용됩니다. 또한, 피보나치 수열은 수학의 다른 영역에서도 중요한 역할을 하며, 이를 통해 새로운 수학적인 발견들을 이루어낼 수 있습니다.\n",
      "\n",
      "피보나치 수열은 많은 문화에서 영향을 미쳤으며, 음악, 문학, 아트 등 다양한 분야에서 표현되어져 있습니다. 피보나치 수열은 수학의 기본 원리와 연결되어 있으며, 이를 통해 수학의 주요 개념과 관계를 이해하는 데 도움이 됩니다.\n",
      "\n",
      "결론적으로, 피보나치 수열은 수학에서 가장 유명한 수열 중 하나이며, 재귀 함수와 관련된 문제에 자주 사용됩니다. 피보나치 수열은 수학적 구조를 가지고 있으며, 이 구조는 자연스럽게 나타나고, 다양한 분야에서 중요한 역할을 합니다. 피보나치 수열은 수학의 기본 원리와 연결되어 있으며, 이를 통해 수학의 주요 개념과 관계를 이해하는 데 도움이 됩니다.<|eot_id|>\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Multi-turn Conversation",
   "id": "9377ca2ee01e9f56"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T07:03:22.957311Z",
     "start_time": "2024-05-06T07:03:22.955115Z"
    }
   },
   "cell_type": "code",
   "source": [
    "system_prompt = \"다음 지시사항에 대한 응답을 작성해주세요.\"\n",
    "conversation_history = [{\"role\": \"system\", \"content\": system_prompt}]"
   ],
   "id": "755414328bf0bb36",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T07:03:22.964085Z",
     "start_time": "2024-05-06T07:03:22.958138Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def generate_conversation(user):\n",
    "    global conversation_history\n",
    "    conversation_history.append({\"role\": \"user\", \"content\": user})\n",
    "    prompt = tokenizer.apply_chat_template(\n",
    "        conversation_history,\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=False\n",
    "    )\n",
    "    \n",
    "    input_ids = tokenizer.encode(\n",
    "        prompt,\n",
    "        max_length=max_length,\n",
    "        padding=padding,\n",
    "        truncation=truncation,\n",
    "        add_special_tokens=False,\n",
    "        return_tensors=\"pt\"\n",
    "    ).to(device)\n",
    "    \n",
    "    outputs = model.generate(\n",
    "        input_ids=input_ids,\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "        num_return_sequences=num_return_sequences,\n",
    "        max_new_tokens=max_new_tokens,\n",
    "        do_sample=do_sample,\n",
    "        temperature=temperature,\n",
    "        top_k=top_k,\n",
    "        top_p=top_p,\n",
    "        repetition_penalty=repetition_penalty\n",
    "    )\n",
    "    \n",
    "    assistant_response = tokenizer.decode(outputs[0], skip_special_tokens=False).split(\"<|start_header_id|>assistant<|end_header_id|>\")[-1]\n",
    "    conversation_history.append({\"role\": \"assistant\", \"content\": assistant_response})\n",
    "    return assistant_response"
   ],
   "id": "fcb7ac53017a73f",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T07:03:54.309349Z",
     "start_time": "2024-05-06T07:03:22.965230Z"
    }
   },
   "cell_type": "code",
   "source": [
    "user_input = \"이번 주말에 할 수 있는 취미 활동을 추천해주세요.\"\n",
    "response = generate_conversation(user_input)\n",
    "print(response)"
   ],
   "id": "b21aac61d3dea342",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "여러분의 취미를 고려하여 다양한 주말 활동을 추천합니다:\n",
      "\n",
      "1. 산책: 도시에서 멀리 떨어진 곳으로 이동하는 것이 좋습니다. 자연을 감상하고 바람을 느끼며 휴식을 취할 수 있습니다.\n",
      "\n",
      "2. 요리: 새롭게 만드는 요리를 시도하세요. 인터넷에서 레시피를 찾거나 가족과 함께 만들 수 있습니다. 맛있는 음식은 즐거운 시간을 보낼 수 있어요!\n",
      "\n",
      "3. 운동: 주말에는 스트레스를 해소하기 위해 운동을 하세요. 자전거, 피트니스 센터 또는 친구와 함께 야외에서 운동을 시작하세요.\n",
      "\n",
      "4. 여행: 가까운 장소나 멀리 가서 새로운 장소를 방문하세요. 새로운 경험을 얻고 새로운 사람들을 만나기 위한 좋은 기회가 될 수 있습니다.\n",
      "\n",
      "5. 미술: 도안, 그림, 사진 등을 그려보세요. 창의적인 능력을 발휘하면서 재미를 누릴 수 있습니다.\n",
      "\n",
      "6. 게임: 친구들과 온라인 게임이나 보드 게임을 하세요. 가족과 함께하면 더 재미있을 수 있습니다.\n",
      "\n",
      "7. 음악: 악기를 배우거나 노래를 부르세요. 음악은 스트레스를 해소하고 즐거움을 주는 것으로 알려져 있습니다.\n",
      "\n",
      "8. 식물 키우기: 집에서 식물을 키워보세요. 이로 인해 집 안의 공기 청정 효과와 함께 스트레스를 줄일 수 있습니다.\n",
      "\n",
      "9. 독서: 책을 읽어보세요. 새로운 지식과 이야기를 얻으면 좋습니다.\n",
      "\n",
      "10. 영화보기: 최근 개봉한 영화를 볼 수도 있고, 오래된 클래식 영화도 재미있을 수 있습니다.\n",
      "\n",
      "11. 일상 생활에서 불필요한 물품을 정리하세요. 이것은 공간을 정리하고 정신적으로도 긍정적인 영향을 미칠 수 있습니다.\n",
      "\n",
      "12. 여행 계획을 세우세요. 가까운 장소나 멀리 가서 새로운 장소를 방문하려고 계획하세요. 새로운 경험을 얻고 새로운 사람들을 만나기 위한 좋은 기회가 될 수 있습니다.\n",
      "\n",
      "13. 커피 테라스에서 시간을 보내세요. 따뜻한 커피와 좋은 분위기로 휴식을 취하세요.\n",
      "\n",
      "14. 요리 강습: 요리에 관심이 있다면 요리 강습 프로그램을 따라해보세요. 새로운 요리를 배울 수 있으며, 새로운 요리를 만들어 가족과 함께 먹을 수 있습니다.\n",
      "\n",
      "15. 캠핑: 가까운 곳에서 캠핑을 하거나 멀리 가서 캠핑을 하세요. 야외에서 휴식을 취하며 새로운 경험을 얻을 수 있습니다.\n",
      "\n",
      "16. 음악 콘서트: 지역에서 열리는 무료 음악 콘서트에 참석하세요. 새로운 음악을 듣고 새로운 사람들을 만나기 위한 좋은 기회가 될 수 있습니다.\n",
      "\n",
      "17. 필드 스포츠: 친구들과 야외에서 필드 스포츠 활동을 시작하세요. 야구, 축구, 농구 등 다양한 종목을 선택할 수 있습니다.\n",
      "\n",
      "18. 요리 경연 대회: 요리에 관심이 있다면 요리 경연 대회에 참가하세요. 새로운 요리를 만들어 가족과 함께 먹을 수 있습니다.\n",
      "\n",
      "19. 차량 여행: 가까운 장소나 멀리 가서 차량 여행을 계획하세요. 새로운 장소를 방문하고 새로운 사람들을 만나기 위한 좋은 기회가 될 수 있습니다.\n",
      "\n",
      "20. 플랜트 나잇: 꽃과 식물을 심고 관리하세요. 자연과 연결되는 계절적인 활동이며, 새로운 경험을 얻을 수 있습니다.\n",
      "\n",
      "이러한 주말 활동 중 하나를 선택하시면 좋은 시간을 보낼 수 있을 것입니다!<|eot_id|>\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T07:04:02.786042Z",
     "start_time": "2024-05-06T07:03:54.310372Z"
    }
   },
   "cell_type": "code",
   "source": [
    "user_input = \"추천한 취미 활동 중 건강에 도움이 되는 것은 무엇인가요?\"\n",
    "response = generate_conversation(user_input)\n",
    "print(response)"
   ],
   "id": "a9980840ff668db6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Recommendations for healthy hobbies include:\n",
      "\n",
      "1. Exercise: Cycling, fitness center, outdoor sports, etc.\n",
      "2. Camping: Outdoor activities can be beneficial for physical and mental health.\n",
      "3. Yoga or meditation: Mindfulness exercises that improve overall well-being.\n",
      "4. Reading books: Intellectual stimulation can reduce stress and improve mental health.\n",
      "5. Traveling: Explore new places and cultures to broaden your horizons and gain new experiences.\n",
      "6. Gardening: Planting flowers and plants can be therapeutic and provide a sense of accomplishment.\n",
      "7. Cooking: Healthy eating habits can be developed through cooking at home with fresh ingredients.\n",
      "8. Photography: Capturing moments and beauty in nature can be a great way to relax and appreciate the world around you.\n",
      "\n",
      "These activities are not only fun but also have benefits for our physical and mental health. Remember to choose activities that bring joy and fulfillment while respecting your body's limitations.<|eot_id|>\n"
     ]
    }
   ],
   "execution_count": 19
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
