{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Login to Hugging Face"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "98126af063c251e0"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-06T07:08:44.550914Z",
     "start_time": "2024-05-06T07:08:43.920184Z"
    }
   },
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from huggingface_hub import login\n",
    "\n",
    "load_dotenv()\n",
    "token = os.getenv(\"HUGGINGFACE_TOKEN\")\n",
    "login(\n",
    "    token=token, # ADD YOUR TOKEN HERE\n",
    "    add_to_git_credential=True\n",
    ")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token is valid (permission: write).\n",
      "Your token has been saved in your configured git credential helpers (store).\n",
      "Your token has been saved to /home/pathfinder/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Imports"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f21a95a142b71e93"
  },
  {
   "cell_type": "code",
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "# pytorch\n",
    "import torch\n",
    "\n",
    "# huggingface\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    BitsAndBytesConfig\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T07:08:46.089185Z",
     "start_time": "2024-05-06T07:08:44.552758Z"
    }
   },
   "id": "108874429856aabe",
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Device"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2f29fda50194a3fe"
  },
  {
   "cell_type": "code",
   "source": [
    "# Device setup\n",
    "device = (\n",
    "    \"cuda:0\" if torch.cuda.is_available() else # Nvidia GPU\n",
    "    \"mps\" if torch.backends.mps.is_available() else # Apple Silicon GPU\n",
    "    \"cpu\"\n",
    ")\n",
    "print(f\"Device = {device}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T07:08:46.493266Z",
     "start_time": "2024-05-06T07:08:46.090356Z"
    }
   },
   "id": "5555b5512cd1a1dd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device = cuda:0\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T07:08:46.556243Z",
     "start_time": "2024-05-06T07:08:46.495217Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Flash Attention Implementation\n",
    "if device == \"cuda:0\":\n",
    "    if torch.cuda.get_device_capability()[0] >= 8: # Ampere, Ada, or Hopper GPUs\n",
    "        attn_implementation = \"flash_attention_2\"\n",
    "        torch_dtype = torch.bfloat16\n",
    "    else:\n",
    "        attn_implementation = \"eager\"\n",
    "        torch_dtype = torch.float16\n",
    "else:\n",
    "    attn_implementation = \"eager\"\n",
    "    torch_dtype = torch.float32\n",
    "print(f\"Attention Implementation = {attn_implementation}\")"
   ],
   "id": "f0e72bfaf9471e1e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention Implementation = flash_attention_2\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Hyperparameters"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b452e9ab5ed33883"
  },
  {
   "cell_type": "code",
   "source": [
    "################################################################################\n",
    "# Tokenizer parameters\n",
    "################################################################################\n",
    "max_length=8192\n",
    "padding=\"do_not_pad\" # \"max_length\", \"longest\", \"do_not_pad\"\n",
    "truncation=True\n",
    "\n",
    "################################################################################\n",
    "# Generation parameters\n",
    "################################################################################\n",
    "num_return_sequences=1\n",
    "max_new_tokens=1024\n",
    "do_sample=True # True for sampling, False for greedy decoding\n",
    "temperature=0.6\n",
    "top_k=0 # not recommended\n",
    "top_p=0.9\n",
    "repetition_penalty=1.1\n",
    "\n",
    "################################################################################\n",
    "# bitsandbytes parameters\n",
    "################################################################################\n",
    "load_in_4bit=True\n",
    "bnb_4bit_compute_dtype=torch_dtype\n",
    "bnb_4bit_quant_type=\"nf4\" # \"nf4\", #fp4\"\n",
    "bnb_4bit_use_double_quant=True"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T07:08:46.560900Z",
     "start_time": "2024-05-06T07:08:46.557592Z"
    }
   },
   "id": "778930f2cc7c1224",
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "14f31dc8d02b7233"
  },
  {
   "cell_type": "code",
   "source": [
    "# Model List\n",
    "\n",
    "# gemma variants\n",
    "# \"google/gemma-1.1-7b-it\"\n",
    "# \"google/codegemma-7b-it\"\n",
    "\n",
    "# llama variants\n",
    "# \"meta-llama/Meta-Llama-3-8B\" // downloaded\n",
    "# \"meta-llama/Meta-Llama-3-8B-Instruct\" // downloaded\n",
    "# \"codellama/CodeLlama-7b-Instruct-hf\"\n",
    "# \"PathFinderKR/Waktaverse-Llama-3-KO-8B-Instruct\"\n",
    "\n",
    "# mistral variants\n",
    "# \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "\n",
    "# openELM variants\n",
    "# \"apple/OpenELM-3B-Instruct\" // downloaded\n",
    "\n",
    "# solar variants\n",
    "# \"upstage/SOLAR-10.7B-Instruct-v1.0\" // downloaded\n",
    "# \"PathFinderKR/Waktaverse-SOLAR-KO-10.7B-Instruct\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T07:08:46.569139Z",
     "start_time": "2024-05-06T07:08:46.562099Z"
    }
   },
   "id": "3a8abd326253137e",
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "source": "model_id = \"PathFinderKR/Waktaverse-Llama-3-KO-8B-Instruct\"",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T07:08:46.576517Z",
     "start_time": "2024-05-06T07:08:46.570439Z"
    }
   },
   "id": "352852804a6a38db",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T07:08:47.138161Z",
     "start_time": "2024-05-06T07:08:46.577785Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "tokenizer.padding_side = \"right\""
   ],
   "id": "3a1ea98f6eba58f8",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T07:08:47.144726Z",
     "start_time": "2024-05-06T07:08:47.139451Z"
    }
   },
   "cell_type": "code",
   "source": [
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=load_in_4bit,\n",
    "    bnb_4bit_compute_dtype=bnb_4bit_compute_dtype,\n",
    "    bnb_4bit_quant_type=bnb_4bit_quant_type,\n",
    "    bnb_4bit_use_double_quant=bnb_4bit_use_double_quant\n",
    ")"
   ],
   "id": "be26d2efc49fcbf6",
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    device_map=device,\n",
    "    attn_implementation=attn_implementation,\n",
    "    torch_dtype=torch_dtype,\n",
    "    quantization_config=quantization_config\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T07:08:57.540570Z",
     "start_time": "2024-05-06T07:08:47.146651Z"
    }
   },
   "id": "f5f879cefa518232",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b91355fc41204b66b04ca9f463452c69"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T07:08:57.545588Z",
     "start_time": "2024-05-06T07:08:57.541609Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Display the model architecture\n",
    "display(Markdown(f'```{model}```'))"
   ],
   "id": "9fedd479c0a753a0",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "```LlamaForCausalLM(\n  (model): LlamaModel(\n    (embed_tokens): Embedding(128256, 4096)\n    (layers): ModuleList(\n      (0-31): 32 x LlamaDecoderLayer(\n        (self_attn): LlamaFlashAttention2(\n          (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n          (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n          (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n          (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n          (rotary_emb): LlamaRotaryEmbedding()\n        )\n        (mlp): LlamaMLP(\n          (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n          (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n          (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n          (act_fn): SiLU()\n        )\n        (input_layernorm): LlamaRMSNorm()\n        (post_attention_layernorm): LlamaRMSNorm()\n      )\n    )\n    (norm): LlamaRMSNorm()\n  )\n  (lm_head): Linear(in_features=4096, out_features=128256, bias=False)\n)```"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Inference",
   "id": "12b7e2fc01311961"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T07:08:57.552687Z",
     "start_time": "2024-05-06T07:08:57.546496Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def generate_response(system ,user):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system},\n",
    "        {\"role\": \"user\", \"content\": user}\n",
    "    ]\n",
    "    prompt = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=False\n",
    "    )\n",
    "    \n",
    "    input_ids = tokenizer.encode(\n",
    "        prompt,\n",
    "        max_length=max_length,\n",
    "        padding=padding,\n",
    "        truncation=truncation,\n",
    "        add_special_tokens=False,\n",
    "        return_tensors=\"pt\"\n",
    "    ).to(device)\n",
    "    \n",
    "    outputs = model.generate(\n",
    "        input_ids=input_ids,\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "        num_return_sequences=num_return_sequences,\n",
    "        max_new_tokens=max_new_tokens,\n",
    "        do_sample=do_sample,\n",
    "        temperature=temperature,\n",
    "        top_k=top_k,\n",
    "        top_p=top_p,\n",
    "        repetition_penalty=repetition_penalty\n",
    "    )\n",
    "    \n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=False)"
   ],
   "id": "1c849786ee0282d8",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T07:08:57.559790Z",
     "start_time": "2024-05-06T07:08:57.553849Z"
    }
   },
   "cell_type": "code",
   "source": "system_prompt = \"다음 지시사항에 대한 응답을 작성해주세요.\"",
   "id": "36dd54c1250609de",
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "source": "user_prompt = \"피보나치 수열에 대해 설명해주세요.\"",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T07:08:57.566780Z",
     "start_time": "2024-05-06T07:08:57.560896Z"
    }
   },
   "id": "7e2c71d41fed35b0",
   "outputs": [],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "source": [
    "response = generate_response(system_prompt, user_prompt)\n",
    "print(response)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T07:09:21.510199Z",
     "start_time": "2024-05-06T07:08:57.567783Z"
    }
   },
   "id": "aac19ad24cb1cca2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "다음 지시사항에 대한 응답을 작성해주세요.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "피보나치 수열에 대해 설명해주세요.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\"\n",
      "\n",
      "피보나치 수열은 0과 1로 시작하며, 각 항이 이전 두 항의 합으로 계산되는 수열입니다. 이 수열에는 무한히 많은 숫자가 포함되어 있으며, 첫 번째 몇 개의 항은 다음과 같습니다:\n",
      "\n",
      "0, 1, 1, 2, 3, 5, 8, 13, 21, 34, 55, 89, 144, 233, 377, 610, 985, 1597, 2584, 4181, 6765, 10946, 17711, 28657, 46368, 75025, 121393, 196418,...\n",
      "\n",
      "피보나치 수열은 수학적 구조와 재귀 관계를 가지고 있습니다. 예를 들어, 피보나치 수열의 n번째 항은 (n-1)번째와 (n-2)번째 항의 합입니다.\n",
      "\n",
      "피보나치 수열은 여러 분야에서 사용됩니다. 예를 들어, 화폐의 배치 문제에서는 피보나치 수열이 사용될 수 있습니다. 또한, 기하학에서 피보나치 수열은 점의 배열에 사용될 수 있습니다.\n",
      "\n",
      "피보나치 수열은 수학자 레온아르도 피보나치의 이름을 따서 명명되었습니다. 그는 이 수열을 처음 발견하고 기록했습니다. 피보나치 수열은 유럽에서 인기를 끌었으며, 다른 문화에서도 독특한 형태로 나타납니다.\n",
      "\n",
      "피보나치 수열은 컴퓨터 프로그램과 알고리즘에도 적용될 수 있습니다. 예를 들어, 피보나치 수열을 계산하는 알고리즘이 있습니다. 이러한 알고리즘은 현재까지 매우 효율적이며, 대규모 계산에 사용됩니다. 피보나치 수열은 수학적 구조와 재귀 관계를 가지고 있기 때문에 프로그래밍 언어에서도 자주 사용됩니다.\n",
      "\n",
      "요약하면, 피보나치 수열은 수학적 구조와 재귀 관계를 가진 수열로, 다양한 분야에서 사용되고 있습니다. 이 수열은 컴퓨터 프로그램과 알고리즘에도 적용될 수 있으며, 대규모 계산에 사용됩니다. 피보나치 수열은 수학자 레온아르도 피보나치의 이름을 따서 명명되었으며, 그의 업적으로 유명합니다.<|eot_id|>\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Multi-turn Conversation",
   "id": "9377ca2ee01e9f56"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T07:09:21.514Z",
     "start_time": "2024-05-06T07:09:21.511722Z"
    }
   },
   "cell_type": "code",
   "source": [
    "system_prompt = \"다음 지시사항에 대한 응답을 작성해주세요.\"\n",
    "conversation_history = [{\"role\": \"system\", \"content\": system_prompt}]"
   ],
   "id": "755414328bf0bb36",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T07:09:21.521248Z",
     "start_time": "2024-05-06T07:09:21.514881Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def generate_conversation(user):\n",
    "    global conversation_history\n",
    "    conversation_history.append({\"role\": \"user\", \"content\": user})\n",
    "    prompt = tokenizer.apply_chat_template(\n",
    "        conversation_history,\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=False\n",
    "    )\n",
    "    \n",
    "    input_ids = tokenizer.encode(\n",
    "        prompt,\n",
    "        max_length=max_length,\n",
    "        padding=padding,\n",
    "        truncation=truncation,\n",
    "        add_special_tokens=False,\n",
    "        return_tensors=\"pt\"\n",
    "    ).to(device)\n",
    "    \n",
    "    outputs = model.generate(\n",
    "        input_ids=input_ids,\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "        num_return_sequences=num_return_sequences,\n",
    "        max_new_tokens=max_new_tokens,\n",
    "        do_sample=do_sample,\n",
    "        temperature=temperature,\n",
    "        top_k=top_k,\n",
    "        top_p=top_p,\n",
    "        repetition_penalty=repetition_penalty\n",
    "    )\n",
    "    \n",
    "    assistant_response = tokenizer.decode(outputs[0], skip_special_tokens=False).split(\"<|start_header_id|>assistant<|end_header_id|>\")[-1]\n",
    "    conversation_history.append({\"role\": \"assistant\", \"content\": assistant_response})\n",
    "    return assistant_response"
   ],
   "id": "fcb7ac53017a73f",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T07:09:45.019268Z",
     "start_time": "2024-05-06T07:09:21.522201Z"
    }
   },
   "cell_type": "code",
   "source": [
    "user_input = \"이번 주말에 할 수 있는 취미 활동을 추천해주세요.\"\n",
    "response = generate_conversation(user_input)\n",
    "print(response)"
   ],
   "id": "b21aac61d3dea342",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "안녕하세요! 다양한 취미 활동들이 있습니다. 이번 주말에 어떤 활동을 하실지 추천해드리겠습니다.\n",
      "\n",
      "1. 야외 캠핑: 자연 속에서 휴식을 즐기며 별을 볼 수 있는 좋은 기회입니다.\n",
      "2. 산책: 도시를 벗어나서 산책을 해보세요. 자연의 아름다움과 함께 건강한 시간을 보낼 수 있습니다.\n",
      "3. 음악 연주: 악기를 배우고 연습하여 가족들과 함께 음악을 즐길 수 있습니다.\n",
      "4. 요리: 새로운 레시피를 찾아 맛있는 음식을 만들어보세요.\n",
      "5. 그림 그리기: 색감이나 윤곽 등 다양한 방법으로 그림을 그려보세요.\n",
      "6. 사진 촬영: 카메라를 가지고 나가 자연의 아름다움을 찍어보세요.\n",
      "7. 운동: 달리거나 조깅을 하여 건강한 몸을 유지할 수 있습니다.\n",
      "8. 독서: 책을 읽으면 새로운 지식과 생각을 얻을 수 있습니다.\n",
      "9. 여행: 가까운 곳으로 여행을 가서 새로운 장소와 사람들을 만나볼 수 있습니다.\n",
      "\n",
      "이러한 활동 중 하나를 선택하시면 좋습니다. 자신에게 맞는 취미를 찾으셔서 즐거운 시간을 보내시기 바랍니다. \n",
      "\n",
      "추가 답변:\n",
      "또 다른 활동으로는, 친구나 가족과 함께 영화를 시청하거나 게임을 즐겨보세요. 또한, 직접 만든 음식을 나누고 싶은 경우에는 홈 파티를 열어보세요. 이러한 활동들은 모두 서로 다른 경험을 제공하며, 새로운 것에 도전해보는 것은 좋습니다. \n",
      "\n",
      "참고로, 취미는 개인적인 것이므로 자신의 취향에 따라 선택하면 됩니다.<|end_of_text|>\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T07:10:18.977594Z",
     "start_time": "2024-05-06T07:09:45.020500Z"
    }
   },
   "cell_type": "code",
   "source": [
    "user_input = \"추천한 취미 활동 중 건강에 도움이 되는 것은 무엇인가요?\"\n",
    "response = generate_conversation(user_input)\n",
    "print(response)"
   ],
   "id": "a9980840ff668db6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "저는 여러 가지 취미 활동을 추천했지만, 건강에 도움이 되는 것으로 인지되는 것은 다음과 같습니다:\n",
      "\n",
      "1. 산책: 도시를 떠나 자연속으로 나가서 산책을 하면 몸과 마음이 편안해질 수 있습니다. 산책하면서 자연을 감상하고 신선한 공기를 마시는 것도 좋습니다.\n",
      "\n",
      "2. 댄스: 춤을 추면서도 몸과 마음이 움직이는 운동입니다. 춤을 추는 동안 스트레스를 풀고, 신체적으로도 근육을 튼튼하게 만들 수 있습니다.\n",
      "\n",
      "3. 요리: 요리를 통해 식재료와 영양소를 알게 되고, 건강한 식사를 할 수 있습니다. 또한, 요리에 관심이 생기면 가정에서 필요한 식량을 직접 준비할 수 있어 경제적 이점도 있습니다.\n",
      "\n",
      "4. 독서: 책을 읽으면 새로운 지식과 정보를 얻을 수 있고, 독서를 통해 정신적으로도 자극을 받을 수 있습니다. 독서를 좋아하다면 매일 한 시간 정도 시간을 내서 책을 읽어보세요.\n",
      "\n",
      "5. 사진 촬영: 사진을 찍으면 사진을 보면 새로운 것을 발견하고, 사진을 찍는 동안에도 중요한 순간을 놓치지 않도록 합니다. 또한, 사진 촬영을 좋아하다면 사진을 찍는 동안에도 신체적으로도 좋은 운동이 될 수 있습니다.\n",
      "\n",
      "6. 음악: 음악을 들으며 마음이 편안해지고, 음악을 부르거나 기타를 치며 재능을 발휘하는 것도 좋은 취미입니다.\n",
      "\n",
      "7. 운동: 다양한 종류의 운동을 하는 것은 몸에 좋으며, 적절한 운동량을 유지하는 것이 중요합니다. 운동을 즐겁게 하려면 적절한 운동량을 유지해야 합니다.\n",
      "\n",
      "8. 미술: 미술을 하면서 창작성을 키우고, 예술을 통해 자신의 표현력을 개발할 수 있습니다.\n",
      "\n",
      "9. 여행: 여행을 하면서 새로운 문화와 사람들에 대해 알게 되고, 다양한 경험을 통해 성장할 수 있습니다.\n",
      "\n",
      "10. 대화: 대화를 통해 새로운 사람들과 대화를 나누고, 새로운 것을 배울 수도 있습니다.\n",
      "\n",
      "위의 활동들 중 어느것도 건강에 도움이 된다는 것은 아닙니다. 하지만, 저는 모든 활동이 건강에 도움이 될 수 있다는 믿음을 가지고 있습니다. 이러한 활동들을 통해 건강을 유지하고, 성장하는 데 도움이 될 것입니다. \n",
      "\n",
      "참고로, 취미란 개인적인 취미를 말하며, 취미활동이 건강에 도움이 된다는 것은 누구나 다르다고 생각됩니다. 저는 이러한 활동들을 통해 개인적인 만족을 느끼고, 새로운 것을 배우고, 성장하는 데 도움이 될 수 있다고 믿습니다. \n",
      "\n",
      " 추가 답변:\n",
      "어떤 활동이 건강에 도움이 되는지는 개인마다 다를 수 있으므로, 각각의 활동을 자세히 살펴보기 바래요.<|end_of_text|>\n"
     ]
    }
   ],
   "execution_count": 19
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
