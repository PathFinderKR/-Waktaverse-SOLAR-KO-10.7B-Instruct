{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Importing Libraries",
   "id": "c8f33a502600bec9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-30T10:16:06.805829Z",
     "start_time": "2024-05-30T10:16:02.784716Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "# pytorch\n",
    "import torch\n",
    "\n",
    "# huggingface\n",
    "from huggingface_hub import login\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, TrainingArguments\n",
    "from peft import prepare_model_for_kbit_training, LoraConfig, get_peft_model\n",
    "from trl import SFTTrainer\n",
    "from datasets import load_dataset\n",
    "\n",
    "# wandb\n",
    "import wandb"
   ],
   "id": "6c3dab257ca35b13",
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Login to Hugging Face"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7c2f9104252a4bb"
  },
  {
   "cell_type": "code",
   "source": [
    "load_dotenv()\n",
    "token = os.getenv(\"HUGGINGFACE_TOKEN\")\n",
    "login(\n",
    "    token=token,  # ADD YOUR TOKEN HERE\n",
    "    add_to_git_credential=True\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-30T10:16:07.137280Z",
     "start_time": "2024-05-30T10:16:06.807358Z"
    }
   },
   "id": "4eee58c68eb02d85",
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "model_name = \"Waktaverse-Llama-2-KO-7B-Instruct\"  # ADD YOUR MODEL NAME HERE\n",
    "username = \"PathFinderKR\"  # ADD YOUR USERNAME HERE\n",
    "repo_id = f\"{username}/{model_name}\"  # repository id"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-31T02:16:43.830351Z",
     "start_time": "2024-05-31T02:16:43.825332Z"
    }
   },
   "id": "cd4c26069d51a597",
   "execution_count": 37,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Login to Weights & Biases",
   "id": "45b93503027bc62"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-30T10:16:11.818165Z",
     "start_time": "2024-05-30T10:16:07.142414Z"
    }
   },
   "cell_type": "code",
   "source": [
    "api_key = os.getenv(\"WANDB_API_KEY\")\n",
    "wandb.login(\n",
    "    key=api_key  # ADD YOUR API KEY HERE\n",
    ")\n",
    "wandb.init(project=model_name)"
   ],
   "id": "bd9885bdc6270f76",
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Device"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e512d30c21d105c2"
  },
  {
   "cell_type": "code",
   "source": [
    "# Device setup\n",
    "device = (\n",
    "    \"cuda:0\" if torch.cuda.is_available() else # Nvidia GPU\n",
    "    \"mps\" if torch.backends.mps.is_available() else # Apple Silicon GPU\n",
    "    \"cpu\"\n",
    ")\n",
    "print(f\"Device = {device}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-30T10:16:11.823359Z",
     "start_time": "2024-05-30T10:16:11.819442Z"
    }
   },
   "id": "fdf3a2a4e0e31554",
   "execution_count": 5,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-30T10:16:11.831803Z",
     "start_time": "2024-05-30T10:16:11.824316Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Flash Attention Implementation\n",
    "if device == \"cuda:0\":\n",
    "    if torch.cuda.get_device_capability()[0] >= 8: # Ampere, Ada, or Hopper GPUs\n",
    "        attn_implementation = \"flash_attention_2\"\n",
    "        torch_dtype = torch.bfloat16\n",
    "    else:\n",
    "        attn_implementation = \"eager\"\n",
    "        torch_dtype = torch.float16\n",
    "else:\n",
    "    attn_implementation = \"eager\"\n",
    "    torch_dtype = torch.float32\n",
    "print(f\"Attention Implementation = {attn_implementation}\")"
   ],
   "id": "d96a4ad9abc2d0ed",
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Hyperparameters"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "84ce31a12e172a64"
  },
  {
   "cell_type": "code",
   "source": [
    "################################################################################\n",
    "# Tokenizer parameters\n",
    "################################################################################\n",
    "max_length=4096\n",
    "padding=\"do_not_pad\"  # \"max_length\", \"longest\", \"do_not_pad\"\n",
    "truncation=True\n",
    "\n",
    "################################################################################\n",
    "# Generation parameters\n",
    "################################################################################\n",
    "num_return_sequences=1\n",
    "max_new_tokens=1024\n",
    "do_sample=True  # True for sampling, False for greedy decoding\n",
    "temperature=0.6\n",
    "top_p=0.9\n",
    "repetition_penalty=1.1\n",
    "\n",
    "################################################################################\n",
    "# bitsandbytes parameters\n",
    "################################################################################\n",
    "load_in_4bit=True\n",
    "bnb_4bit_compute_dtype=torch_dtype\n",
    "bnb_4bit_quant_type=\"nf4\"  # \"nf4\", #fp4\"\n",
    "bnb_4bit_use_double_quant=True\n",
    "\n",
    "################################################################################\n",
    "# LoRA parameters\n",
    "################################################################################\n",
    "task_type=\"CAUSAL_LM\"\n",
    "target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"]\n",
    "r=16\n",
    "lora_alpha=32\n",
    "lora_dropout=0.1\n",
    "bias=\"none\"\n",
    "\n",
    "################################################################################\n",
    "# Training parameters\n",
    "################################################################################\n",
    "output_dir=\"./results\"\n",
    "logging_dir=\"./logs\"\n",
    "save_strategy=\"epoch\"\n",
    "logging_strategy=\"steps\"  # \"steps\", \"epoch\"\n",
    "if logging_strategy == \"steps\":\n",
    "    logging_steps=10\n",
    "else:\n",
    "    logging_steps=None\n",
    "save_total_limit=1\n",
    "report_to=\"wandb\"\n",
    "\n",
    "num_train_epochs=1\n",
    "per_device_train_batch_size=2\n",
    "gradient_accumulation_steps=2\n",
    "gradient_checkpointing=True\n",
    "bf16=True\n",
    "learning_rate=2e-5\n",
    "lr_scheduler_type=\"cosine\"  # \"constant\", \"linear\", \"cosine\"\n",
    "warmup_ratio=0.1\n",
    "optim = \"paged_adamw_32bit\"\n",
    "weight_decay=0.1\n",
    "\n",
    "################################################################################\n",
    "# SFT parameters\n",
    "################################################################################\n",
    "max_seq_length=4096\n",
    "packing=True"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-30T10:16:11.839882Z",
     "start_time": "2024-05-30T10:16:11.832946Z"
    }
   },
   "id": "dc1a272a1c0b7ce4",
   "execution_count": 7,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Tokenizer",
   "id": "516ea451de4ded55"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-30T10:16:11.848018Z",
     "start_time": "2024-05-30T10:16:11.840949Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Korean Tokenizer ID\n",
    "tokenizer_id = \"meta-llama/Llama-2-7b-chat-hf\""
   ],
   "id": "5c5b21448100815d",
   "execution_count": 8,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-30T10:16:12.126555Z",
     "start_time": "2024-05-30T10:16:11.849370Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_id)"
   ],
   "id": "c50c6ca52d903d8d",
   "execution_count": 9,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-30T10:16:12.131045Z",
     "start_time": "2024-05-30T10:16:12.128265Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Add padding token\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ],
   "id": "d27e6237718edd67",
   "execution_count": 10,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-30T10:16:12.141605Z",
     "start_time": "2024-05-30T10:16:12.132222Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Vocabulary size\n",
    "print(f\"Vocabulary size: {len(tokenizer)}\")\n",
    "# Special tokens\n",
    "print(f\"Special tokens: {tokenizer.special_tokens_map}\")\n",
    "# Padding side\n",
    "print(f\"Padding side: {tokenizer.padding_side}\")"
   ],
   "id": "59ccccfd53102df8",
   "execution_count": 11,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-30T10:16:12.148041Z",
     "start_time": "2024-05-30T10:16:12.142805Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Display the tokenizer configuration\n",
    "display(Markdown(f'```{tokenizer}```'))"
   ],
   "id": "b67c01467026b872",
   "execution_count": 12,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Model",
   "id": "fb5c1161ebd9df8a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-30T10:16:12.153763Z",
     "start_time": "2024-05-30T10:16:12.149116Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Model ID for base model\n",
    "model_id = \"meta-llama/Llama-2-7b-chat-hf\""
   ],
   "id": "eb8160d8919cdaeb",
   "execution_count": 13,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-30T10:16:12.162077Z",
     "start_time": "2024-05-30T10:16:12.154886Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Quantization\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=load_in_4bit,\n",
    "    bnb_4bit_compute_dtype=bnb_4bit_compute_dtype,\n",
    "    bnb_4bit_quant_type=bnb_4bit_quant_type,\n",
    "    bnb_4bit_use_double_quant=bnb_4bit_use_double_quant\n",
    ")"
   ],
   "id": "69d30da42bd6cf7b",
   "execution_count": 14,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-30T10:16:21.306339Z",
     "start_time": "2024-05-30T10:16:12.163223Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load model\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    device_map=device,\n",
    "    attn_implementation=attn_implementation,\n",
    "    torch_dtype=torch_dtype,\n",
    "    quantization_config=quantization_config,\n",
    "    low_cpu_mem_usage=True\n",
    ")"
   ],
   "id": "978055543828a014",
   "execution_count": 15,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-30T10:16:21.312438Z",
     "start_time": "2024-05-30T10:16:21.307546Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Display the model architecture\n",
    "display(Markdown(f'```{model}```'))"
   ],
   "id": "e224c50f423698e1",
   "execution_count": 16,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-30T10:16:21.320620Z",
     "start_time": "2024-05-30T10:16:21.313523Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Number of parameters\n",
    "print(f\"Number of parameters (in billions): {model.num_parameters() / 1e9:.2f}\")"
   ],
   "id": "8cee59fa37c5f0bc",
   "execution_count": 17,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Dataset",
   "id": "a4042d4b7cd2d0fd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-30T10:16:21.327158Z",
     "start_time": "2024-05-30T10:16:21.321632Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Dataset ID\n",
    "dataset_id = \"beomi/KoAlpaca-v1.1a\""
   ],
   "id": "4cd4661dab93e4c8",
   "execution_count": 18,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Load the dataset\n",
    "dataset = load_dataset(dataset_id)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-30T10:16:24.984147Z",
     "start_time": "2024-05-30T10:16:21.328236Z"
    }
   },
   "id": "4373ef1c6a85e5e2",
   "execution_count": 19,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Dataset information\n",
    "dataset"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-30T10:16:24.991141Z",
     "start_time": "2024-05-30T10:16:24.985221Z"
    }
   },
   "id": "aabd9487c235d581",
   "execution_count": 20,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-30T10:16:24.998995Z",
     "start_time": "2024-05-30T10:16:24.992164Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Dataset example\n",
    "print(dataset[\"train\"][0][\"instruction\"])\n",
    "print(dataset[\"train\"][0][\"output\"])"
   ],
   "id": "4cf2c30835e34a13",
   "execution_count": 21,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Preprocessing",
   "id": "6e54c42138a256a8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-30T10:16:25.009849Z",
     "start_time": "2024-05-30T10:16:25.000124Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Shuffle the dataset\n",
    "dataset = dataset.shuffle(seed=42)"
   ],
   "id": "c177f01dab4ce2a0",
   "execution_count": 22,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-30T10:16:25.060390Z",
     "start_time": "2024-05-30T10:16:25.011070Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Alpaca dataset format: \n",
    "# {\"instruction\": [str],\n",
    "#   \"input\": [str],\n",
    "#   \"output\": [str]}\n",
    "\n",
    "# Korean\n",
    "def prompt_without_input(example):\n",
    "    text = (\n",
    "        \"<s>[INST]<<SYS>>\\n\"\n",
    "        \"다음은 작업을 설명하는 지시사항입니다. 요청을 적절하게 완료하는 응답을 작성하세요.\\n\"\n",
    "        \"<</SYS>>\\n\\n\"\n",
    "\n",
    "        f\"{example['instruction']}[/INST]{example['output']}</s>\"\n",
    "        )\n",
    "    return {'text': text}\n",
    "\n",
    "# Apply the alpaca prompt to the dataset\n",
    "dataset = dataset.map(prompt_without_input)"
   ],
   "id": "fd3aaf9eac48027a",
   "execution_count": 23,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-30T10:16:25.064838Z",
     "start_time": "2024-05-30T10:16:25.061369Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Display the first example\n",
    "print(dataset[\"train\"][0][\"text\"])"
   ],
   "id": "2161788a1129971e",
   "execution_count": 24,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Supervised Fine-Tuning (LoRA)",
   "id": "b43eba6780d2e557"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-30T10:16:25.209240Z",
     "start_time": "2024-05-30T10:16:25.066008Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Prepare model for kbit training\n",
    "model = prepare_model_for_kbit_training(model)"
   ],
   "id": "84c74906e328d032",
   "execution_count": 25,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-30T10:16:25.213124Z",
     "start_time": "2024-05-30T10:16:25.210336Z"
    }
   },
   "cell_type": "code",
   "source": [
    "lora_config = LoraConfig(\n",
    "    task_type=task_type,\n",
    "    target_modules=target_modules,\n",
    "    r=r,\n",
    "    lora_alpha=lora_alpha,\n",
    "    lora_dropout=lora_dropout,\n",
    "    bias=bias\n",
    ")"
   ],
   "id": "75ef555547f56ebf",
   "execution_count": 26,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-30T10:16:26.841910Z",
     "start_time": "2024-05-30T10:16:25.214115Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Number of trainable parameters\n",
    "model = get_peft_model(model, lora_config)\n",
    "model.print_trainable_parameters()"
   ],
   "id": "e4d2d7975a1ff14e",
   "execution_count": 27,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-30T10:16:26.927964Z",
     "start_time": "2024-05-30T10:16:26.844100Z"
    }
   },
   "cell_type": "code",
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    logging_dir=logging_dir,\n",
    "    save_strategy=save_strategy,\n",
    "    logging_strategy=logging_strategy,\n",
    "    logging_steps=logging_steps,\n",
    "    save_total_limit=save_total_limit,\n",
    "    report_to=report_to,\n",
    "    \n",
    "    num_train_epochs=num_train_epochs,\n",
    "    per_device_train_batch_size=per_device_train_batch_size,\n",
    "    gradient_accumulation_steps=gradient_accumulation_steps,\n",
    "    gradient_checkpointing=gradient_checkpointing,\n",
    "    bf16=bf16,\n",
    "    learning_rate=learning_rate,\n",
    "    lr_scheduler_type=lr_scheduler_type,\n",
    "    warmup_ratio=warmup_ratio,\n",
    "    optim=optim,\n",
    "    weight_decay=weight_decay\n",
    ")"
   ],
   "id": "2e29a9a3ca3b96b1",
   "execution_count": 28,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    peft_config=lora_config,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset[\"train\"],\n",
    "    dataset_text_field=\"text\",\n",
    "    max_seq_length=max_seq_length,\n",
    "    packing=packing\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-30T10:16:26.992730Z",
     "start_time": "2024-05-30T10:16:26.929021Z"
    }
   },
   "id": "c60c5aa9a7d970b3",
   "execution_count": 29,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "trainer.train()",
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "end_time": "2024-05-30T16:32:26.158601Z",
     "start_time": "2024-05-30T10:16:26.993780Z"
    }
   },
   "id": "5d9ba03835392e2a",
   "execution_count": 30,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "wandb.finish()\n",
    "trainer.save_model(model_name)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "end_time": "2024-05-30T16:32:35.716063Z",
     "start_time": "2024-05-30T16:32:26.165231Z"
    }
   },
   "id": "f4b2fdcf617359a4",
   "execution_count": 31,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Inference",
   "metadata": {
    "collapsed": false
   },
   "id": "4ec24bf55b44834d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-30T16:32:35.720146Z",
     "start_time": "2024-05-30T16:32:35.717207Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def prompt_template(system, user):\n",
    "    return (\n",
    "        \"<s>[INST]<<SYS>>\\n\"\n",
    "        f\"{system}\\n\"\n",
    "        \"<</SYS>>\\n\\n\"\n",
    "        \n",
    "        f\"{user}[/INST]\"\n",
    "    )"
   ],
   "id": "cd97cb5f0b719d5e",
   "execution_count": 32,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-30T16:32:35.727341Z",
     "start_time": "2024-05-30T16:32:35.721183Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def generate_response(system ,user):\n",
    "    prompt = prompt_template(system, user)\n",
    "    \n",
    "    input_ids = tokenizer.encode(\n",
    "        prompt,\n",
    "        max_length=max_length,\n",
    "        padding=padding,\n",
    "        truncation=truncation,\n",
    "        add_special_tokens=False,\n",
    "        return_tensors=\"pt\"\n",
    "    ).to(device)\n",
    "    \n",
    "    outputs = model.generate(\n",
    "        input_ids=input_ids,\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "        num_return_sequences=num_return_sequences,\n",
    "        max_new_tokens=max_new_tokens,\n",
    "        do_sample=do_sample,\n",
    "        temperature=temperature,\n",
    "        top_p=top_p,\n",
    "        repetition_penalty=repetition_penalty\n",
    "    )\n",
    "    \n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=False)"
   ],
   "id": "926796ff0f85510b",
   "execution_count": 33,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-30T16:32:35.734541Z",
     "start_time": "2024-05-30T16:32:35.728333Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#system_prompt = \"You are a helpful assistant. Respond to the following user prompt.\"\n",
    "system_prompt = \"다음 지시사항에 대한 응답을 작성해주세요.\"\n",
    "#user_prompt = \"Write me a poem about Machine Learning.\"\n",
    "user_prompt = \"머신러닝에 대한 시를 써주세요.\""
   ],
   "id": "d35aa851e8176d2d",
   "execution_count": 34,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "response = generate_response(system_prompt, user_prompt)\n",
    "print(response)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "end_time": "2024-05-30T16:37:54.110994Z",
     "start_time": "2024-05-30T16:32:35.735514Z"
    }
   },
   "id": "1219dfd08fc2facd",
   "execution_count": 35,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Upload PEFT Model",
   "id": "8c64f03b7b139093"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T02:17:15.471243Z",
     "start_time": "2024-05-31T02:16:50.263543Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tokenizer.push_to_hub(\n",
    "    repo_id=repo_id,\n",
    "    use_temp_dir=False\n",
    ")\n",
    "model.push_to_hub(\n",
    "    repo_id=repo_id,\n",
    "    use_temp_dir=False\n",
    ")"
   ],
   "id": "cb45a3cfa04bbe",
   "execution_count": 38,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
